{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10afd79c",
   "metadata": {},
   "source": [
    "# Training a model for correct first page prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d9053",
   "metadata": {},
   "source": [
    "This notebook covers one of the approaches to training a model for predicting whether a page of the document is the first one or not -- a feature that would allow correct splitting for PDFs that consist of more than one actual document (we assume that the pages are already sorted). The approach used is NBOW (Neural Bag-of-words)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b2125",
   "metadata": {},
   "source": [
    "Before you start, makee sure you have **installed** and **initialized** the konfuzio_sdk package as shown in the readme of the [repository](https://github.com/konfuzio-ai/Python-SDK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konfuzio-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c57130",
   "metadata": {},
   "outputs": [],
   "source": [
    "!konfuzio_sdk init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80734a86",
   "metadata": {},
   "source": [
    "Importing necessary libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53858247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from konfuzio_sdk.data import Project, Document\n",
    "from nltk import word_tokenize\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a707c",
   "metadata": {},
   "source": [
    "Setting seed for reproducibility purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72d86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636852e",
   "metadata": {},
   "source": [
    "We will use a multilayered perceptron architecture built with Keras library and a vocabulary built by using Counter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d6d22",
   "metadata": {},
   "source": [
    "### Gathering the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579d2b6",
   "metadata": {},
   "source": [
    "Loading our project for training and testing purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1de0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project = Project(id_=1644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02180ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = my_project.documents\n",
    "test_data = my_project.test_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f195fd",
   "metadata": {},
   "source": [
    "Preparing data for training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1488016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1443/1443 [00:02<00:00, 683.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_texts = []\n",
    "train_data_labels = []\n",
    "\n",
    "for doc in tqdm(train_data):\n",
    "    for page in doc.pages():\n",
    "        train_data_texts.append(page.text)\n",
    "        if page.number == 1:\n",
    "            train_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            train_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ebf15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 286/286 [00:00<00:00, 696.91it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_texts = []\n",
    "test_data_labels = []\n",
    "\n",
    "for doc in tqdm(test_data):\n",
    "    for page in doc.pages():\n",
    "        test_data_texts.append(page.text)\n",
    "        if page.number == 1:\n",
    "            test_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            test_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384388f",
   "metadata": {},
   "source": [
    "### NBOW (no preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03364ea3",
   "metadata": {},
   "source": [
    "Initializing and building the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c24fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32592b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2634/2634 [00:07<00:00, 361.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm(train_data_texts):\n",
    "    tokens = word_tokenize(text)\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c77e4b",
   "metadata": {},
   "source": [
    "Intializing and fitting the tokenizer for subsequent applying at the training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a0d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97812f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_data_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328089a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2634, 49404)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = tokenizer.texts_to_matrix(train_data_texts, mode='freq')\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df45169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 49404)\n"
     ]
    }
   ],
   "source": [
    "Xtest = tokenizer.texts_to_matrix(test_data_texts, mode='freq')\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f3651",
   "metadata": {},
   "source": [
    "Processing the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d420ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.array(train_data_labels)\n",
    "ytest = np.array(test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "041e4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = Xtest.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8bbc0",
   "metadata": {},
   "source": [
    "The architecture is Keras's Sequential with two Dense layers. The training runs for 50 epochs; chosen metric is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b9c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 14:24:15.461986: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5283 - accuracy: 0.7388 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.2112 - accuracy: 0.9127 - 898ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0762 - accuracy: 0.9749 - 1s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0335 - accuracy: 0.9913 - 917ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0249 - accuracy: 0.9916 - 914ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0204 - accuracy: 0.9939 - 924ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0156 - accuracy: 0.9943 - 1s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0157 - accuracy: 0.9932 - 996ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0131 - accuracy: 0.9954 - 935ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0138 - accuracy: 0.9947 - 1s/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0121 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9951 - 963ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 999ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9954 - 998ms/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9962 - 967ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9970 - 955ms/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9958 - 962ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0132 - accuracy: 0.9954 - 938ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0159 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9973 - 1s/epoch - 18ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9970 - 1s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9954 - 989ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9966 - 976ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9951 - 968ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9958 - 976ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 955ms/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9958 - 987ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9973 - 993ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 2s - loss: 0.0068 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 2s - loss: 0.0065 - accuracy: 0.9981 - 2s/epoch - 20ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9970 - 1s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9981 - 1s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9973 - 1s/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9970 - 1s/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9973 - 1s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9977 - 1s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 2s - loss: 0.0062 - accuracy: 0.9973 - 2s/epoch - 19ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 2s - loss: 0.0050 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 2s - loss: 0.0073 - accuracy: 0.9977 - 2s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 2s - loss: 0.0064 - accuracy: 0.9970 - 2s/epoch - 27ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9966 - 2s/epoch - 21ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 2s - loss: 0.0054 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 2s - loss: 0.0061 - accuracy: 0.9973 - 2s/epoch - 23ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9977 - 1s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9973 - 1s/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 2s - loss: 0.0051 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 2s - loss: 0.0044 - accuracy: 0.9981 - 2s/epoch - 20ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 2s - loss: 0.0076 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 2s - loss: 0.0058 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9973 - 2s/epoch - 23ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 2s - loss: 0.0055 - accuracy: 0.9973 - 2s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9970 - 2s/epoch - 24ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 2s - loss: 0.0055 - accuracy: 0.9977 - 2s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 2s - loss: 0.0066 - accuracy: 0.9966 - 2s/epoch - 22ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 2s - loss: 0.0053 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9970 - 2s/epoch - 24ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9981 - 1s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 2s - loss: 0.0055 - accuracy: 0.9973 - 2s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 2s - loss: 0.0061 - accuracy: 0.9962 - 2s/epoch - 18ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feeeb2a9c40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xtrain, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e5b97",
   "metadata": {},
   "source": [
    "Let's save our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba012b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NBOW.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795753a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 13:45:12.881055: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('NBOW.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b102495",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47241b2c",
   "metadata": {},
   "source": [
    "### Metrics & prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0b972",
   "metadata": {},
   "source": [
    "Accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3da44cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.85057330131531\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc624dc8",
   "metadata": {},
   "source": [
    "A function for running predictions manually consists of pre-filtering with the usage of previously built vocabulary and the prediction on the remaining tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f2a7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(page_text, vocab, tokenizer, model):\n",
    "    tokens = word_tokenize(page_text)\n",
    "    tokens = [t for t in tokens if t in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    pred = model.predict(encoded, verbose=0)\n",
    "    return round(pred[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d570e",
   "metadata": {},
   "source": [
    "We calculate our custom metric via the following function that determines how many ground-truth first pages were actually predicted as first pages. The logic behind this approach suggests that by determining first pages correctly we can consecutively split documents correctly, using each first page as a separator (since it means a start of a new document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83846d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(texts, labels):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for i, test in tqdm(zip(labels, texts)):\n",
    "        pred = predict_label(test, vocab, tokenizer, model)\n",
    "        if i == 1 and pred == 1:\n",
    "            true_positive += 1\n",
    "        elif i == 1 and pred == 0:\n",
    "            false_negative += 1\n",
    "        elif i == 0 and pred == 1:\n",
    "            false_positive += 1\n",
    "    \n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if precision + recall != 0:\n",
    "    \n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        f1 = 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1 = calculate_metrics(test_data_texts, test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fae37a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Precision: 0.7642276422764228 \n",
      " Recall: 0.986013986013986 \n",
      " F1-score: 0.8610687022900764\n"
     ]
    }
   ],
   "source": [
    "print('\\n Precision: {} \\n Recall: {} \\n F1-score: {}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414e8c2",
   "metadata": {},
   "source": [
    "Manual assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef74a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for test in test_data_texts[:10]: \n",
    "    print(predict_label(test, vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3acd7490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26cc242",
   "metadata": {},
   "source": [
    "The results for the manual assessment prove to be similar to the evaluation given previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a05a65",
   "metadata": {},
   "source": [
    "Let us make some visualizations to ensure the manually-run predictions are correct as well.\n",
    "First, let's take a look at a single-page document which is the first in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f19c0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document 32.pdf (334665)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373604a",
   "metadata": {},
   "source": [
    "Since it's a single-page document, it only has the first page, and it was predicted as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db0bc375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 1 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[0] , \", prediction:\", predict_label(test_data_texts[0], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920220e7",
   "metadata": {},
   "source": [
    "Next, we'll take a look at a two-page document which is also present in the test set. Its first page should be predicted to be the first (receive label 1) , and the second one should be predicted as not first (receive label 0), and it has been predicted as such."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a7e3c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "test_data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "beacb10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 1 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[7] , \", prediction:\", predict_label(test_data_texts[7], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b7a3787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 0 , prediction: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[8] , \", prediction:\", predict_label(test_data_texts[8], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab95f92",
   "metadata": {},
   "source": [
    "Not all the pages get predicted correctly. Let's take a look at the three-page document that got 2 non-first pages predicted as first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b92b8d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 1 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[28] , \", prediction:\", predict_label(test_data_texts[28], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "974923e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = my_project.get_document_by_id(334946).pages()[0].image_path\n",
    "path_2 = my_project.get_document_by_id(334946).pages()[1].image_path\n",
    "path_3 = my_project.get_document_by_id(334946).pages()[2].image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab8456d",
   "metadata": {},
   "source": [
    "The following page gets predicted incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afbf6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 0 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[29] , \", prediction:\", predict_label(test_data_texts[29], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38418c70",
   "metadata": {},
   "source": [
    "The third page also gets an incorrect prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d8d7575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 0 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[30] , \", prediction:\", predict_label(test_data_texts[30], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021f57a",
   "metadata": {},
   "source": [
    "## Testing various preprocessing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48936c05",
   "metadata": {},
   "source": [
    "In order to possibly enhance the results, let's try several preprocessing approaches for the texts. There will be eight of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec49cb",
   "metadata": {},
   "source": [
    "Removal of punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0957de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punctuation(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0147e",
   "metadata": {},
   "source": [
    "Removal of punctuation and non-alphabetical tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0147f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punct_alpha(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49112c",
   "metadata": {},
   "source": [
    "Removal of punctuation, non-alphabetical tokens, and 1-character-long tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abe0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punct_alpha_len(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7bf59",
   "metadata": {},
   "source": [
    "Removal of punctuation, non-alphabetical tokens, 1-character-long tokens, and stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc6e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punct_alpha_len_sw(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3635b",
   "metadata": {},
   "source": [
    "Removal of punctuation and stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c86108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punct_sw(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a1ada",
   "metadata": {},
   "source": [
    "Removal of punctuation, 1-character-long tokens, and stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "409b71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punct_len_sw(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d2d39",
   "metadata": {},
   "source": [
    "Removal of punctuation, 1-character-long tokens, stopwords, and numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33282af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punct_len_sw_nums(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = [w for w in tokens if not w.isnumeric()]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b318662",
   "metadata": {},
   "source": [
    "Removal of punctuation, 1-character-long tokens, stopwords, and dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e01b1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_punct_len_sw_dates(text):\n",
    "    text = re.sub(r\"[0-9]{1,4}[\\_|\\-|\\/|\\|\\.][0-9]{1,2}[\\_|\\-|\\/|\\|\\.][0-9]{1,4}\", '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a1065",
   "metadata": {},
   "source": [
    "For each of the approaches, we will need a separate train and test set, a vocabulary and a tokenizer fit specifically on this set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32599e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1443/1443 [00:59<00:00, 24.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_texts_1 = []\n",
    "train_data_labels = []\n",
    "\n",
    "train_data_texts_2 = []\n",
    "train_data_texts_3 = []\n",
    "train_data_texts_4 = []\n",
    "train_data_texts_5 = []\n",
    "train_data_texts_6 = []\n",
    "train_data_texts_7 = []\n",
    "train_data_texts_8 = []\n",
    "\n",
    "\n",
    "for doc in tqdm(train_data):\n",
    "    for page in doc.pages():\n",
    "        train_data_texts_1.append(page.text)\n",
    "        train_data_texts_2.append(preprocess_punctuation(page.text))\n",
    "        train_data_texts_3.append(preprocess_punct_alpha(page.text))\n",
    "        train_data_texts_4.append(preprocess_punct_alpha_len(page.text))\n",
    "        train_data_texts_5.append(preprocess_punct_sw(page.text))\n",
    "        train_data_texts_6.append(preprocess_punct_len_sw(page.text))\n",
    "        train_data_texts_7.append(preprocess_punct_len_sw_nums(page.text))\n",
    "        train_data_texts_8.append(preprocess_punct_len_sw_dates(page.text))\n",
    "        if page.number == 1:\n",
    "            train_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            train_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4f4e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 286/286 [00:08<00:00, 32.41it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_texts_1 = []\n",
    "test_data_labels = []\n",
    "\n",
    "test_data_texts_2 = []\n",
    "test_data_texts_3 = []\n",
    "test_data_texts_4 = []\n",
    "test_data_texts_5 = []\n",
    "test_data_texts_6 = []\n",
    "test_data_texts_7 = []\n",
    "test_data_texts_8 = []\n",
    "\n",
    "for doc in tqdm(test_data):\n",
    "    for page in doc.pages():\n",
    "        test_data_texts_1.append(page.text)\n",
    "        test_data_texts_2.append(preprocess_punctuation(page.text))\n",
    "        test_data_texts_3.append(preprocess_punct_alpha(page.text))\n",
    "        test_data_texts_4.append(preprocess_punct_alpha_len(page.text))\n",
    "        test_data_texts_5.append(preprocess_punct_sw(page.text))\n",
    "        test_data_texts_6.append(preprocess_punct_len_sw(page.text))\n",
    "        test_data_texts_7.append(preprocess_punct_len_sw_nums(page.text))\n",
    "        test_data_texts_8.append(preprocess_punct_len_sw_dates(page.text))\n",
    "        if page.number == 1:\n",
    "            test_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            test_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccee523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_1 = Counter()\n",
    "vocab_2 = Counter()\n",
    "vocab_3 = Counter()\n",
    "vocab_4 = Counter()\n",
    "vocab_5 = Counter()\n",
    "vocab_6 = Counter()\n",
    "vocab_7 = Counter()\n",
    "vocab_8 = Counter()\n",
    "\n",
    "vocab = [vocab_1, vocab_2, vocab_3, vocab_4, vocab_5, vocab_6, vocab_7, vocab_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48ae2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [train_data_texts_1, train_data_texts_2, train_data_texts_3, train_data_texts_4,\n",
    "        train_data_texts_5, train_data_texts_6, train_data_texts_7, train_data_texts_8]\n",
    "\n",
    "for t, v in zip(train, vocab):\n",
    "    for text in t:\n",
    "        tokens = word_tokenize(text)\n",
    "        v.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ec1f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_1 = Tokenizer()\n",
    "tokenizer_2 = Tokenizer()\n",
    "tokenizer_3 = Tokenizer()\n",
    "tokenizer_4 = Tokenizer()\n",
    "tokenizer_5 = Tokenizer()\n",
    "tokenizer_6 = Tokenizer()\n",
    "tokenizer_7 = Tokenizer()\n",
    "tokenizer_8 = Tokenizer()\n",
    "\n",
    "tokenizer = [tokenizer_1, tokenizer_2, tokenizer_3, tokenizer_4, tokenizer_5, tokenizer_6, tokenizer_7,\n",
    "            tokenizer_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c063d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_1.fit_on_texts(train_data_texts_1)\n",
    "tokenizer_2.fit_on_texts(train_data_texts_2)\n",
    "tokenizer_3.fit_on_texts(train_data_texts_3)\n",
    "tokenizer_4.fit_on_texts(train_data_texts_4)\n",
    "tokenizer_5.fit_on_texts(train_data_texts_5)\n",
    "tokenizer_6.fit_on_texts(train_data_texts_6)\n",
    "tokenizer_7.fit_on_texts(train_data_texts_7)\n",
    "tokenizer_8.fit_on_texts(train_data_texts_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9b5d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_1 = tokenizer_1.texts_to_matrix(train_data_texts_1, mode='freq')\n",
    "Xtrain_2 = tokenizer_2.texts_to_matrix(train_data_texts_2, mode='freq')\n",
    "Xtrain_3 = tokenizer_3.texts_to_matrix(train_data_texts_3, mode='freq')\n",
    "Xtrain_4 = tokenizer_4.texts_to_matrix(train_data_texts_4, mode='freq')\n",
    "Xtrain_5 = tokenizer_5.texts_to_matrix(train_data_texts_5, mode='freq')\n",
    "Xtrain_6 = tokenizer_6.texts_to_matrix(train_data_texts_6, mode='freq')\n",
    "Xtrain_7 = tokenizer_7.texts_to_matrix(train_data_texts_7, mode='freq')\n",
    "Xtrain_8 = tokenizer_8.texts_to_matrix(train_data_texts_8, mode='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d846d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_1 = tokenizer_1.texts_to_matrix(test_data_texts_1, mode='freq')\n",
    "Xtest_2 = tokenizer_2.texts_to_matrix(test_data_texts_2, mode='freq')\n",
    "Xtest_3 = tokenizer_3.texts_to_matrix(test_data_texts_3, mode='freq')\n",
    "Xtest_4 = tokenizer_4.texts_to_matrix(test_data_texts_4, mode='freq')\n",
    "Xtest_5 = tokenizer_5.texts_to_matrix(test_data_texts_5, mode='freq')\n",
    "Xtest_6 = tokenizer_6.texts_to_matrix(test_data_texts_6, mode='freq')\n",
    "Xtest_7 = tokenizer_7.texts_to_matrix(test_data_texts_7, mode='freq')\n",
    "Xtest_8 = tokenizer_8.texts_to_matrix(test_data_texts_8, mode='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8013a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.array(train_data_labels)\n",
    "ytest = np.array(test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a85919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words_1 = Xtest_1.shape[1]\n",
    "n_words_2 = Xtest_2.shape[1]\n",
    "n_words_3 = Xtest_3.shape[1]\n",
    "n_words_4 = Xtest_4.shape[1]\n",
    "n_words_5 = Xtest_5.shape[1]\n",
    "n_words_6 = Xtest_6.shape[1]\n",
    "n_words_7 = Xtest_7.shape[1]\n",
    "n_words_8 = Xtest_8.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54658072",
   "metadata": {},
   "source": [
    "Fitting the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ad58df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5130 - accuracy: 0.7574 - 2s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.2018 - accuracy: 0.9172 - 924ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0765 - accuracy: 0.9742 - 836ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0368 - accuracy: 0.9882 - 936ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0222 - accuracy: 0.9916 - 979ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0190 - accuracy: 0.9928 - 865ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0154 - accuracy: 0.9943 - 952ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0202 - accuracy: 0.9924 - 897ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9962 - 924ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9935 - 859ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0125 - accuracy: 0.9958 - 879ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9954 - 870ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0135 - accuracy: 0.9947 - 873ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0114 - accuracy: 0.9958 - 872ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9966 - 875ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9970 - 899ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 885ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9962 - 872ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9958 - 952ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0125 - accuracy: 0.9947 - 927ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0104 - accuracy: 0.9970 - 891ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9962 - 891ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9973 - 884ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9951 - 861ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9970 - 950ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9951 - 1s/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9966 - 948ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9954 - 910ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9962 - 888ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9962 - 890ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 841ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9970 - 902ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9947 - 997ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 983ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9970 - 910ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0109 - accuracy: 0.9954 - 982ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 895ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9954 - 890ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9981 - 904ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0104 - accuracy: 0.9970 - 918ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9966 - 946ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9958 - 896ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9966 - 877ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9951 - 896ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9981 - 885ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9973 - 894ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9954 - 904ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9973 - 936ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9970 - 905ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 881ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9970 - 922ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9966 - 927ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9970 - 893ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9958 - 892ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9954 - 878ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 881ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9954 - 890ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9970 - 893ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9977 - 906ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 902ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 871ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9966 - 870ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9973 - 891ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0050 - accuracy: 0.9970 - 964ms/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 943ms/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9970 - 915ms/epoch - 11ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9981 - 927ms/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9970 - 931ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9970 - 917ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 886ms/epoch - 11ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 933ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9962 - 908ms/epoch - 11ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9962 - 880ms/epoch - 11ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9962 - 888ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9973 - 897ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9977 - 896ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9973 - 878ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 935ms/epoch - 11ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9962 - 932ms/epoch - 11ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9970 - 910ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9970 - 933ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9962 - 954ms/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0036 - accuracy: 0.9985 - 922ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9977 - 915ms/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9966 - 968ms/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9977 - 967ms/epoch - 12ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0050 - accuracy: 0.9970 - 930ms/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0049 - accuracy: 0.9966 - 936ms/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9970 - 937ms/epoch - 11ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9962 - 975ms/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 965ms/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9958 - 934ms/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d2ed56fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(50, input_shape=(n_words_1,), activation='relu'))\n",
    "model_1.add(Dense(50, activation='elu'))\n",
    "model_1.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(Xtrain_1, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0978999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5301 - accuracy: 0.7373 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1955 - accuracy: 0.9203 - 1s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0647 - accuracy: 0.9822 - 1s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0266 - accuracy: 0.9920 - 1s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0157 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0143 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0175 - accuracy: 0.9939 - 1s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0123 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0119 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0145 - accuracy: 0.9943 - 1s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9985 - 1s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 2s - loss: 0.0083 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0046 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 2s - loss: 0.0072 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9977 - 1s/epoch - 13ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 2s - loss: 0.0067 - accuracy: 0.9970 - 2s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 2s - loss: 0.0069 - accuracy: 0.9977 - 2s/epoch - 21ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 2s - loss: 0.0074 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9973 - 1s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9966 - 1s/epoch - 18ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9973 - 1s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9977 - 1s/epoch - 18ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 2s - loss: 0.0053 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9970 - 1s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0049 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9cf55e2be0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(50, input_shape=(n_words_2,), activation='relu'))\n",
    "model_2.add(Dense(50, activation='elu'))\n",
    "model_2.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(Xtrain_2, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6abc3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 1s - loss: 0.5369 - accuracy: 0.7267 - 1s/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.2024 - accuracy: 0.9241 - 625ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0771 - accuracy: 0.9768 - 623ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0396 - accuracy: 0.9894 - 623ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0263 - accuracy: 0.9913 - 655ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0188 - accuracy: 0.9939 - 671ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0160 - accuracy: 0.9924 - 798ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0223 - accuracy: 0.9928 - 641ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9970 - 651ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0170 - accuracy: 0.9935 - 755ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0134 - accuracy: 0.9951 - 644ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9954 - 652ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9954 - 757ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9954 - 659ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9958 - 656ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9951 - 659ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9962 - 643ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0154 - accuracy: 0.9943 - 631ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9958 - 638ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9962 - 700ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9962 - 631ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9962 - 645ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 717ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9977 - 670ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9966 - 753ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9970 - 744ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0092 - accuracy: 0.9966 - 641ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0102 - accuracy: 0.9958 - 637ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9970 - 639ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9966 - 634ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 688ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9973 - 692ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0131 - accuracy: 0.9947 - 685ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9977 - 694ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9966 - 690ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 704ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 883ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9947 - 986ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 963ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9970 - 958ms/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 922ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9970 - 803ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9970 - 788ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9970 - 784ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9973 - 700ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 705ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9958 - 702ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9977 - 705ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9966 - 681ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 715ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9962 - 900ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9973 - 1s/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9966 - 945ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9970 - 875ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 966ms/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0047 - accuracy: 0.9981 - 769ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 756ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9973 - 835ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9958 - 718ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9962 - 803ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 708ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9962 - 706ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9977 - 836ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9954 - 784ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9962 - 757ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9958 - 771ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9970 - 742ms/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9962 - 811ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9962 - 785ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9973 - 741ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 827ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9962 - 882ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9966 - 790ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9973 - 863ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9977 - 940ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0039 - accuracy: 0.9973 - 711ms/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9977 - 886ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9981 - 722ms/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9966 - 736ms/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 713ms/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 745ms/epoch - 9ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9966 - 754ms/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 689ms/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9970 - 705ms/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9954 - 688ms/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9973 - 662ms/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 681ms/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9958 - 749ms/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9962 - 682ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 701ms/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9966 - 716ms/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 686ms/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 751ms/epoch - 9ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9962 - 760ms/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 783ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0047 - accuracy: 0.9973 - 788ms/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ccb06e6a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(50, input_shape=(n_words_3,), activation='relu'))\n",
    "model_3.add(Dense(50, activation='elu'))\n",
    "model_3.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_3.fit(Xtrain_3, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2b8a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5189 - accuracy: 0.7426 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1915 - accuracy: 0.9233 - 736ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0773 - accuracy: 0.9711 - 707ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0397 - accuracy: 0.9886 - 800ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0259 - accuracy: 0.9913 - 1s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0189 - accuracy: 0.9920 - 1s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0193 - accuracy: 0.9932 - 1s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 2s - loss: 0.0173 - accuracy: 0.9935 - 2s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 2s - loss: 0.0170 - accuracy: 0.9947 - 2s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 2s - loss: 0.0142 - accuracy: 0.9951 - 2s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 2s - loss: 0.0122 - accuracy: 0.9966 - 2s/epoch - 18ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0157 - accuracy: 0.9951 - 866ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9947 - 870ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0122 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0144 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9947 - 1s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9954 - 1s/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9947 - 1s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9954 - 983ms/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0168 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 1s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9966 - 952ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0113 - accuracy: 0.9954 - 849ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0134 - accuracy: 0.9951 - 738ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9951 - 752ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0104 - accuracy: 0.9962 - 797ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9947 - 760ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0102 - accuracy: 0.9954 - 725ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0161 - accuracy: 0.9939 - 757ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9962 - 697ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9951 - 715ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0109 - accuracy: 0.9954 - 700ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 720ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9962 - 714ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9970 - 713ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9966 - 687ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9958 - 693ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9951 - 701ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9958 - 704ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 713ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 702ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9970 - 678ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9947 - 746ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 738ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 742ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9954 - 951ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9954 - 842ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9951 - 726ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9954 - 719ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 865ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9966 - 737ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9962 - 793ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 886ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9962 - 829ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 850ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 816ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9962 - 787ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9954 - 765ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9954 - 723ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9947 - 766ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9954 - 748ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 726ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 733ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9954 - 846ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 802ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 759ms/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9966 - 778ms/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 737ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 707ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 713ms/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 712ms/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9962 - 797ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9958 - 769ms/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 788ms/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9966 - 775ms/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9954 - 788ms/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9943 - 738ms/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9962 - 676ms/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9958 - 696ms/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9954 - 700ms/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9958 - 872ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 889ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9954 - 781ms/epoch - 9ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9962 - 715ms/epoch - 9ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9954 - 693ms/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9962 - 658ms/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9951 - 670ms/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9962 - 653ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9958 - 665ms/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9954 - 742ms/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 723ms/epoch - 9ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9970 - 743ms/epoch - 9ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9951 - 701ms/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9958 - 689ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9958 - 821ms/epoch - 10ms/step\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 812ms/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c9a7f3070>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(50, input_shape=(n_words_4,), activation='relu'))\n",
    "model_4.add(Dense(50, activation='elu'))\n",
    "model_4.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_4.fit(Xtrain_4, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a174c2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5127 - accuracy: 0.7677 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1708 - accuracy: 0.9324 - 1s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0598 - accuracy: 0.9814 - 1s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0269 - accuracy: 0.9920 - 1s/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0154 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0148 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0135 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0130 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0050 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9977 - 1s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9970 - 1s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0042 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0049 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0045 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0045 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 2s - loss: 0.0046 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9977 - 2s/epoch - 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c7a6c2190>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Dense(50, input_shape=(n_words_5,), activation='relu'))\n",
    "model_5.add(Dense(50, activation='elu'))\n",
    "model_5.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_5.fit(Xtrain_5, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0705880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5295 - accuracy: 0.7156 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1672 - accuracy: 0.9358 - 1s/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0599 - accuracy: 0.9803 - 1s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0258 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0199 - accuracy: 0.9935 - 1s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0143 - accuracy: 0.9962 - 1s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0136 - accuracy: 0.9947 - 1s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0124 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0140 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0109 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 2s - loss: 0.0149 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9947 - 1s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 2s - loss: 0.0124 - accuracy: 0.9951 - 2s/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0130 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0121 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0114 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9939 - 1s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9966 - 1s/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 2s - loss: 0.0063 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9954 - 1s/epoch - 18ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 2s - loss: 0.0069 - accuracy: 0.9954 - 2s/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 2s - loss: 0.0078 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9962 - 2s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 2s - loss: 0.0068 - accuracy: 0.9954 - 2s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c5af99f70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Dense(50, input_shape=(n_words_6,), activation='relu'))\n",
    "model_6.add(Dense(50, activation='elu'))\n",
    "model_6.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_6.fit(Xtrain_6, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6a9e17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5140 - accuracy: 0.7677 - 2s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1807 - accuracy: 0.9256 - 982ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0657 - accuracy: 0.9787 - 902ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0361 - accuracy: 0.9879 - 903ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0179 - accuracy: 0.9939 - 928ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0197 - accuracy: 0.9947 - 922ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9962 - 958ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0146 - accuracy: 0.9943 - 931ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0142 - accuracy: 0.9947 - 917ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9958 - 963ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0141 - accuracy: 0.9947 - 1s/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0130 - accuracy: 0.9954 - 998ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9954 - 908ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9951 - 921ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0146 - accuracy: 0.9954 - 968ms/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9947 - 951ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9951 - 949ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9947 - 941ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 917ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9958 - 918ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9954 - 919ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0135 - accuracy: 0.9951 - 940ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0102 - accuracy: 0.9954 - 980ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9958 - 938ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0149 - accuracy: 0.9939 - 947ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 930ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9943 - 931ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9958 - 885ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 954ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9951 - 936ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9962 - 928ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9947 - 872ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9958 - 876ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9954 - 885ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 904ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9951 - 964ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9962 - 887ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 879ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9958 - 901ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9966 - 958ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9947 - 1s/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9951 - 996ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9954 - 997ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 946ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9962 - 937ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 953ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9951 - 970ms/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9973 - 954ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9973 - 969ms/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9970 - 902ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9962 - 973ms/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9973 - 977ms/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9958 - 921ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 978ms/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9966 - 995ms/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 2s - loss: 0.0078 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 2s - loss: 0.0070 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9947 - 1s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9951 - 1s/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9954 - 971ms/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 960ms/epoch - 12ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9951 - 961ms/epoch - 12ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 991ms/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9962 - 954ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9954 - 977ms/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9947 - 962ms/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 2s - loss: 0.0063 - accuracy: 0.9970 - 2s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 951ms/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c2d262af0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7 = Sequential()\n",
    "model_7.add(Dense(50, input_shape=(n_words_7,), activation='relu'))\n",
    "model_7.add(Dense(50, activation='elu'))\n",
    "model_7.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_7.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_7.fit(Xtrain_7, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27ca2539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 3s - loss: 0.5153 - accuracy: 0.7673 - 3s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 2s - loss: 0.1653 - accuracy: 0.9362 - 2s/epoch - 23ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 2s - loss: 0.0558 - accuracy: 0.9829 - 2s/epoch - 22ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 2s - loss: 0.0230 - accuracy: 0.9928 - 2s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 2s - loss: 0.0162 - accuracy: 0.9951 - 2s/epoch - 22ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 2s - loss: 0.0138 - accuracy: 0.9943 - 2s/epoch - 23ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 2s - loss: 0.0122 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 2s - loss: 0.0109 - accuracy: 0.9973 - 2s/epoch - 22ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 2s - loss: 0.0128 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 2s - loss: 0.0144 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0163 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 2s - loss: 0.0131 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9966 - 1s/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 2s - loss: 0.0087 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9958 - 1s/epoch - 18ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 2s - loss: 0.0104 - accuracy: 0.9962 - 2s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0132 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 2s - loss: 0.0083 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 2s - loss: 0.0097 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 2s - loss: 0.0084 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 2s - loss: 0.0097 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 2s - loss: 0.0077 - accuracy: 0.9962 - 2s/epoch - 20ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 2s - loss: 0.0097 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 2s - loss: 0.0122 - accuracy: 0.9951 - 2s/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 2s - loss: 0.0092 - accuracy: 0.9943 - 2s/epoch - 24ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 2s - loss: 0.0094 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 2s - loss: 0.0080 - accuracy: 0.9958 - 2s/epoch - 23ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 2s - loss: 0.0099 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 2s - loss: 0.0086 - accuracy: 0.9962 - 2s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 2s - loss: 0.0073 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 2s - loss: 0.0087 - accuracy: 0.9970 - 2s/epoch - 22ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 2s - loss: 0.0083 - accuracy: 0.9958 - 2s/epoch - 20ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 2s - loss: 0.0095 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9947 - 1s/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9962 - 1s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 2s - loss: 0.0088 - accuracy: 0.9962 - 2s/epoch - 20ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 2s - loss: 0.0056 - accuracy: 0.9962 - 2s/epoch - 19ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9970 - 1s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 2s - loss: 0.0067 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 2s - loss: 0.0061 - accuracy: 0.9954 - 2s/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 2s - loss: 0.0067 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9954 - 2s/epoch - 18ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 2s - loss: 0.0063 - accuracy: 0.9962 - 2s/epoch - 23ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 2s - loss: 0.0056 - accuracy: 0.9954 - 2s/epoch - 22ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 2s - loss: 0.0058 - accuracy: 0.9943 - 2s/epoch - 19ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9bff539c70>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8 = Sequential()\n",
    "model_8.add(Dense(50, input_shape=(n_words_8,), activation='relu'))\n",
    "model_8.add(Dense(50, activation='elu'))\n",
    "model_8.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_8.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_8.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_8.fit(Xtrain_8, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42612943",
   "metadata": {},
   "source": [
    "Evaluating our models' performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "240b1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1, acc_1 = model_1.evaluate(Xtest_1, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4da3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_2, acc_2 = model_2.evaluate(Xtest_2, ytest, verbose=0)\n",
    "loss_3, acc_3 = model_3.evaluate(Xtest_3, ytest, verbose=0)\n",
    "loss_4, acc_4 = model_4.evaluate(Xtest_4, ytest, verbose=0)\n",
    "loss_5, acc_5 = model_5.evaluate(Xtest_5, ytest, verbose=0)\n",
    "loss_6, acc_6 = model_6.evaluate(Xtest_6, ytest, verbose=0)\n",
    "loss_7, acc_7 = model_7.evaluate(Xtest_7, ytest, verbose=0)\n",
    "loss_8, acc_8 = model_8.evaluate(Xtest_8, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58568c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1: 77.93103456497192 \n",
      " Accuracy 2: 77.7011513710022 \n",
      " Accuracy 3: 77.93103456497192 \n",
      " Accuracy 4: 77.93103456497192 \n",
      " Accuracy 5: 79.08046245574951 \n",
      " Accuracy 6: 79.08046245574951 \n",
      " Accuracy 7: 78.85057330131531 \n",
      " Accuracy 8: 77.7011513710022 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy 1: {} \\n'.format(acc_1*100),\n",
    "     'Accuracy 2: {} \\n'.format(acc_2*100),\n",
    "     'Accuracy 3: {} \\n'.format(acc_3*100),\n",
    "     'Accuracy 4: {} \\n'.format(acc_4*100),\n",
    "     'Accuracy 5: {} \\n'.format(acc_5*100),\n",
    "     'Accuracy 6: {} \\n'.format(acc_6*100),\n",
    "     'Accuracy 7: {} \\n'.format(acc_7*100),\n",
    "     'Accuracy 8: {} \\n'.format(acc_8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ad8554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(page_text, vocab, tokenizer, model):\n",
    "    tokens = word_tokenize(page_text)\n",
    "    tokens = [t for t in tokens if t in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    pred = model.predict(encoded, verbose=0)\n",
    "    return round(pred[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d25dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(texts, labels, tokenizer, model, vocab):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for i, test in tqdm(zip(labels, texts)):\n",
    "        pred = predict_label(test, vocab, tokenizer, model)\n",
    "        if i == 1 and pred == 1:\n",
    "            true_positive += 1\n",
    "        elif i == 1 and pred == 0:\n",
    "            false_negative += 1\n",
    "        elif i == 0 and pred == 1:\n",
    "            false_positive += 1\n",
    "    \n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if precision + recall != 0:\n",
    "    \n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        f1 = 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b572bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [00:19, 22.14it/s]\n",
      "435it [00:16, 25.61it/s]\n",
      "435it [00:16, 25.61it/s]\n",
      "435it [00:16, 26.63it/s]\n",
      "435it [00:16, 25.59it/s]\n",
      "435it [00:16, 26.44it/s]\n",
      "435it [00:16, 26.65it/s]\n",
      "435it [00:16, 26.71it/s]\n"
     ]
    }
   ],
   "source": [
    "precision_1, recall_1, f1_1 = calculate_metrics(test_data_texts_1, test_data_labels, tokenizer_1, model_1, vocab_1)\n",
    "precision_2, recall_2, f1_2 = calculate_metrics(test_data_texts_2, test_data_labels, tokenizer_2, model_2, vocab_2)\n",
    "precision_3, recall_3, f1_3 = calculate_metrics(test_data_texts_3, test_data_labels, tokenizer_3, model_3, vocab_3)\n",
    "precision_4, recall_4, f1_4 = calculate_metrics(test_data_texts_4, test_data_labels, tokenizer_4, model_4, vocab_4)\n",
    "precision_5, recall_5, f1_5 = calculate_metrics(test_data_texts_5, test_data_labels, tokenizer_5, model_5, vocab_5)\n",
    "precision_6, recall_6, f1_6 = calculate_metrics(test_data_texts_6, test_data_labels, tokenizer_6, model_6, vocab_6)\n",
    "precision_7, recall_7, f1_7 = calculate_metrics(test_data_texts_7, test_data_labels, tokenizer_7, model_7, vocab_7)\n",
    "precision_8, recall_8, f1_8 = calculate_metrics(test_data_texts_8, test_data_labels, tokenizer_8, model_8, vocab_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "13d498be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Precision: 0.7608695652173914, Recall: 0.9790209790209791, F1-score: 0.8562691131498472 \n",
      " 2. Precision: 0.7540106951871658, Recall: 0.986013986013986, F1-score: 0.8545454545454545 \n",
      " 3. Precision: 0.7526595744680851, Recall: 0.9895104895104895, F1-score: 0.8549848942598186 \n",
      " 4. Precision: 0.7574931880108992, Recall: 0.972027972027972, F1-score: 0.8514548238897396 \n",
      " 5. Precision: 0.7613941018766756, Recall: 0.993006993006993, F1-score: 0.8619119878603945 \n",
      " 6. Precision: 0.7629427792915532, Recall: 0.9790209790209791, F1-score: 0.8575803981623277 \n",
      " 7. Precision: 0.7587131367292225, Recall: 0.9895104895104895, F1-score: 0.8588770864946889 \n",
      " 8. Precision: 0.75, Recall: 0.986013986013986, F1-score: 0.8519637462235651 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('1. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_1, recall_1, f1_1),\n",
    "     '2. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_2, recall_2, f1_2),\n",
    "     '3. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_3, recall_3, f1_3),\n",
    "     '4. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_4, recall_4, f1_4),\n",
    "     '5. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_5, recall_5, f1_5),\n",
    "     '6. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_6, recall_6, f1_6),\n",
    "     '7. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_7, recall_7, f1_7),\n",
    "     '8. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_8, recall_8, f1_8),)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
