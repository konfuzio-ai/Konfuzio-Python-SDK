{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db223561",
   "metadata": {},
   "source": [
    "# Training a CV model for correct first page prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8eb3a",
   "metadata": {},
   "source": [
    "This notebook covers one of the approaches to training a CV model for predicting whether a page of the document is the first one or not -- a feature that would allow correct splitting for PDFs that consist of more than one actual document (we assume that the pages are already sorted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4be7b3",
   "metadata": {},
   "source": [
    "Before you start, make sure you have **installed** and **initialized** the konfuzio_sdk package as shown in the readme of the [repository](https://github.com/konfuzio-ai/Python-SDK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konfuzio-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!konfuzio_sdk init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8520139",
   "metadata": {},
   "source": [
    "Importing necessary libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a292fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2   \n",
    "import keras\n",
    "import os\n",
    " \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from konfuzio_sdk.data import Project, Document\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c7440",
   "metadata": {},
   "source": [
    "Setting seed for reproducibility purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b241da",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03032a00",
   "metadata": {},
   "source": [
    "### Gathering and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361139c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project = Project(id_=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29dcd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = my_project.documents\n",
    "test_docs = my_project.test_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ddc79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in train_docs:\n",
    "    doc.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695951f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_paths = []\n",
    "\n",
    "for el in os.listdir('data_95/documents/'):\n",
    "    doc_paths.append('data_95/documents/' + el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b704c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_paths = []\n",
    "labels = []\n",
    "\n",
    "for path in doc_paths:\n",
    "    try:\n",
    "        for el in os.listdir(path + '/'):\n",
    "            if el.split('.')[-1] == 'png':\n",
    "                page_paths.append(path + '/' + el)\n",
    "                if el.split('.')[-2] == 'page_1':\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    except NotADirectoryError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f0fa1",
   "metadata": {},
   "source": [
    "Processing images from training and test sets with Otsu binarization and resizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd9c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 881/881 [00:13<00:00, 64.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(page_paths):\n",
    "    image = cv2.imread(img)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh1 = cv2.threshold(image, 120, 255, cv2.THRESH_BINARY + \n",
    "                                                cv2.THRESH_OTSU)\n",
    "    image = cv2.resize(thresh1, (224,224), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imwrite('otsued/train/{}'.format(img.split('/')[-2] + '_' +\n",
    "                                        img.split('/')[-1]), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f92ef26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in test_docs:\n",
    "    doc.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd4d8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = []\n",
    "\n",
    "for el in os.listdir('data_95/documents/'):\n",
    "    try:\n",
    "        if int(el) >= 7065 and int(el) <= 7127 :\n",
    "            test_paths.append('data_95/documents/' + el)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f04072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_paths = []\n",
    "labels = []\n",
    "\n",
    "for path in test_paths:\n",
    "    for el in os.listdir(path + '/'):\n",
    "        if el.split('.')[-1] == 'png':\n",
    "            page_paths.append(path + '/' + el)\n",
    "            if el.split('.')[-2] == 'page_1':\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63d34603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 235/235 [00:04<00:00, 55.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(page_paths):\n",
    "    image = cv2.imread(img)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh1 = cv2.threshold(image, 120, 255, cv2.THRESH_BINARY + \n",
    "                                                cv2.THRESH_OTSU)\n",
    "    image = cv2.resize(thresh1, (224,224), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imwrite('otsued/test/{}'.format(img.split('/')[-2] + '_' +\n",
    "                                        img.split('/')[-1]), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a887b51",
   "metadata": {},
   "source": [
    "Loading processed and sorted images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe910f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cj0jg6mjoxrP",
    "outputId": "c652070a-0fdb-4c17-ef29-2731a2f942b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 881 images belonging to 2 classes.\n",
      "Found 235 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory=\"drive/MyDrive/train\",target_size=(224,224))\n",
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(directory=\"drive/MyDrive/test\", target_size=(224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cac691a",
   "metadata": {},
   "source": [
    "Building VGG16 architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8de550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa00b1b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwMg3_x6zqhf",
    "outputId": "3dc1e5d6-e325-41e4-f4ec-f7cf25776fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3395f",
   "metadata": {},
   "source": [
    "Training the model with 100 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e50663",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlOQ5M8ZzsjY",
    "outputId": "8511482c-d264-43b4-8dee-41973efeeb12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28/100 [=======>......................] - ETA: 29s - loss: 0.6062 - accuracy: 0.7469 - precision: 0.7469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73191, saving model to vgg16_1.h5\n",
      "100/100 [==============================] - 19s 190ms/step - loss: 0.6062 - accuracy: 0.7469 - precision: 0.7469 - val_loss: 0.4786 - val_accuracy: 0.7319 - val_precision: 0.7319\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "hist = model.fit_generator(steps_per_epoch=100,generator=traindata, validation_data=testdata, \n",
    "                           validation_steps=10,epochs=100,callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205c118",
   "metadata": {
    "id": "gxXOBCdHu112"
   },
   "source": [
    "# Metrics & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd311f5",
   "metadata": {
    "id": "0n6wWJKyylkl"
   },
   "outputs": [],
   "source": [
    "saved_model = load_model(\"drive/MyDrive/model/vgg16_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ac13622",
   "metadata": {
    "id": "5saLVxk0u8Cy"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(paths, model):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for path in tqdm(paths):\n",
    "        if 'not_first_page' in path:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        img = image.load_img(path,target_size=(224,224))\n",
    "        img = np.asarray(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        output = saved_model.predict(img)\n",
    "\n",
    "        if output[0][0] > output[0][1]:\n",
    "            pred = 0\n",
    "        else:\n",
    "            pred = 1\n",
    "\n",
    "        if label == 1 and pred == 1:\n",
    "            true_positive += 1\n",
    "        elif label == 1 and pred == 0:\n",
    "            false_negative += 1\n",
    "        elif label == 0 and pred == 1:\n",
    "            false_positive += 1\n",
    "    \n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if precision + recall != 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dde6a001",
   "metadata": {
    "id": "yP87_GD0vEmd"
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "for el in os.listdir('drive/MyDrive/test/first_page'):\n",
    "    paths.append('drive/MyDrive/test/first_page/' + el)\n",
    "\n",
    "for el in os.listdir('drive/MyDrive/test/not_first_page'):\n",
    "    paths.append('drive/MyDrive/test/not_first_page/' + el)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0378a0bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1836SWNwuWPi",
    "outputId": "ba04ee1b-d982-4e40-e270-6615d2d0ca23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:14<00:00, 16.18it/s]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = calculate_metrics(paths, saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff756972",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_65E26Jg0bzo",
    "outputId": "5641a45e-d493-4d95-be7a-b702b13420c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Precision: 0.2680851063829787 \n",
      " Recall: 1.0 \n",
      " F1 score: 0.4228187919463087\n"
     ]
    }
   ],
   "source": [
    "print('\\n Precision: {} \\n Recall: {} \\n F1 score: {}'.format(precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
