{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26bc1e0",
   "metadata": {},
   "source": [
    "# Training a model for correct first-page prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dab5a",
   "metadata": {
    "id": "UPNlAXhiI3mR"
   },
   "source": [
    "This notebook covers two approaches to training a model for predicting whether a page of the document is the first one or not -- a feature that would allow correct splitting for PDFs that consist of more than one actual document (we assume that the pages are already sorted). The first approach used is NBOW (Neural Bag-of-words) and the second is fine-tuning Transformers model (BERT) with our document-related dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a8d38",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating project and prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4557e0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is an extract from [this](https://help.konfuzio.com/tutorials/quickstart/index.html) video tutorial. For more detailed information address it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4e53c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To create a project, go to the main server page and press \"Create a project\". Give it a name and save it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5695ad3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before adding any documents, we need to create labels for future annotations. They can include any type of information that is to be extracted from the documents, i.e. \"Total\", \"Description\", \"Net sum\". \n",
    "\n",
    "To create a label, go to Home > Labels > + Add. \n",
    "\n",
    "Each label has to be named; it also has the tickbox \"Multiple\" allowing for it occuring in the document more than once. \n",
    "\n",
    "Threshold allows setting a minimal level of confidence (model's prediction accuracy – how sure the model is about the label) for putting a label — for example, 0.1 threshold means the label will only be assigned if model has 10 or more percents of confidence about this label. \n",
    "\n",
    "Data type allows to choose what type of information will be under the label, i.e. text, percentage.\n",
    "\n",
    "After filling all the necessary fields, save the label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb8420",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Labels are grouped into label sets. We need to create at least one label set because labels have to be assigned one.  \n",
    "\n",
    "To create a label set, go to Home > Label sets > + Add; you can also use an automatically made set that has a name similar to that of the project. \n",
    "\n",
    "After creating or selecting a label set, add all the necessary labels in it.\n",
    "\n",
    "If you create a new label set, you also need to assign it a category.\n",
    "\n",
    "After all changes, save the resulting set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98083b2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Uploading the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c2f8e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ideally, to build a dataset you will need at least a hundred of documents. The training and testing shares can be divided as 80%/20%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c18e0f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All the documents must fit a certain set of requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134a12d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- each document has to contain only one unit (i.e. no multiple documents scanned as a single file);\n",
    "- if document's length is more than one page, the pages have to be sorted or at least the ground-truth first page should go first;\n",
    "- the formats supported are PNG and PDF;\n",
    "- each document has to be ascribed a certain category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194c015",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Preferably, a balanced dataset would contain not only single-page documents, but also multiple-paged ones in an equal amount; category-based splitting should also be balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d36e6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To add documents, go to the Documents page and add all the necessary files. \n",
    "\n",
    "Documents need to be categorized; for that, go to Home > Categories and add all the categories you deem necessary. After, it is possible to change the category in the Documents page in a similarly-named column, if it has not already been predicted by AI.\n",
    "\n",
    "After that it is possible to open any of the documents in the smartview by clicking on the title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9c4e5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When you have finished processing all the documents, go to the project's page and note the ID: we will have to use it for accessing the data later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9363a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports and initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98797d",
   "metadata": {
    "hidden": true,
    "id": "dzWYMYE1JLam"
   },
   "source": [
    "Before you start, make sure you have **installed** and **initialized** the konfuzio_sdk package as shown in the readme of the [repository](https://github.com/konfuzio-ai/Python-SDK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72820f33",
   "metadata": {
    "hidden": true,
    "id": "yBKvWHmiJOdm"
   },
   "outputs": [],
   "source": [
    "!pip install konfuzio-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d17e73e",
   "metadata": {
    "hidden": true,
    "id": "r6bvl5RFJO9Y"
   },
   "outputs": [],
   "source": [
    "!konfuzio_sdk init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d536a",
   "metadata": {
    "hidden": true,
    "id": "vfLGEvXNJQM0"
   },
   "source": [
    "Also, you will need to install the Transformers-related packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580f7eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "AxqhNEq8aBG2",
    "outputId": "a16fb525-81a7-40ed-8dba-2295cc62d6fb"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cfce81",
   "metadata": {
    "hidden": true,
    "id": "uR4TVAnuJYKU"
   },
   "source": [
    "Importing necessary libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207f69ba",
   "metadata": {
    "hidden": true,
    "id": "hWZq-frvabAx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from datasets import load_dataset, load_metric\n",
    "from nltk import word_tokenize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from konfuzio_sdk.data import Project, Document\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification, AutoConfig, \\\n",
    "                        TrainingArguments, DataCollatorWithPadding, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6361ebf",
   "metadata": {
    "hidden": true,
    "id": "WmIxwFwKJegG"
   },
   "source": [
    "Setting seed for reproducibility purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cf736e",
   "metadata": {
    "hidden": true,
    "id": "q9lVQ3l4Jgk5"
   },
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4191acb8",
   "metadata": {
    "hidden": true,
    "id": "6ccL1ffIKBgz"
   },
   "source": [
    "Initializing the config file, model and the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aacb040",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "configuration = AutoConfig.from_pretrained('bert-base-uncased')\n",
    "configuration.num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64059fb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "703a91b58e524ce79b02ed6d09e93c92",
      "52cb077c47124128869bdf173605f774",
      "d03c7d28190a44f38fdcdf2945da51be",
      "5f8b02046f0144b692d2c6b5e134d884",
      "9159ee7cdd6d4eb7ab152258a1411087",
      "b9447ac83ce84b9485e6b2faa22948b0",
      "10238b09b02344028a79fc09a8d36497",
      "049d227aedd84a7b9ba4a9b08b9e169d",
      "7b7928d079b7415192583666ea87ca7a",
      "c64d7347add042f2a12a0f8761a2198e",
      "ae69638d91c34cb78fb03c1bdb4f2fa3",
      "4ff99f04785e4d66a71cfc71bf633797",
      "5f5f4ada9a224e62b2886627c169a6f3",
      "28a9efe5ddbf44c2ad5ad5b9b383c7ad",
      "1ed98e0ef8444a5cac3e10e09cba1d94",
      "97f34467d18943a6916f94ff1dfe7b02",
      "d4bc780bf0a449379d85ad7d13cd5e07",
      "1c21f1cbe1c748029f898d70262ea277",
      "f57906f198ed472b998a86c52b79ab34",
      "d8b03d9988cf428ba4123eab941ac52f",
      "e729c2b2998f4651b07fefffa0e4bf24",
      "70cb2ccaec9048159209f95466e50ac8",
      "b3156f6b7b964944b636b31135adf3d2",
      "d6d7c4b37dc4488294be2b46a043bf96",
      "04a0d51b95174217892a464766c194f2",
      "26b0127bd6dc4aec99e6bb5bff5e654b",
      "22437f1fbfa94b1e9bfd3055ad825c18",
      "fbe38d4ad2af487e99f9d32c32d41b91",
      "66aa6630b3c6435ab8a812b68078b8fa",
      "fd4b0621669a4d9193f3d3c5fa86d3e1",
      "2d68ebd22b1547d1973d2dfc0399ba4c",
      "d3a8ae3670654ba796a671ea684c6613",
      "6989f37f90ee409782992e0eaaf7f315"
     ]
    },
    "hidden": true,
    "id": "jQbQUZ8babiZ",
    "outputId": "ddd8c47b-efc5-4394-9baa-172f4455cd88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', config=configuration)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, max_length=10000, \n",
    "                                          padding=\"max_length\", truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73581a02",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579d2b6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Loading our project for training and testing purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1de0f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_project = Project(id_=1644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02180ef0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data = my_project.documents\n",
    "test_data = my_project.test_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f195fd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Preparing data for training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1488016b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1443/1443 [00:02<00:00, 683.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_texts = []\n",
    "train_data_labels = []\n",
    "\n",
    "for doc in tqdm(train_data):\n",
    "    for page in doc.pages():\n",
    "        train_data_texts.append(page.text)\n",
    "        if page.number == 1:\n",
    "            train_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            train_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ebf15a",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 286/286 [00:00<00:00, 696.91it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_texts = []\n",
    "test_data_labels = []\n",
    "\n",
    "for doc in tqdm(test_data):\n",
    "    for page in doc.pages():\n",
    "        test_data_texts.append(page.text)\n",
    "        if page.number == 1:\n",
    "            test_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            test_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e752b86",
   "metadata": {},
   "source": [
    "## NBOW approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d777b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### No preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03364ea3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Initializing and building the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c24fa29",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32592b13",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2634/2634 [00:07<00:00, 361.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm(train_data_texts):\n",
    "    tokens = word_tokenize(text)\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c77e4b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Intializing and fitting the tokenizer for subsequent applying at the training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a0d5b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97812f93",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_data_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328089a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2634, 49404)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = tokenizer.texts_to_matrix(train_data_texts, mode='freq')\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df45169",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 49404)\n"
     ]
    }
   ],
   "source": [
    "Xtest = tokenizer.texts_to_matrix(test_data_texts, mode='freq')\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f3651",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Processing the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d420ac33",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ytrain = np.array(train_data_labels)\n",
    "ytest = np.array(test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "041e4cb1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_words = Xtest.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8bbc0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The architecture is Keras's Sequential with two Dense layers. The training runs for 50 epochs; chosen metric is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b9c57e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 14:24:15.461986: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5283 - accuracy: 0.7388 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.2112 - accuracy: 0.9127 - 898ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0762 - accuracy: 0.9749 - 1s/epoch - 13ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0335 - accuracy: 0.9913 - 917ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0249 - accuracy: 0.9916 - 914ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0204 - accuracy: 0.9939 - 924ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0156 - accuracy: 0.9943 - 1s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0157 - accuracy: 0.9932 - 996ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0131 - accuracy: 0.9954 - 935ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0138 - accuracy: 0.9947 - 1s/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0121 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9951 - 963ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 999ms/epoch - 12ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9954 - 998ms/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9962 - 967ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9970 - 955ms/epoch - 12ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9958 - 962ms/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0132 - accuracy: 0.9954 - 938ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0159 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9973 - 1s/epoch - 18ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9970 - 1s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9954 - 989ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9966 - 976ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9951 - 968ms/epoch - 12ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9958 - 976ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 955ms/epoch - 12ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9958 - 987ms/epoch - 12ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9973 - 993ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 2s - loss: 0.0068 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 2s - loss: 0.0065 - accuracy: 0.9981 - 2s/epoch - 20ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9970 - 1s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9981 - 1s/epoch - 13ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9973 - 1s/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9970 - 1s/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9973 - 1s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9977 - 1s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 2s - loss: 0.0062 - accuracy: 0.9973 - 2s/epoch - 19ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 2s - loss: 0.0050 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 2s - loss: 0.0073 - accuracy: 0.9977 - 2s/epoch - 21ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 2s - loss: 0.0064 - accuracy: 0.9970 - 2s/epoch - 27ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9966 - 2s/epoch - 21ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 2s - loss: 0.0054 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 2s - loss: 0.0061 - accuracy: 0.9973 - 2s/epoch - 23ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9977 - 1s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9973 - 1s/epoch - 18ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 2s - loss: 0.0051 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 2s - loss: 0.0044 - accuracy: 0.9981 - 2s/epoch - 20ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 2s - loss: 0.0076 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 2s - loss: 0.0058 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9973 - 2s/epoch - 23ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 2s - loss: 0.0055 - accuracy: 0.9973 - 2s/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9970 - 2s/epoch - 24ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 2s - loss: 0.0055 - accuracy: 0.9977 - 2s/epoch - 24ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 2s - loss: 0.0066 - accuracy: 0.9966 - 2s/epoch - 22ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 2s - loss: 0.0053 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9970 - 2s/epoch - 24ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9981 - 1s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 2s - loss: 0.0055 - accuracy: 0.9973 - 2s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 2s - loss: 0.0061 - accuracy: 0.9962 - 2s/epoch - 18ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feeeb2a9c40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xtrain, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e5b97",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's save our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba012b51",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save('NBOW.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795753a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 13:45:12.881055: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('NBOW.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f6832",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's evaluate the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b102495",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0b972",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3da44cd2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.85057330131531\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc624dc8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A function for running predictions manually consists of pre-filtering with the usage of previously built vocabulary and the prediction on the remaining tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f2a7082",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict_label(page_text, vocab, tokenizer, model):\n",
    "    tokens = word_tokenize(page_text)\n",
    "    tokens = [t for t in tokens if t in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    pred = model.predict(encoded, verbose=0)\n",
    "    return round(pred[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d570e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We calculate our custom metric via the following function that determines how many ground-truth first pages were actually predicted as first pages. The logic behind this approach suggests that by determining first pages correctly we can consecutively split documents correctly, using each first page as a separator (since it means a start of a new document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83846d1d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(texts, labels):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for i, test in tqdm(zip(labels, texts)):\n",
    "        pred = predict_label(test, vocab, tokenizer, model)\n",
    "        if i == 1 and pred == 1:\n",
    "            true_positive += 1\n",
    "        elif i == 1 and pred == 0:\n",
    "            false_negative += 1\n",
    "        elif i == 0 and pred == 1:\n",
    "            false_positive += 1\n",
    "    \n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if precision + recall != 0:\n",
    "    \n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        f1 = 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9a817",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "precision, recall, f1 = calculate_metrics(test_data_texts, test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fae37a4",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Precision: 0.7642276422764228 \n",
      " Recall: 0.986013986013986 \n",
      " F1-score: 0.8610687022900764\n"
     ]
    }
   ],
   "source": [
    "print('\\n Precision: {} \\n Recall: {} \\n F1-score: {}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414e8c2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Manual assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef74a085",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for test in test_data_texts[:10]: \n",
    "    print(predict_label(test, vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3acd7490",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26cc242",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The results for the manual assessment prove to be similar to the evaluation given previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a05a65",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us make some visualizations to ensure the manually-run predictions are correct as well.\n",
    "First, let's take a look at a single-page document which is the first in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f19c0ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document 32.pdf (334665)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373604a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since it's a single-page document, it only has the first page, and it was predicted as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db0bc375",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 1 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[0] , \", prediction:\", predict_label(test_data_texts[0], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920220e7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we'll take a look at a two-page document which is also present in the test set. Its first page should be predicted to be the first (receive label 1) , and the second one should be predicted as not first (receive label 0), and it has been predicted as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "beacb10e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 1 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[7] , \", prediction:\", predict_label(test_data_texts[7], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b7a3787",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 0 , prediction: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[8] , \", prediction:\", predict_label(test_data_texts[8], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab95f92",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Not all the pages get predicted correctly. Let's take a look at the three-page document that got 2 non-first pages predicted as first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b92b8d26",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 1 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[28] , \", prediction:\", predict_label(test_data_texts[28], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "974923e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_1 = my_project.get_document_by_id(334946).pages()[0].image_path\n",
    "path_2 = my_project.get_document_by_id(334946).pages()[1].image_path\n",
    "path_3 = my_project.get_document_by_id(334946).pages()[2].image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab8456d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following page gets predicted incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afbf6c83",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 0 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[29] , \", prediction:\", predict_label(test_data_texts[29], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38418c70",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The third page also gets an incorrect prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d8d7575",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original label: 0 , prediction: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"original label:\", test_data_labels[30] , \", prediction:\", predict_label(test_data_texts[30], vocab, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340d281",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Various preprocessing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48936c05",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In order to possibly enhance the results, let's try several preprocessing approaches for the texts. There will be eight of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec49cb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0957de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punctuation(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0147e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation and non-alphabetical tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0147f023",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punct_alpha(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49112c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation, non-alphabetical tokens, and 1-character-long tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6abe0e56",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punct_alpha_len(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7bf59",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation, non-alphabetical tokens, 1-character-long tokens, and stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc6e142",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punct_alpha_len_sw(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3635b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation and stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c86108b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punct_sw(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a1ada",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation, 1-character-long tokens, and stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "409b71a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punct_len_sw(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d2d39",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation, 1-character-long tokens, stopwords, and numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33282af6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punct_len_sw_nums(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = [w for w in tokens if not w.isnumeric()]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b318662",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Removal of punctuation, 1-character-long tokens, stopwords, and dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e01b1e05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess_punct_len_sw_dates(text):\n",
    "    text = re.sub(r\"[0-9]{1,4}[\\_|\\-|\\/|\\|\\.][0-9]{1,2}[\\_|\\-|\\/|\\|\\.][0-9]{1,4}\", '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a1065",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For each of the approaches, we will need a separate train and test set, a vocabulary and a tokenizer fit specifically on this set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32599e92",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1443/1443 [00:59<00:00, 24.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_texts_1 = []\n",
    "train_data_labels = []\n",
    "\n",
    "train_data_texts_2 = []\n",
    "train_data_texts_3 = []\n",
    "train_data_texts_4 = []\n",
    "train_data_texts_5 = []\n",
    "train_data_texts_6 = []\n",
    "train_data_texts_7 = []\n",
    "train_data_texts_8 = []\n",
    "\n",
    "\n",
    "for doc in tqdm(train_data):\n",
    "    for page in doc.pages():\n",
    "        train_data_texts_1.append(page.text)\n",
    "        train_data_texts_2.append(preprocess_punctuation(page.text))\n",
    "        train_data_texts_3.append(preprocess_punct_alpha(page.text))\n",
    "        train_data_texts_4.append(preprocess_punct_alpha_len(page.text))\n",
    "        train_data_texts_5.append(preprocess_punct_sw(page.text))\n",
    "        train_data_texts_6.append(preprocess_punct_len_sw(page.text))\n",
    "        train_data_texts_7.append(preprocess_punct_len_sw_nums(page.text))\n",
    "        train_data_texts_8.append(preprocess_punct_len_sw_dates(page.text))\n",
    "        if page.number == 1:\n",
    "            train_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            train_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4f4e86",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 286/286 [00:08<00:00, 32.41it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_texts_1 = []\n",
    "test_data_labels = []\n",
    "\n",
    "test_data_texts_2 = []\n",
    "test_data_texts_3 = []\n",
    "test_data_texts_4 = []\n",
    "test_data_texts_5 = []\n",
    "test_data_texts_6 = []\n",
    "test_data_texts_7 = []\n",
    "test_data_texts_8 = []\n",
    "\n",
    "for doc in tqdm(test_data):\n",
    "    for page in doc.pages():\n",
    "        test_data_texts_1.append(page.text)\n",
    "        test_data_texts_2.append(preprocess_punctuation(page.text))\n",
    "        test_data_texts_3.append(preprocess_punct_alpha(page.text))\n",
    "        test_data_texts_4.append(preprocess_punct_alpha_len(page.text))\n",
    "        test_data_texts_5.append(preprocess_punct_sw(page.text))\n",
    "        test_data_texts_6.append(preprocess_punct_len_sw(page.text))\n",
    "        test_data_texts_7.append(preprocess_punct_len_sw_nums(page.text))\n",
    "        test_data_texts_8.append(preprocess_punct_len_sw_dates(page.text))\n",
    "        if page.number == 1:\n",
    "            test_data_labels.append(1)\n",
    "        elif page.number != 1 and int(page.number):\n",
    "            test_data_labels.append(0)\n",
    "        else:\n",
    "            print(page.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccee523e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab_1 = Counter()\n",
    "vocab_2 = Counter()\n",
    "vocab_3 = Counter()\n",
    "vocab_4 = Counter()\n",
    "vocab_5 = Counter()\n",
    "vocab_6 = Counter()\n",
    "vocab_7 = Counter()\n",
    "vocab_8 = Counter()\n",
    "\n",
    "vocab = [vocab_1, vocab_2, vocab_3, vocab_4, vocab_5, vocab_6, vocab_7, vocab_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48ae2a0c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = [train_data_texts_1, train_data_texts_2, train_data_texts_3, train_data_texts_4,\n",
    "        train_data_texts_5, train_data_texts_6, train_data_texts_7, train_data_texts_8]\n",
    "\n",
    "for t, v in zip(train, vocab):\n",
    "    for text in t:\n",
    "        tokens = word_tokenize(text)\n",
    "        v.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ec1f9d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer_1 = Tokenizer()\n",
    "tokenizer_2 = Tokenizer()\n",
    "tokenizer_3 = Tokenizer()\n",
    "tokenizer_4 = Tokenizer()\n",
    "tokenizer_5 = Tokenizer()\n",
    "tokenizer_6 = Tokenizer()\n",
    "tokenizer_7 = Tokenizer()\n",
    "tokenizer_8 = Tokenizer()\n",
    "\n",
    "tokenizer = [tokenizer_1, tokenizer_2, tokenizer_3, tokenizer_4, tokenizer_5, tokenizer_6, tokenizer_7,\n",
    "            tokenizer_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c063d11e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer_1.fit_on_texts(train_data_texts_1)\n",
    "tokenizer_2.fit_on_texts(train_data_texts_2)\n",
    "tokenizer_3.fit_on_texts(train_data_texts_3)\n",
    "tokenizer_4.fit_on_texts(train_data_texts_4)\n",
    "tokenizer_5.fit_on_texts(train_data_texts_5)\n",
    "tokenizer_6.fit_on_texts(train_data_texts_6)\n",
    "tokenizer_7.fit_on_texts(train_data_texts_7)\n",
    "tokenizer_8.fit_on_texts(train_data_texts_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9b5d716",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xtrain_1 = tokenizer_1.texts_to_matrix(train_data_texts_1, mode='freq')\n",
    "Xtrain_2 = tokenizer_2.texts_to_matrix(train_data_texts_2, mode='freq')\n",
    "Xtrain_3 = tokenizer_3.texts_to_matrix(train_data_texts_3, mode='freq')\n",
    "Xtrain_4 = tokenizer_4.texts_to_matrix(train_data_texts_4, mode='freq')\n",
    "Xtrain_5 = tokenizer_5.texts_to_matrix(train_data_texts_5, mode='freq')\n",
    "Xtrain_6 = tokenizer_6.texts_to_matrix(train_data_texts_6, mode='freq')\n",
    "Xtrain_7 = tokenizer_7.texts_to_matrix(train_data_texts_7, mode='freq')\n",
    "Xtrain_8 = tokenizer_8.texts_to_matrix(train_data_texts_8, mode='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d846d7e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xtest_1 = tokenizer_1.texts_to_matrix(test_data_texts_1, mode='freq')\n",
    "Xtest_2 = tokenizer_2.texts_to_matrix(test_data_texts_2, mode='freq')\n",
    "Xtest_3 = tokenizer_3.texts_to_matrix(test_data_texts_3, mode='freq')\n",
    "Xtest_4 = tokenizer_4.texts_to_matrix(test_data_texts_4, mode='freq')\n",
    "Xtest_5 = tokenizer_5.texts_to_matrix(test_data_texts_5, mode='freq')\n",
    "Xtest_6 = tokenizer_6.texts_to_matrix(test_data_texts_6, mode='freq')\n",
    "Xtest_7 = tokenizer_7.texts_to_matrix(test_data_texts_7, mode='freq')\n",
    "Xtest_8 = tokenizer_8.texts_to_matrix(test_data_texts_8, mode='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8013a03d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ytrain = np.array(train_data_labels)\n",
    "ytest = np.array(test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a85919a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_words_1 = Xtest_1.shape[1]\n",
    "n_words_2 = Xtest_2.shape[1]\n",
    "n_words_3 = Xtest_3.shape[1]\n",
    "n_words_4 = Xtest_4.shape[1]\n",
    "n_words_5 = Xtest_5.shape[1]\n",
    "n_words_6 = Xtest_6.shape[1]\n",
    "n_words_7 = Xtest_7.shape[1]\n",
    "n_words_8 = Xtest_8.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54658072",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fitting the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ad58df2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5130 - accuracy: 0.7574 - 2s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.2018 - accuracy: 0.9172 - 924ms/epoch - 11ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0765 - accuracy: 0.9742 - 836ms/epoch - 10ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0368 - accuracy: 0.9882 - 936ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0222 - accuracy: 0.9916 - 979ms/epoch - 12ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0190 - accuracy: 0.9928 - 865ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0154 - accuracy: 0.9943 - 952ms/epoch - 11ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0202 - accuracy: 0.9924 - 897ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9962 - 924ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9935 - 859ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0125 - accuracy: 0.9958 - 879ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9954 - 870ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0135 - accuracy: 0.9947 - 873ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0114 - accuracy: 0.9958 - 872ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9966 - 875ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9970 - 899ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 885ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9962 - 872ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9958 - 952ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0125 - accuracy: 0.9947 - 927ms/epoch - 11ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0104 - accuracy: 0.9970 - 891ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9962 - 891ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9973 - 884ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9951 - 861ms/epoch - 10ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9970 - 950ms/epoch - 11ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9951 - 1s/epoch - 12ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9966 - 948ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9954 - 910ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9962 - 888ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9962 - 890ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 841ms/epoch - 10ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9970 - 902ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9947 - 997ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 983ms/epoch - 12ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9970 - 910ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0109 - accuracy: 0.9954 - 982ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 895ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9954 - 890ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9981 - 904ms/epoch - 11ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0104 - accuracy: 0.9970 - 918ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9966 - 946ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9958 - 896ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9966 - 877ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9951 - 896ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9981 - 885ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9973 - 894ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9954 - 904ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9973 - 936ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9970 - 905ms/epoch - 11ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 881ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9970 - 922ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9966 - 927ms/epoch - 11ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9970 - 893ms/epoch - 11ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9958 - 892ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9954 - 878ms/epoch - 11ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 881ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9954 - 890ms/epoch - 11ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9970 - 893ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9977 - 906ms/epoch - 11ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 902ms/epoch - 11ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 871ms/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9966 - 870ms/epoch - 10ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9973 - 891ms/epoch - 11ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0050 - accuracy: 0.9970 - 964ms/epoch - 12ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 943ms/epoch - 11ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9970 - 915ms/epoch - 11ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9981 - 927ms/epoch - 11ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9970 - 931ms/epoch - 11ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9970 - 917ms/epoch - 11ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 886ms/epoch - 11ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 933ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9962 - 908ms/epoch - 11ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9962 - 880ms/epoch - 11ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9962 - 888ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9973 - 897ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9977 - 896ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9973 - 878ms/epoch - 11ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 935ms/epoch - 11ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9962 - 932ms/epoch - 11ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9970 - 910ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9970 - 933ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9962 - 954ms/epoch - 11ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0036 - accuracy: 0.9985 - 922ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9977 - 915ms/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9966 - 968ms/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9977 - 967ms/epoch - 12ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0050 - accuracy: 0.9970 - 930ms/epoch - 11ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9977 - 1s/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0049 - accuracy: 0.9966 - 936ms/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9970 - 937ms/epoch - 11ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9962 - 975ms/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 965ms/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9958 - 934ms/epoch - 11ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d2ed56fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(50, input_shape=(n_words_1,), activation='relu'))\n",
    "model_1.add(Dense(50, activation='elu'))\n",
    "model_1.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(Xtrain_1, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0978999",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5301 - accuracy: 0.7373 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1955 - accuracy: 0.9203 - 1s/epoch - 14ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0647 - accuracy: 0.9822 - 1s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0266 - accuracy: 0.9920 - 1s/epoch - 14ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0157 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0143 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0175 - accuracy: 0.9939 - 1s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0123 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0119 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0145 - accuracy: 0.9943 - 1s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9985 - 1s/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 2s - loss: 0.0083 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0046 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 2s - loss: 0.0072 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9977 - 1s/epoch - 13ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 2s - loss: 0.0067 - accuracy: 0.9970 - 2s/epoch - 21ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 2s - loss: 0.0069 - accuracy: 0.9977 - 2s/epoch - 21ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 2s - loss: 0.0074 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9973 - 1s/epoch - 17ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9966 - 1s/epoch - 18ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9973 - 1s/epoch - 17ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9977 - 1s/epoch - 18ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 2s - loss: 0.0053 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9970 - 1s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0049 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9cf55e2be0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(50, input_shape=(n_words_2,), activation='relu'))\n",
    "model_2.add(Dense(50, activation='elu'))\n",
    "model_2.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(Xtrain_2, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6abc3e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 1s - loss: 0.5369 - accuracy: 0.7267 - 1s/epoch - 15ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.2024 - accuracy: 0.9241 - 625ms/epoch - 8ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0771 - accuracy: 0.9768 - 623ms/epoch - 8ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0396 - accuracy: 0.9894 - 623ms/epoch - 8ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0263 - accuracy: 0.9913 - 655ms/epoch - 8ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0188 - accuracy: 0.9939 - 671ms/epoch - 8ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0160 - accuracy: 0.9924 - 798ms/epoch - 10ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0223 - accuracy: 0.9928 - 641ms/epoch - 8ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9970 - 651ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0170 - accuracy: 0.9935 - 755ms/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0134 - accuracy: 0.9951 - 644ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9954 - 652ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9954 - 757ms/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9954 - 659ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9958 - 656ms/epoch - 8ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9951 - 659ms/epoch - 8ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9962 - 643ms/epoch - 8ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0154 - accuracy: 0.9943 - 631ms/epoch - 8ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9958 - 638ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9962 - 700ms/epoch - 8ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9962 - 631ms/epoch - 8ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9962 - 645ms/epoch - 8ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 717ms/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9977 - 670ms/epoch - 8ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9966 - 753ms/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9970 - 744ms/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0092 - accuracy: 0.9966 - 641ms/epoch - 8ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0102 - accuracy: 0.9958 - 637ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9970 - 639ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9966 - 634ms/epoch - 8ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 688ms/epoch - 8ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9973 - 692ms/epoch - 8ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0131 - accuracy: 0.9947 - 685ms/epoch - 8ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9977 - 694ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9966 - 690ms/epoch - 8ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 704ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 883ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9947 - 986ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 963ms/epoch - 12ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9970 - 958ms/epoch - 12ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 922ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9970 - 803ms/epoch - 10ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9970 - 788ms/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9970 - 784ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9973 - 700ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 705ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9958 - 702ms/epoch - 8ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9977 - 705ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9966 - 681ms/epoch - 8ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 715ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9962 - 900ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9973 - 1s/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9966 - 945ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9970 - 875ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 966ms/epoch - 12ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0047 - accuracy: 0.9981 - 769ms/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 756ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9973 - 835ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9958 - 718ms/epoch - 9ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9962 - 803ms/epoch - 10ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 708ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9962 - 706ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9977 - 836ms/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9954 - 784ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9962 - 757ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9958 - 771ms/epoch - 9ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9970 - 742ms/epoch - 9ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9973 - 1s/epoch - 13ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9962 - 811ms/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9962 - 785ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9973 - 741ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 827ms/epoch - 10ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9962 - 882ms/epoch - 11ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9966 - 790ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9973 - 863ms/epoch - 10ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9977 - 940ms/epoch - 11ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0039 - accuracy: 0.9973 - 711ms/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9977 - 886ms/epoch - 11ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9981 - 722ms/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9966 - 736ms/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 713ms/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 745ms/epoch - 9ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9966 - 754ms/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 689ms/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9970 - 705ms/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9954 - 688ms/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9973 - 662ms/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 681ms/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9958 - 749ms/epoch - 9ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9962 - 682ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 701ms/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9966 - 716ms/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 686ms/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 751ms/epoch - 9ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9962 - 760ms/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9970 - 783ms/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0047 - accuracy: 0.9973 - 788ms/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ccb06e6a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(50, input_shape=(n_words_3,), activation='relu'))\n",
    "model_3.add(Dense(50, activation='elu'))\n",
    "model_3.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_3.fit(Xtrain_3, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2b8a3da",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5189 - accuracy: 0.7426 - 2s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1915 - accuracy: 0.9233 - 736ms/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0773 - accuracy: 0.9711 - 707ms/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0397 - accuracy: 0.9886 - 800ms/epoch - 10ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0259 - accuracy: 0.9913 - 1s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0189 - accuracy: 0.9920 - 1s/epoch - 14ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0193 - accuracy: 0.9932 - 1s/epoch - 16ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 2s - loss: 0.0173 - accuracy: 0.9935 - 2s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 2s - loss: 0.0170 - accuracy: 0.9947 - 2s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 2s - loss: 0.0142 - accuracy: 0.9951 - 2s/epoch - 25ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 2s - loss: 0.0122 - accuracy: 0.9966 - 2s/epoch - 18ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0157 - accuracy: 0.9951 - 866ms/epoch - 10ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9947 - 870ms/epoch - 10ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0122 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0144 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9947 - 1s/epoch - 13ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9954 - 1s/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9947 - 1s/epoch - 16ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9954 - 983ms/epoch - 12ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0168 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 1s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9966 - 952ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0113 - accuracy: 0.9954 - 849ms/epoch - 10ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0134 - accuracy: 0.9951 - 738ms/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9951 - 752ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0104 - accuracy: 0.9962 - 797ms/epoch - 10ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9947 - 760ms/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0102 - accuracy: 0.9954 - 725ms/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0161 - accuracy: 0.9939 - 757ms/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9962 - 697ms/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9951 - 715ms/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0109 - accuracy: 0.9954 - 700ms/epoch - 8ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9970 - 720ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9962 - 714ms/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9970 - 713ms/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9966 - 687ms/epoch - 8ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0106 - accuracy: 0.9958 - 693ms/epoch - 8ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9951 - 701ms/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9958 - 704ms/epoch - 8ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 713ms/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 702ms/epoch - 8ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9970 - 678ms/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9947 - 746ms/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 738ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 742ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9954 - 951ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9954 - 842ms/epoch - 10ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9951 - 726ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9954 - 719ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 865ms/epoch - 10ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9966 - 737ms/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9962 - 793ms/epoch - 10ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 886ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9962 - 829ms/epoch - 10ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 850ms/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 816ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9962 - 787ms/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9954 - 765ms/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9954 - 723ms/epoch - 9ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9947 - 766ms/epoch - 9ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9954 - 748ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9966 - 726ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 733ms/epoch - 9ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9954 - 846ms/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 802ms/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 759ms/epoch - 9ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9966 - 778ms/epoch - 9ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 737ms/epoch - 9ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 707ms/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 713ms/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 712ms/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9962 - 797ms/epoch - 10ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9958 - 769ms/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 788ms/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9966 - 775ms/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9954 - 788ms/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9943 - 738ms/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9962 - 676ms/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9958 - 696ms/epoch - 8ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9954 - 700ms/epoch - 8ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9958 - 872ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 889ms/epoch - 11ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9954 - 781ms/epoch - 9ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9962 - 715ms/epoch - 9ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9954 - 693ms/epoch - 8ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9962 - 658ms/epoch - 8ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9951 - 670ms/epoch - 8ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9962 - 653ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9958 - 665ms/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9954 - 742ms/epoch - 9ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 723ms/epoch - 9ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9970 - 743ms/epoch - 9ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9951 - 701ms/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9958 - 689ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9958 - 821ms/epoch - 10ms/step\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 812ms/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c9a7f3070>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(50, input_shape=(n_words_4,), activation='relu'))\n",
    "model_4.add(Dense(50, activation='elu'))\n",
    "model_4.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_4.fit(Xtrain_4, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a174c2a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5127 - accuracy: 0.7677 - 2s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1708 - accuracy: 0.9324 - 1s/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0598 - accuracy: 0.9814 - 1s/epoch - 14ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0269 - accuracy: 0.9920 - 1s/epoch - 15ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0154 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0148 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0135 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0115 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0130 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0098 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0118 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0050 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9977 - 1s/epoch - 16ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9970 - 1s/epoch - 17ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0042 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0057 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0049 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0052 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0045 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9977 - 1s/epoch - 14ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9973 - 1s/epoch - 14ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0054 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0056 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0045 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0048 - accuracy: 0.9981 - 1s/epoch - 15ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 2s - loss: 0.0046 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0051 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 2s - loss: 0.0049 - accuracy: 0.9977 - 2s/epoch - 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c7a6c2190>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Dense(50, input_shape=(n_words_5,), activation='relu'))\n",
    "model_5.add(Dense(50, activation='elu'))\n",
    "model_5.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_5.fit(Xtrain_5, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0705880a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5295 - accuracy: 0.7156 - 2s/epoch - 23ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1672 - accuracy: 0.9358 - 1s/epoch - 15ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0599 - accuracy: 0.9803 - 1s/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0258 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0199 - accuracy: 0.9935 - 1s/epoch - 17ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0143 - accuracy: 0.9962 - 1s/epoch - 17ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0136 - accuracy: 0.9947 - 1s/epoch - 17ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0124 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9970 - 1s/epoch - 16ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0140 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0117 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0109 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 2s - loss: 0.0149 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9947 - 1s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 2s - loss: 0.0124 - accuracy: 0.9951 - 2s/epoch - 18ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0100 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0130 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0121 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0089 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0107 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0082 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0114 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9939 - 1s/epoch - 14ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9947 - 1s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9977 - 1s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9966 - 1s/epoch - 18ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 2s - loss: 0.0063 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9954 - 1s/epoch - 18ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 2s - loss: 0.0069 - accuracy: 0.9954 - 2s/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 2s - loss: 0.0078 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9962 - 2s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 2s - loss: 0.0068 - accuracy: 0.9954 - 2s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0058 - accuracy: 0.9966 - 1s/epoch - 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c5af99f70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Dense(50, input_shape=(n_words_6,), activation='relu'))\n",
    "model_6.add(Dense(50, activation='elu'))\n",
    "model_6.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_6.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_6.fit(Xtrain_6, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6a9e17a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 2s - loss: 0.5140 - accuracy: 0.7677 - 2s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 1s - loss: 0.1807 - accuracy: 0.9256 - 982ms/epoch - 12ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 1s - loss: 0.0657 - accuracy: 0.9787 - 902ms/epoch - 11ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 1s - loss: 0.0361 - accuracy: 0.9879 - 903ms/epoch - 11ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 1s - loss: 0.0179 - accuracy: 0.9939 - 928ms/epoch - 11ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 1s - loss: 0.0197 - accuracy: 0.9947 - 922ms/epoch - 11ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9962 - 958ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 1s - loss: 0.0146 - accuracy: 0.9943 - 931ms/epoch - 11ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 1s - loss: 0.0142 - accuracy: 0.9947 - 917ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0127 - accuracy: 0.9958 - 963ms/epoch - 12ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 1s - loss: 0.0141 - accuracy: 0.9947 - 1s/epoch - 12ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0130 - accuracy: 0.9954 - 998ms/epoch - 12ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 1s - loss: 0.0120 - accuracy: 0.9954 - 908ms/epoch - 11ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0137 - accuracy: 0.9951 - 921ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0146 - accuracy: 0.9954 - 968ms/epoch - 12ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9947 - 951ms/epoch - 11ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0108 - accuracy: 0.9951 - 949ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9947 - 941ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9962 - 1s/epoch - 12ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 917ms/epoch - 11ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9958 - 918ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9954 - 919ms/epoch - 11ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 1s - loss: 0.0135 - accuracy: 0.9951 - 940ms/epoch - 11ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0102 - accuracy: 0.9954 - 980ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9958 - 938ms/epoch - 11ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 1s - loss: 0.0149 - accuracy: 0.9939 - 947ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 930ms/epoch - 11ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9943 - 931ms/epoch - 11ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9958 - 885ms/epoch - 11ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 954ms/epoch - 11ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9951 - 936ms/epoch - 11ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9962 - 928ms/epoch - 11ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9947 - 872ms/epoch - 11ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9958 - 876ms/epoch - 11ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9954 - 885ms/epoch - 11ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9962 - 904ms/epoch - 11ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9951 - 964ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9962 - 887ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9962 - 879ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9958 - 901ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 1s - loss: 0.0095 - accuracy: 0.9966 - 958ms/epoch - 12ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 1s - loss: 0.0099 - accuracy: 0.9947 - 1s/epoch - 12ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9951 - 996ms/epoch - 12ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9954 - 997ms/epoch - 12ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9954 - 1s/epoch - 12ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 1s - loss: 0.0096 - accuracy: 0.9954 - 946ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9962 - 937ms/epoch - 11ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9962 - 953ms/epoch - 11ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9951 - 970ms/epoch - 12ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9973 - 954ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9973 - 969ms/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9970 - 902ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9962 - 973ms/epoch - 12ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0085 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9973 - 977ms/epoch - 12ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0103 - accuracy: 0.9958 - 921ms/epoch - 11ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 978ms/epoch - 12ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9966 - 995ms/epoch - 12ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9966 - 1s/epoch - 13ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 2s - loss: 0.0078 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 2s - loss: 0.0070 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9947 - 1s/epoch - 13ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9951 - 1s/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9962 - 1s/epoch - 13ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0086 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9954 - 971ms/epoch - 12ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 960ms/epoch - 12ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9951 - 961ms/epoch - 12ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0076 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 1s/epoch - 12ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9970 - 1s/epoch - 13ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0075 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9958 - 1s/epoch - 16ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 991ms/epoch - 12ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9962 - 954ms/epoch - 11ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9954 - 977ms/epoch - 12ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0061 - accuracy: 0.9947 - 962ms/epoch - 12ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9958 - 1s/epoch - 13ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 2s - loss: 0.0063 - accuracy: 0.9970 - 2s/epoch - 20ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9958 - 1s/epoch - 12ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9954 - 951ms/epoch - 11ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9954 - 1s/epoch - 13ms/step\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c2d262af0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7 = Sequential()\n",
    "model_7.add(Dense(50, input_shape=(n_words_7,), activation='relu'))\n",
    "model_7.add(Dense(50, activation='elu'))\n",
    "model_7.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_7.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_7.fit(Xtrain_7, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27ca2539",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 - 3s - loss: 0.5153 - accuracy: 0.7673 - 3s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "83/83 - 2s - loss: 0.1653 - accuracy: 0.9362 - 2s/epoch - 23ms/step\n",
      "Epoch 3/100\n",
      "83/83 - 2s - loss: 0.0558 - accuracy: 0.9829 - 2s/epoch - 22ms/step\n",
      "Epoch 4/100\n",
      "83/83 - 2s - loss: 0.0230 - accuracy: 0.9928 - 2s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "83/83 - 2s - loss: 0.0162 - accuracy: 0.9951 - 2s/epoch - 22ms/step\n",
      "Epoch 6/100\n",
      "83/83 - 2s - loss: 0.0138 - accuracy: 0.9943 - 2s/epoch - 23ms/step\n",
      "Epoch 7/100\n",
      "83/83 - 2s - loss: 0.0122 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "83/83 - 2s - loss: 0.0109 - accuracy: 0.9973 - 2s/epoch - 22ms/step\n",
      "Epoch 9/100\n",
      "83/83 - 2s - loss: 0.0128 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "83/83 - 1s - loss: 0.0126 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "83/83 - 2s - loss: 0.0144 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "83/83 - 1s - loss: 0.0163 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 13/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 14/100\n",
      "83/83 - 2s - loss: 0.0131 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 16/100\n",
      "83/83 - 1s - loss: 0.0090 - accuracy: 0.9966 - 1s/epoch - 18ms/step\n",
      "Epoch 17/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9973 - 1s/epoch - 16ms/step\n",
      "Epoch 18/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 19/100\n",
      "83/83 - 2s - loss: 0.0087 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "83/83 - 1s - loss: 0.0112 - accuracy: 0.9958 - 1s/epoch - 18ms/step\n",
      "Epoch 21/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 22/100\n",
      "83/83 - 2s - loss: 0.0104 - accuracy: 0.9962 - 2s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "83/83 - 1s - loss: 0.0132 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 24/100\n",
      "83/83 - 2s - loss: 0.0083 - accuracy: 0.9966 - 2s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "83/83 - 1s - loss: 0.0097 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 26/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 27/100\n",
      "83/83 - 2s - loss: 0.0097 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 28/100\n",
      "83/83 - 2s - loss: 0.0084 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "83/83 - 1s - loss: 0.0105 - accuracy: 0.9966 - 1s/epoch - 17ms/step\n",
      "Epoch 30/100\n",
      "83/83 - 2s - loss: 0.0097 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "83/83 - 1s - loss: 0.0080 - accuracy: 0.9962 - 1s/epoch - 16ms/step\n",
      "Epoch 32/100\n",
      "83/83 - 2s - loss: 0.0077 - accuracy: 0.9962 - 2s/epoch - 20ms/step\n",
      "Epoch 33/100\n",
      "83/83 - 2s - loss: 0.0097 - accuracy: 0.9962 - 2s/epoch - 21ms/step\n",
      "Epoch 34/100\n",
      "83/83 - 2s - loss: 0.0122 - accuracy: 0.9951 - 2s/epoch - 21ms/step\n",
      "Epoch 35/100\n",
      "83/83 - 2s - loss: 0.0092 - accuracy: 0.9943 - 2s/epoch - 24ms/step\n",
      "Epoch 36/100\n",
      "83/83 - 2s - loss: 0.0094 - accuracy: 0.9954 - 2s/epoch - 19ms/step\n",
      "Epoch 37/100\n",
      "83/83 - 2s - loss: 0.0080 - accuracy: 0.9958 - 2s/epoch - 23ms/step\n",
      "Epoch 38/100\n",
      "83/83 - 2s - loss: 0.0099 - accuracy: 0.9970 - 2s/epoch - 19ms/step\n",
      "Epoch 39/100\n",
      "83/83 - 2s - loss: 0.0086 - accuracy: 0.9962 - 2s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "83/83 - 2s - loss: 0.0073 - accuracy: 0.9966 - 2s/epoch - 19ms/step\n",
      "Epoch 41/100\n",
      "83/83 - 2s - loss: 0.0087 - accuracy: 0.9970 - 2s/epoch - 22ms/step\n",
      "Epoch 42/100\n",
      "83/83 - 2s - loss: 0.0083 - accuracy: 0.9958 - 2s/epoch - 20ms/step\n",
      "Epoch 43/100\n",
      "83/83 - 2s - loss: 0.0095 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 44/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9947 - 1s/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "83/83 - 1s - loss: 0.0110 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 46/100\n",
      "83/83 - 1s - loss: 0.0111 - accuracy: 0.9962 - 1s/epoch - 17ms/step\n",
      "Epoch 47/100\n",
      "83/83 - 2s - loss: 0.0088 - accuracy: 0.9962 - 2s/epoch - 20ms/step\n",
      "Epoch 48/100\n",
      "83/83 - 1s - loss: 0.0116 - accuracy: 0.9970 - 1s/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "83/83 - 1s - loss: 0.0094 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 50/100\n",
      "83/83 - 1s - loss: 0.0088 - accuracy: 0.9951 - 1s/epoch - 16ms/step\n",
      "Epoch 51/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 52/100\n",
      "83/83 - 1s - loss: 0.0093 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 53/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9973 - 1s/epoch - 15ms/step\n",
      "Epoch 54/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 55/100\n",
      "83/83 - 1s - loss: 0.0072 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 56/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 57/100\n",
      "83/83 - 1s - loss: 0.0078 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 58/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 59/100\n",
      "83/83 - 1s - loss: 0.0083 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 60/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9947 - 1s/epoch - 15ms/step\n",
      "Epoch 61/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 62/100\n",
      "83/83 - 1s - loss: 0.0091 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 63/100\n",
      "83/83 - 1s - loss: 0.0081 - accuracy: 0.9951 - 1s/epoch - 15ms/step\n",
      "Epoch 64/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 65/100\n",
      "83/83 - 1s - loss: 0.0079 - accuracy: 0.9962 - 1s/epoch - 14ms/step\n",
      "Epoch 66/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 67/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 68/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "83/83 - 1s - loss: 0.0101 - accuracy: 0.9954 - 1s/epoch - 14ms/step\n",
      "Epoch 70/100\n",
      "83/83 - 1s - loss: 0.0073 - accuracy: 0.9954 - 1s/epoch - 15ms/step\n",
      "Epoch 71/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9951 - 1s/epoch - 14ms/step\n",
      "Epoch 72/100\n",
      "83/83 - 1s - loss: 0.0062 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 73/100\n",
      "83/83 - 1s - loss: 0.0070 - accuracy: 0.9954 - 1s/epoch - 16ms/step\n",
      "Epoch 74/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 75/100\n",
      "83/83 - 1s - loss: 0.0074 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 76/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 77/100\n",
      "83/83 - 1s - loss: 0.0071 - accuracy: 0.9962 - 1s/epoch - 15ms/step\n",
      "Epoch 78/100\n",
      "83/83 - 1s - loss: 0.0087 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 79/100\n",
      "83/83 - 1s - loss: 0.0068 - accuracy: 0.9966 - 1s/epoch - 14ms/step\n",
      "Epoch 80/100\n",
      "83/83 - 1s - loss: 0.0066 - accuracy: 0.9958 - 1s/epoch - 15ms/step\n",
      "Epoch 81/100\n",
      "83/83 - 1s - loss: 0.0077 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 82/100\n",
      "83/83 - 1s - loss: 0.0063 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 83/100\n",
      "83/83 - 1s - loss: 0.0084 - accuracy: 0.9966 - 1s/epoch - 15ms/step\n",
      "Epoch 84/100\n",
      "83/83 - 1s - loss: 0.0067 - accuracy: 0.9958 - 1s/epoch - 14ms/step\n",
      "Epoch 85/100\n",
      "83/83 - 1s - loss: 0.0064 - accuracy: 0.9970 - 1s/epoch - 14ms/step\n",
      "Epoch 86/100\n",
      "83/83 - 2s - loss: 0.0056 - accuracy: 0.9962 - 2s/epoch - 19ms/step\n",
      "Epoch 87/100\n",
      "83/83 - 1s - loss: 0.0059 - accuracy: 0.9962 - 1s/epoch - 18ms/step\n",
      "Epoch 88/100\n",
      "83/83 - 1s - loss: 0.0053 - accuracy: 0.9970 - 1s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "83/83 - 2s - loss: 0.0067 - accuracy: 0.9958 - 2s/epoch - 19ms/step\n",
      "Epoch 90/100\n",
      "83/83 - 1s - loss: 0.0065 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 91/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n",
      "Epoch 92/100\n",
      "83/83 - 2s - loss: 0.0061 - accuracy: 0.9954 - 2s/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "83/83 - 1s - loss: 0.0055 - accuracy: 0.9958 - 1s/epoch - 17ms/step\n",
      "Epoch 94/100\n",
      "83/83 - 2s - loss: 0.0067 - accuracy: 0.9951 - 2s/epoch - 19ms/step\n",
      "Epoch 95/100\n",
      "83/83 - 1s - loss: 0.0069 - accuracy: 0.9951 - 1s/epoch - 17ms/step\n",
      "Epoch 96/100\n",
      "83/83 - 2s - loss: 0.0057 - accuracy: 0.9954 - 2s/epoch - 18ms/step\n",
      "Epoch 97/100\n",
      "83/83 - 2s - loss: 0.0063 - accuracy: 0.9962 - 2s/epoch - 23ms/step\n",
      "Epoch 98/100\n",
      "83/83 - 2s - loss: 0.0056 - accuracy: 0.9954 - 2s/epoch - 22ms/step\n",
      "Epoch 99/100\n",
      "83/83 - 2s - loss: 0.0058 - accuracy: 0.9943 - 2s/epoch - 19ms/step\n",
      "Epoch 100/100\n",
      "83/83 - 1s - loss: 0.0060 - accuracy: 0.9954 - 1s/epoch - 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9bff539c70>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8 = Sequential()\n",
    "model_8.add(Dense(50, input_shape=(n_words_8,), activation='relu'))\n",
    "model_8.add(Dense(50, activation='elu'))\n",
    "model_8.add(Dense(50, activation='elu'))\n",
    "\n",
    "model_8.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_8.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_8.fit(Xtrain_8, ytrain, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42612943",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Evaluating our models' performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "240b1d68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_1, acc_1 = model_1.evaluate(Xtest_1, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4da3e36",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_2, acc_2 = model_2.evaluate(Xtest_2, ytest, verbose=0)\n",
    "loss_3, acc_3 = model_3.evaluate(Xtest_3, ytest, verbose=0)\n",
    "loss_4, acc_4 = model_4.evaluate(Xtest_4, ytest, verbose=0)\n",
    "loss_5, acc_5 = model_5.evaluate(Xtest_5, ytest, verbose=0)\n",
    "loss_6, acc_6 = model_6.evaluate(Xtest_6, ytest, verbose=0)\n",
    "loss_7, acc_7 = model_7.evaluate(Xtest_7, ytest, verbose=0)\n",
    "loss_8, acc_8 = model_8.evaluate(Xtest_8, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58568c61",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1: 77.93103456497192 \n",
      " Accuracy 2: 77.7011513710022 \n",
      " Accuracy 3: 77.93103456497192 \n",
      " Accuracy 4: 77.93103456497192 \n",
      " Accuracy 5: 79.08046245574951 \n",
      " Accuracy 6: 79.08046245574951 \n",
      " Accuracy 7: 78.85057330131531 \n",
      " Accuracy 8: 77.7011513710022 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy 1: {} \\n'.format(acc_1*100),\n",
    "     'Accuracy 2: {} \\n'.format(acc_2*100),\n",
    "     'Accuracy 3: {} \\n'.format(acc_3*100),\n",
    "     'Accuracy 4: {} \\n'.format(acc_4*100),\n",
    "     'Accuracy 5: {} \\n'.format(acc_5*100),\n",
    "     'Accuracy 6: {} \\n'.format(acc_6*100),\n",
    "     'Accuracy 7: {} \\n'.format(acc_7*100),\n",
    "     'Accuracy 8: {} \\n'.format(acc_8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ad8554b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict_label(page_text, vocab, tokenizer, model):\n",
    "    tokens = word_tokenize(page_text)\n",
    "    tokens = [t for t in tokens if t in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    pred = model.predict(encoded, verbose=0)\n",
    "    return round(pred[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d25dedd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(texts, labels, tokenizer, model, vocab):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for i, test in tqdm(zip(labels, texts)):\n",
    "        pred = predict_label(test, vocab, tokenizer, model)\n",
    "        if i == 1 and pred == 1:\n",
    "            true_positive += 1\n",
    "        elif i == 1 and pred == 0:\n",
    "            false_negative += 1\n",
    "        elif i == 0 and pred == 1:\n",
    "            false_positive += 1\n",
    "    \n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if precision + recall != 0:\n",
    "    \n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        f1 = 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b572bfb",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [00:19, 22.14it/s]\n",
      "435it [00:16, 25.61it/s]\n",
      "435it [00:16, 25.61it/s]\n",
      "435it [00:16, 26.63it/s]\n",
      "435it [00:16, 25.59it/s]\n",
      "435it [00:16, 26.44it/s]\n",
      "435it [00:16, 26.65it/s]\n",
      "435it [00:16, 26.71it/s]\n"
     ]
    }
   ],
   "source": [
    "precision_1, recall_1, f1_1 = calculate_metrics(test_data_texts_1, test_data_labels, tokenizer_1, model_1, vocab_1)\n",
    "precision_2, recall_2, f1_2 = calculate_metrics(test_data_texts_2, test_data_labels, tokenizer_2, model_2, vocab_2)\n",
    "precision_3, recall_3, f1_3 = calculate_metrics(test_data_texts_3, test_data_labels, tokenizer_3, model_3, vocab_3)\n",
    "precision_4, recall_4, f1_4 = calculate_metrics(test_data_texts_4, test_data_labels, tokenizer_4, model_4, vocab_4)\n",
    "precision_5, recall_5, f1_5 = calculate_metrics(test_data_texts_5, test_data_labels, tokenizer_5, model_5, vocab_5)\n",
    "precision_6, recall_6, f1_6 = calculate_metrics(test_data_texts_6, test_data_labels, tokenizer_6, model_6, vocab_6)\n",
    "precision_7, recall_7, f1_7 = calculate_metrics(test_data_texts_7, test_data_labels, tokenizer_7, model_7, vocab_7)\n",
    "precision_8, recall_8, f1_8 = calculate_metrics(test_data_texts_8, test_data_labels, tokenizer_8, model_8, vocab_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "13d498be",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Precision: 0.7608695652173914, Recall: 0.9790209790209791, F1-score: 0.8562691131498472 \n",
      " 2. Precision: 0.7540106951871658, Recall: 0.986013986013986, F1-score: 0.8545454545454545 \n",
      " 3. Precision: 0.7526595744680851, Recall: 0.9895104895104895, F1-score: 0.8549848942598186 \n",
      " 4. Precision: 0.7574931880108992, Recall: 0.972027972027972, F1-score: 0.8514548238897396 \n",
      " 5. Precision: 0.7613941018766756, Recall: 0.993006993006993, F1-score: 0.8619119878603945 \n",
      " 6. Precision: 0.7629427792915532, Recall: 0.9790209790209791, F1-score: 0.8575803981623277 \n",
      " 7. Precision: 0.7587131367292225, Recall: 0.9895104895104895, F1-score: 0.8588770864946889 \n",
      " 8. Precision: 0.75, Recall: 0.986013986013986, F1-score: 0.8519637462235651 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('1. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_1, recall_1, f1_1),\n",
    "     '2. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_2, recall_2, f1_2),\n",
    "     '3. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_3, recall_3, f1_3),\n",
    "     '4. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_4, recall_4, f1_4),\n",
    "     '5. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_5, recall_5, f1_5),\n",
    "     '6. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_6, recall_6, f1_6),\n",
    "     '7. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_7, recall_7, f1_7),\n",
    "     '8. Precision: {}, Recall: {}, F1-score: {} \\n'.format(precision_8, recall_8, f1_8),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee027a0b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BERT approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a7430a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenized_train = tokenizer(train_data_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8cb77e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'text': train_data_texts, 'label': train_data_labels})\n",
    "train_df.to_csv('train_1644.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f27b9be9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer(test_data_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d5ce4a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'text': test_data_texts, 'label': test_data_labels})\n",
    "test_df.to_csv('test_1644.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a75e03b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "bea1effc67a94c3f87760b97b9934adc",
      "55fa280d7e1048da9129c999f7b35ca7",
      "5355f28c263b4738987bdc1d2af1b912",
      "b40c7cfe18c74be8b6d1e2e252b1a2b8",
      "3039587a059c42908a491994c64d4209",
      "c8bf0adef6c34627bfe41a59427e0eff",
      "0128934400004818b0e74229ef33397a",
      "fe55d62a18fb4d2aabd7e9791f2d1d1d",
      "35485d3a43914687bebd00296f170be1",
      "952b8684e72a40be85ec78f1e0a8749b",
      "ad012d6c1a3e43799eb402063c75727e",
      "d157341fb9b14ceb9cf8ba71b36f1bf7",
      "28721170f0dd4b918e2993d7de9fc03b",
      "709dae6401624c2cb71adf271c807f80",
      "3c1b4c5d68594e2f9a631b24fe2cbd54",
      "6e7bdf4912444fa180cbfc97162d38bb",
      "ec26f3160f81410399b880ce61881da6",
      "8e6156c1214248cb92af93b02e625046",
      "dd18921fd161463d9c3fa7c6a633865a",
      "c9b7bfc7f54f48ceb8786784297134b6",
      "a4bb7bd646da4456a2232e2ff8c83046",
      "567a8e856c2a461fa718a3c583fcfdc7",
      "6988d8410f2542feb6bdaa75ab851904",
      "e67926089f6f400eb8e677b803030e7d",
      "2769c21b6f1241c096d4676bbd3decf5",
      "443f9a5192004d6f93ec297de1a085e2",
      "5d4b6098d6374ba5890a341a7a730944",
      "4ca7d4f7420342aea5978d10e1143c71",
      "20f0207d614f4f4aae3a8a3ce79f2de0",
      "a972800142254607939f89224679b4b1",
      "0252805c3f544e619c81da8abb4a74a2",
      "8b28e539d9e64b5ea5c9d1feda5b8b4e",
      "5aa98a26b1624d9a8aaebbd69128c701",
      "91a9be92a9a843c3bf3135de77ab87b1",
      "3095fe8286fb4073b9166d6299d28f87",
      "85387956ce1049798c3b11c7f6fb0a6d",
      "46b19e0896eb4811875245e0db9a5331",
      "536acc6ea0d1436e8d03a2b158944a66",
      "be906d780f494fb9838b07c5c200d126",
      "0530aea8f2f8450eaa7b304f6d50585f",
      "96c0850e41024850940500152d946485",
      "84f468b4ff1a44eb85dd0a9f17d523f2",
      "287665d4af0549e0844125425a0a9aae",
      "a8608ec755d24001b7842673da1cf8da",
      "47220c4167b44f4aaf9f1e11c174db45",
      "f2467aecb1dc4a1fa3864ed238b310b3",
      "13f36ec5a3654c97954464b43a5d4c25",
      "8d64e11f90894930a676df1f761097b1",
      "5c7a20b394c74f36a53f739839ba4956",
      "3ced7460d37d4731ae48a86234dbbaf7",
      "4e545508b3ce4cb4b71e6df5e5f5a2f6",
      "e11daf89f2a342b9a9b870df4c448126",
      "3b3bf4488a7749ca9703f399aa870402",
      "73777c4983f8478692f9c91700ace50b",
      "eee9def658b14cc1954d3ae4d75457f0"
     ]
    },
    "hidden": true,
    "id": "6mWpSC5Kafs_",
    "outputId": "d2e48985-9d7d-4b50-ddd5-19d9ccae5da2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 16:27:58,479 [datasets.builder    ] [MainThread] [WARNING ] [_create_builder_conf][0463] Using custom data configuration default-0ae9c0752663b210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/macbookpro/.cache/huggingface/datasets/csv/default-0ae9c0752663b210/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020720958709716797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba63d3f3aa3f4037841ae6897fbe2c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021033048629760742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Extracting data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a349f1262f462b9b5c127d7d1b216f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029595136642456055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": " tables",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02033829689025879,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": " tables",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/macbookpro/.cache/huggingface/datasets/csv/default-0ae9c0752663b210/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02122187614440918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a57c3670074cd98836946a3c1cf64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = load_dataset('csv',\n",
    "                      data_files={'train': 'train_1644.csv',\n",
    "                                 'test': 'test_1644.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56b0e9",
   "metadata": {
    "hidden": true,
    "id": "Hnr9qFpeK4hB"
   },
   "source": [
    "Setting the training arguments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cef34774",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2634\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 435\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce76373d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "IFU8pJGMau0l",
    "outputId": "dd823770-2aed-4f14-e5ba-9791dca57e34"
   },
   "outputs": [],
   "source": [
    "arguments = TrainingArguments(\n",
    "    do_predict=True,\n",
    "    output_dir='model', \n",
    "    evaluation_strategy=\"steps\", \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=25,\n",
    "    logging_steps=1000, \n",
    "    logging_strategy='steps', \n",
    "    save_strategy='no',\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0dd42",
   "metadata": {
    "hidden": true,
    "id": "pt7-o3Q5WhSv"
   },
   "source": [
    "Tokenizing our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7c1e80a",
   "metadata": {
    "hidden": true,
    "id": "akFLg0NPa1aA"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "703508c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "671df2e6f20848098fb1c4a2f36499e9",
      "ddd50db55bf949ca8ae286ffb8c57905",
      "c4eb250bcabf4644a06df322c13c7921",
      "13a680b7d2294cd9bbbc18a0ca26f9d5",
      "6fc6bf24d0634de18eea9e0a6e74fc04",
      "81384a6dce62497cbb97e787dff020e1",
      "c03de47867d84115ad67c0f00cd2b210",
      "7f0f930e15ba4035a37615afde79fe70",
      "0adabfef1afa4ce8a2248135a27a0179",
      "9cddd685c03e400eaca64015cf6dbdc6",
      "d95f15cd22ee4e95a2bc1b2082656a9c",
      "617a38193cf94897b832065864c76c00",
      "250bd88df34f4ec99deae97495175749",
      "571ea3a1ba8b4fb7b12eb18731968373",
      "46d69b6f186d44abbe466ee3f611e69d",
      "f62a92e1d15f4bc694cfda05b5cd37c2",
      "c72c678a7a9d4a568cf4aa2eab200a1a",
      "6fdb19e4a0fc4552a5b47f6fccdb5940",
      "f9e9d7cdf66c441b87810f1c9d8e2677",
      "ca418e290d7149e58119f0d676fcec97",
      "7ab59e5ce096401b98f37e13f776c26c",
      "0b9f55af1f0a4509b1df94093a95114f"
     ]
    },
    "hidden": true,
    "id": "zzz_3-QEa27T",
    "outputId": "524f21e1-089d-485d-db31-d111bb42234e"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016750097274780273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da07f381b9284b9a936839b3d22aa44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014142990112304688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea47bdae31f42969cadf33b46481ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e9c15",
   "metadata": {
    "hidden": true,
    "id": "NsEI-VOQY-rF"
   },
   "source": [
    "Defining our metric of choice which is accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d61a96b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ad48e878efcf402aba93675a96a27380",
      "f4f3f1a2d9d34b3abea6bb55c568b38a",
      "5f0f054632f14659977abb510f44c6e0",
      "7a93db0f81e44daa952af78fcf691184",
      "98bffb06d746496fb88aa98b877f91d3",
      "e6ddcac0af014497ac8dc8974f472b28",
      "cbfa42a1df6a423e9f1010fb381e7f73",
      "3ffa8ae477674653b131a6c0e54bc4f0",
      "de8983fa585149ed86c492ef31172e1c",
      "37b976cbec514cdfb8b92093cd0f35e4",
      "e70f5f1b5a0b43aa813a52409f6e164c"
     ]
    },
    "hidden": true,
    "id": "h9tBIy9gYtUJ",
    "outputId": "8e6b4dcf-a092-44c5-c1ff-283d48815b11"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018860816955566406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading builder script",
       "rate": null,
       "total": 1652,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93512154553f4bb88e1e4cb65428d101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38b6f3bf",
   "metadata": {
    "hidden": true,
    "id": "6Vtm_dTAZIw9"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54acae72",
   "metadata": {
    "hidden": true,
    "id": "NRebLmb4WuFN"
   },
   "source": [
    "Initializing the Trainer class and starting the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0293d429",
   "metadata": {
    "hidden": true,
    "id": "TVE1tjnMdFQJ"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e642920b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "hidden": true,
    "id": "YZA4RXn-dJIC",
    "outputId": "ccd3a73d-e05c-4ad5-b578-e74607d8552d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3515\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21975' max='21975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21975/21975 2:37:50, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.655200</td>\n",
       "      <td>0.592744</td>\n",
       "      <td>0.489362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>0.634706</td>\n",
       "      <td>0.731915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.683500</td>\n",
       "      <td>0.926172</td>\n",
       "      <td>0.459574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>1.027632</td>\n",
       "      <td>0.425532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.581100</td>\n",
       "      <td>0.627923</td>\n",
       "      <td>0.591489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.587319</td>\n",
       "      <td>0.731915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.755748</td>\n",
       "      <td>0.523404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.791489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.603451</td>\n",
       "      <td>0.714894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.559300</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.417021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.571438</td>\n",
       "      <td>0.757447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.525900</td>\n",
       "      <td>0.505782</td>\n",
       "      <td>0.655319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.854703</td>\n",
       "      <td>0.557447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.564851</td>\n",
       "      <td>0.612766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.538300</td>\n",
       "      <td>0.504021</td>\n",
       "      <td>0.621277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.480356</td>\n",
       "      <td>0.685106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>0.640572</td>\n",
       "      <td>0.689362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.597900</td>\n",
       "      <td>0.677274</td>\n",
       "      <td>0.689362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.564300</td>\n",
       "      <td>0.670684</td>\n",
       "      <td>0.685106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.634043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.755616</td>\n",
       "      <td>0.634043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-1000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-1000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-2000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-2000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-2000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-3000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-3000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-4000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-4000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-4000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-5000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-5000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-5000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-6000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-6000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-6000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-7000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-7000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-7000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-8000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-8000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-8000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-9000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-9000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-9000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-10000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-10000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-10000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-11000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-11000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-11000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-12000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-12000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-12000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-13000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-13000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-13000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-14000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-14000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-14000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-15000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-15000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-15000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-16000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-16000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-16000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-17000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-17000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-17000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-18000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-18000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-18000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-19000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-19000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-19000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-20000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-20000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-20000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 235\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to drive/MyDrive/knfz/model/checkpoint-21000\n",
      "Configuration saved in drive/MyDrive/knfz/model/checkpoint-21000/config.json\n",
      "Model weights saved in drive/MyDrive/knfz/model/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in drive/MyDrive/knfz/model/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in drive/MyDrive/knfz/model/checkpoint-21000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21975, training_loss=0.5708771286618316, metrics={'train_runtime': 9473.4121, 'train_samples_per_second': 9.276, 'train_steps_per_second': 2.32, 'total_flos': 2.309579388396528e+16, 'train_loss': 0.5708771286618316, 'epoch': 25.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1148d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd7a12",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Evaluating the trained model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de429f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('model', \n",
    "                                                           config=configuration)\n",
    "tokenizer = BertTokenizer.from_pretrained('model', do_lower_case=True, \n",
    "                                          max_length=10000, padding=\"max_length\", truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2462fc7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We calculate our custom metric via the following function that determines how many ground-truth first pages were actually predicted as first pages. The logic behind this approach suggests that by determining first pages correctly we can consecutively split documents correctly, using each first page as a separator (since it means a start of a new document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ab14e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(texts, labels):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    true_negative = 0\n",
    "    \n",
    "    for i, test in tqdm(zip(labels, texts)):\n",
    "        inputs = tokenizer(test, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        pred = logits.argmax().item()\n",
    "        \n",
    "        if i == 1 and pred == 1:\n",
    "            true_positive += 1\n",
    "        elif i == 1 and pred == 0:\n",
    "            false_negative += 1\n",
    "        elif i == 0 and pred == 1:\n",
    "            false_positive += 1\n",
    "        elif i == 0 and pred == 0:\n",
    "            true_negative += 1\n",
    "\n",
    "        \n",
    "    \n",
    "    if true_positive + false_positive != 0:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if true_positive + false_negative != 0:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if precision + recall != 0:\n",
    "    \n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        f1 = 0\n",
    "    \n",
    "    acc = (true_positive + true_negative) / len(texts)\n",
    "    \n",
    "    return precision, recall, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9673ff4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "3Zs-QfDmuASo",
    "outputId": "280f339d-3bfc-49af-8f21-702aae65fd3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [13:05,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, acc = calculate_metrics(pages_test_docs, pages_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25bb0499",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "Whi3fgCnuBav",
    "outputId": "0f278e12-d444-4487-c6ba-c4091fdc65de",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Precision: 0.7225433526011561 \n",
      " Recall: 0.8741258741258742 \n",
      " F1-score: 0.7911392405063291\n"
     ]
    }
   ],
   "source": [
    "print('\\n Precision: {} \\n Recall: {} \\n F1-score: {}'.format(precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
