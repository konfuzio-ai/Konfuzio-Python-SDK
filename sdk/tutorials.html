<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tutorials &mdash; Konfuzio  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/full_green_square.png"/>
    <link rel="canonical" href="https://dev.konfuzio.com/sdk/tutorials.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
        <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Explanations" href="explanations.html" />
    <link rel="prev" title="Get Started" href="get_started.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Konfuzio
            <img src="../_static/docs__static_square_transparent_super_small.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Konfuzio SDK</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">What is the Konfuzio SDK?</a></li>
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Get Started</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#file-splitting-tutorials">File Splitting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#train-a-file-splitting-ai-locally">Train a File Splitting AI locally</a></li>
<li class="toctree-l3"><a class="reference internal" href="#develop-and-save-a-custom-file-splitting-ai">Develop and save a custom File Splitting AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#intro">Intro</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quick-explanation">Quick explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-by-step-explanation">Step-by-step explanation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#filesplittingevaluation-class">FileSplittingEvaluation class</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-of-evaluation-input-and-output">Example of evaluation input and output</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#document-categorization">Document Categorization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#working-with-the-category-of-a-document-and-its-individual-pages">Working with the Category of a Document and its individual Pages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#name-based-categorization-ai">Name-based Categorization AI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-based-categorization-ai">Model-based Categorization AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Available Categorization Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#categorization-ai-overview-diagram">Categorization AI Overview Diagram</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#document-information-extraction">Document Information Extraction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents">Train a Konfuzio SDK Model to Extract Information From Payslip Documents</a></li>
<li class="toctree-l3"><a class="reference internal" href="#customize-extraction-ai">Customize Extraction AI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example-of-custom-extraction-ai-the-paragraph-extraction-ai">Example of Custom Extraction AI: The Paragraph Extraction AI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#evaluate-a-trained-extraction-ai-model">Evaluate a Trained Extraction AI Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#paragraph-and-sentence-tokenizer">Paragraph and Sentence Tokenizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#paragraph-tokenizer">Paragraph Tokenizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sentence-tokenizer">Sentence Tokenizer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#data-validation-rules">Data Validation Rules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#initializing-a-project-with-the-data-validation-rules-enabled">Initializing a Project with the Data Validation Rules enabled</a></li>
<li class="toctree-l3"><a class="reference internal" href="#document-validation-rules">Document Validation Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#annotation-validation">Annotation Validation Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#span-validation">Span Validation Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bbox-validation">Bbox Validation Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#initializing-a-project-with-the-data-validation-rules-disabled">Initializing a Project with the Data Validation Rules disabled</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#find-possible-outliers-among-the-ground-truth-annotations">Find possible outliers among the ground-truth Annotations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#create-regex-based-annotations">Create Regex-based Annotations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#train-label-regex-tokenizer">Train Label Regex Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#finding-spans-of-a-label-not-found-by-a-tokenizer">Finding Spans of a Label Not Found by a Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#getting-word-bounding-box-bbox-for-a-document">Getting Word Bounding Box (BBox) for a Document</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preview-of-result">Preview of Result</a></li>
<li class="toctree-l3"><a class="reference internal" href="#steps">Steps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#retrain-flair-ner-ontonotes-fast-with-human-revised-annotations">Retrain Flair NER-Ontonotes-Fast with Human Revised Annotations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#count-relevant-expressions-in-annual-reports">Count Relevant Expressions in Annual Reports</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="explanations.html">Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="sourcecode.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="contribution.html">Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/konfuzio-ai/konfuzio-sdk/releases">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Konfuzio Server</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../web/index.html">What is the Konfuzio Server?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../web/explanations.html">Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../web/api-v3.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../web/on_premises.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../web/changelog_app.html">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Konfuzio Document Validation UI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dvui/index.html">What is the Konfuzio Document Validation UI?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dvui/explanations.html">Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dvui/sourcecode.html">Source Code</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/konfuzio-ai/document-validation-ui/releases">Changelog</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Konfuzio</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Tutorials</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/sdk/tutorials.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Permalink to this headline">¶</a></h1>
<p><em>Tutorials are lessons that take the reader by the hand through a series of steps to complete a project of some kind.</em>
<em>Tutorials are learning-oriented.</em></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The first step we’re going to cover is <a class="reference external" href="tutorials.html#file-splitting-tutorials">File Splitting</a>
– this happens when the original Document consists of several smaller sub-Documents and needs to be separated so that each one can be processed individually.</p>
<p>Second part is on <a class="reference external" href="tutorials.html#document-categorization">Categorization</a>, where a Document is labelled to be of a certain Category within the Project.</p>
<p>Third part describes <a class="reference external" href="tutorials.html#document-information-extraction">Information Extraction</a>, during which various information is obtained from unstructured texts,
i.e. Name, Date, Recipient, or any other custom Labels.</p>
<p>For a more in-depth look at each step, be sure to check out the
<a class="reference external" href="explanations.html#architecture-sdk-to-server">Architecture Diagram</a> that reflects each step of the
document-processing pipeline.</p>
</section>
<section id="file-splitting-tutorials">
<span id="id1"></span><h2>File Splitting<a class="headerlink" href="#file-splitting-tutorials" title="Permalink to this headline">¶</a></h2>
<p>You can train your own File Splitting AI on the data from any Project of your choice. For that purpose, there are
several tools in the SDK that enable processing Documents that consist of multiple files and propose splitting them
into the Sub-Documents accordingly:</p>
<ul>
<li><p>A Context Aware File Splitting Model uses a simple hands-on logic based on scanning Category’s Documents and finding
strings exclusive for first Pages of all Documents within the Category. Upon predicting whether a Page is a potential
splitting point (meaning whether it is first or not), we compare Page’s contents to these exclusive first-page strings;
if there is occurrence of at least one such string, we mark a Page to be first (thus meaning it is a splitting point).
An instance of the Context Aware File Splitting Model can be used to initially build a File Splitting pipeline and can
later be replaced with more complex solutions.</p>
<p>A Context Aware File Splitting Model instance can be used with an interface provided by Splitting AI – this class
accepts a whole Document instead of a single Page and proposes splitting points or splits the original Documents.</p>
</li>
<li><p>A Multimodal File Splitting Model is a model that uses an approach that takes both visual and textual parts of the
Pages and processes them independently via the combined VGG19 architecture (simplified) and LegalBERT, passing the
resulting outputs together to a Multi-Layered Perceptron. Model’s output is also a prediction of a Page being first or
non-first.</p></li>
</ul>
<p>For developing a custom File Splitting approach, we propose an abstract class <code class="docutils literal notranslate"><span class="pre">AbstractFileSplittingModel</span></code>.</p>
<section id="train-a-file-splitting-ai-locally">
<h3>Train a File Splitting AI locally<a class="headerlink" href="#train-a-file-splitting-ai-locally" title="Permalink to this headline">¶</a></h3>
<p>Let’s see how to use the <code class="docutils literal notranslate"><span class="pre">konfuzio_sdk</span></code> to automatically split a file into several Documents. We will be using
a pre-built class <code class="docutils literal notranslate"><span class="pre">SplittingAI</span></code> and an instance of a trained <code class="docutils literal notranslate"><span class="pre">ContextAwareFileSplittingModel</span></code>. The latter uses a
context-aware logic. By context-aware we mean a rule-based approach that looks for common strings between the first
Pages of all Category’s Documents. Upon predicting whether a Page is a potential splitting point (meaning whether it is
first or not), we compare Page’s contents to these common first-page strings; if there is occurrence of at least one
such string, we mark a Page to be first (thus meaning it is a splitting point).</p>
<p>This tutorial can also be used with the <code class="docutils literal notranslate"><span class="pre">MultimodalFileSplittingModel</span></code>; the only difference in the initialization is
that it does not require specifying a Tokenizer explicitly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Page</span><span class="p">,</span> <span class="n">Category</span><span class="p">,</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">SplittingAI</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">ContextAwareFileSplittingModel</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">ConnectedTextTokenizer</span>

</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a Project and fetch a test Document of your choice</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># initialize a Context Aware File Splitting Model and fit it</span>

<span class="n">file_splitting_model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="p">(</span>
    <span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">ConnectedTextTokenizer</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># for an example run, you can take only a slice of training documents to make fitting faster</span>
<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">allow_empty_categories</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># save the model</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">include_konfuzio</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># run the prediction and see its confidence</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">test_document</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first. Confidence: </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">,</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page_confidence</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>

<span class="c1"># usage with the Splitting AI – you can load a pre-saved model or pass an initialized instance as the input</span>
<span class="c1"># in this example, we load a previously saved one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

<span class="c1"># initialize the Splitting AI</span>
<span class="n">splitting_ai</span> <span class="o">=</span> <span class="n">SplittingAI</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Splitting AI is a more high-level interface to Context Aware File Splitting Model and any other models that can be</span>
<span class="c1"># developed for File Splitting purposes. It takes a Document as an input, rather than individual Pages, because it</span>
<span class="c1"># utilizes page-level prediction of possible split points and returns Document or Documents with changes depending</span>
<span class="c1"># on the prediction mode.</span>

<span class="c1"># Splitting AI can be run in two modes: returning a list of Sub-Documents as the result of the input Document</span>
<span class="c1"># splitting or returning a copy of the input Document with Pages predicted as first having an attribute</span>
<span class="c1"># &quot;is_first_page&quot;. The flag &quot;return_pages&quot; has to be True for the latter; let&#39;s use it</span>
<span class="n">new_document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">test_document</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_document</span><span class="p">)</span>
<span class="c1"># output: [predicted_document]</span>

<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">new_document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first. Confidence: </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">,</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page_confidence</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="develop-and-save-a-custom-file-splitting-ai">
<h3>Develop and save a custom File Splitting AI<a class="headerlink" href="#develop-and-save-a-custom-file-splitting-ai" title="Permalink to this headline">¶</a></h3>
<p>In this tutorial, you will learn how to train a custom File Splitting AI on the data from a Project of your choice and
save a trained model for further usage.</p>
<section id="intro">
<h4>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¶</a></h4>
<p>It’s common for multi-paged files to not be perfectly organized, and in some cases, multiple independent Documents may be
included in a single file. To ensure that these Documents are properly processed and separated, we will be discussing a
method for identifying and splitting them into individual, independent Sub-documents.</p>
<img alt="../_images/multi_file_document_example.png" src="../_images/multi_file_document_example.png" />
<p><em>Multi-file Document Example</em></p>
<p>Konfuzio SDK offers two ways for separating Documents that may be included in a single file. One of them is training
the instance of the Multimodal File Splitting Model for file splitting that would predict whether a Page is first or
not and running the Splitting AI with it. Multimodal File Splitting Model is a combined approach based on architecture
that processes textual and visual data from the Documents separately (in our case, using BERT and VGG19 simplified
architectures respectively) and then combines the outputs which go into a Multi-layer Perceptron architecture as
inputs. A more detailed scheme of the architecture can be found further.</p>
<p>If you hover over the image you can zoom or use the full page mode.</p>
<p><span class="raw-html-m2r"><div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;url&quot;:&quot;https://raw.githubusercontent.com/konfuzio-ai/konfuzio-sdk/master/docs/sdk/examples/file-splitting-class/fusion_model.drawio&quot;}"></div></span></p>
<script type="text/javascript" src="https://viewer.diagrams.net/embed2.js?&fetch=https%3A%2F%2Fraw.githubusercontent.com%2Fkonfuzio-ai%2Fkonfuzio-sdk%2Fmaster%2Fdocs%2Fsdk%2Fexamples%2Ffile-splitting-class%2Ffusion_model.drawio"></script><p>Another approach is context-aware file splitting logic which is presented by Context Aware File Splitting Model. This
approach involves analyzing the contents of each Page and identifying similarities to the first Pages of the Document.
It will allow us to define splitting points and divide the Document into multiple Sub-documents. It’s important to note
that this approach is only effective for Documents written in the same language and that the process must be repeated
for each Category. In this tutorial, we will explain how to implement the class for this model step by step.</p>
<p>If you are unfamiliar with the SDK’s main concepts (like Page or Span), you can get to know them at <a class="reference external" href="https://dev.konfuzio.com/sdk/explanations.html#data-layer-concepts">Data Layer Concepts</a>.</p>
</section>
<section id="quick-explanation">
<h4>Quick explanation<a class="headerlink" href="#quick-explanation" title="Permalink to this headline">¶</a></h4>
<p>The first step in implementing this method is “training”: this involves tokenizing the Document by splitting its text
into parts, specifically into strings without line breaks. We then gather the exclusive strings from Spans, which are
the parts of the text in the Page, and compare them to the first Pages of each Document in the training data.</p>
<p>Once we have identified these strings, we can use them to determine whether a Page in an input Document is a first Page
or not. We do this by going through the strings in the Page and comparing them to the set of strings collected in the
training stage. If we find at least one string that intersects between the current Page and the strings from the first
step, we believe it is the first Page.</p>
<p>Note that the more Documents we use in the training stage, the less intersecting strings we are likely to find. If you
find that your set of first-page strings is empty, try using a smaller slice of the dataset instead of the whole set.
Generally, when used on Documents within the same Category, this algorithm should not return an empty set. If that is
the case, it’s worth checking if your data is consistent, for example, not in different languages or containing other
Categories.</p>
</section>
<section id="step-by-step-explanation">
<h4>Step-by-step explanation<a class="headerlink" href="#step-by-step-explanation" title="Permalink to this headline">¶</a></h4>
<p>In this section, we will walk you through the process of setting up the <code class="docutils literal notranslate"><span class="pre">ContextAwareFileSplittingModel</span></code> class, which
can be found in the code block at the bottom of this page. This class is already implemented and can be imported using
<code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">konfuzio_sdk.trainer.file_splitting</span> <span class="pre">import</span> <span class="pre">ContextAwareFileSplittingModel</span></code>.</p>
<p>Note that any custom File Splitting AI (derived from <code class="docutils literal notranslate"><span class="pre">AbstractFileSplittingModel</span></code> class) requires having the following
methods implemented:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code> to initialize key variables required by the custom AI;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code> to define architecture and training that the model undergoes, i.e. a certain NN architecture or a custom</p></li>
<li><p>hardcoded logic;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict</span></code> to define how the model classifies Pages as first or non-first. <strong>NB:</strong> the classification needs to be
run on the Page level, not the Document level – the result of classification is reflected in <code class="docutils literal notranslate"><span class="pre">is_first_page</span></code> attribute
value, which is unique to the Page class and is not present in Document class. Pages with <code class="docutils literal notranslate"><span class="pre">is_first_page</span> <span class="pre">=</span> <span class="pre">True</span></code> become
splitting points, thus, each new Sub-Document has a Page predicted as first as its starting point.</p></li>
</ul>
<p>To begin, we will make all the necessary imports:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Page</span><span class="p">,</span> <span class="n">Category</span><span class="p">,</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">SplittingAI</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">ContextAwareFileSplittingModel</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">ConnectedTextTokenizer</span>

</pre></div>
</div>
<p>Then, let’s initialize the <code class="docutils literal notranslate"><span class="pre">ContextAwareFileSplittingModel</span></code> class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="nb">globals</span><span class="p">()[</span><span class="s1">&#39;torch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">def</span> <span class="nf">restore_dependencies</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">check_is_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        Check if Multimodal File Splitting Model instance is ready for inference.</span>

<span class="s2">        A method checks that the instance of the Model has at least one Category passed as the input and that it</span>
</pre></div>
</div>
<p>The class inherits from <code class="docutils literal notranslate"><span class="pre">AbstractFileSplittingModel</span></code>, so we run <code class="docutils literal notranslate"><span class="pre">super().__init__(categories=categories)</span></code> to properly
inherit its attributes. The <code class="docutils literal notranslate"><span class="pre">tokenizer</span></code> attribute will be used to process the text within the Document, separating it
into Spans. This is done to ensure that the text in all the Documents is split using the same logic (particularly
tokenization by separating on <code class="docutils literal notranslate"><span class="pre">\n</span></code> whitespaces by ConnectedTextTokenizer, which is used in the example in the end of the
page) and it will be possible to find common Spans. It will be used for training and testing Documents as well as any
Document that will undergo splitting. It’s important to note that if you run fitting with one Tokenizer and then
reassign it within the same instance of the model, all previously gathered strings will be deleted and replaced by new
ones. <code class="docutils literal notranslate"><span class="pre">requires_images</span></code> and <code class="docutils literal notranslate"><span class="pre">requires_text</span></code> determine whether these types of data are used for prediction; this is
needed for distinguishing between preprocessing types once a model is passed into the Splitting AI.</p>
<p>An example of how ConnectedTextTokenizer works:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># before tokenization</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">test_document</span><span class="o">.</span><span class="n">text</span>

<span class="c1"># output: &quot;Hi all,\nI like bread.\n\fI hope to get everything done soon.\n\fMorning,\n\fI&#39;m glad to see you.&quot;</span>
<span class="c1">#             &quot;\n\fMorning,&quot;</span>

<span class="n">test_document</span><span class="o">.</span><span class="n">spans</span><span class="p">()</span>

<span class="c1"># output: []</span>

<span class="n">test_document</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_document</span><span class="p">)</span>

<span class="c1"># after tokenization</span>
<span class="n">test_document</span><span class="o">.</span><span class="n">spans</span><span class="p">()</span>

<span class="c1"># output: [Span (0, 7), Span (8, 21), Span (22, 58), Span (59, 68), Span (69, 90), Span (91, 100)]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">test_document</span><span class="o">.</span><span class="n">spans</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">offset_string</span>

<span class="c1"># output: &quot;Hi all,&quot;</span>
</pre></div>
</div>
<p>The first method to define will be the <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method. For each Category, we call <code class="docutils literal notranslate"><span class="pre">exclusive_first_page_strings</span></code> method,
which allows us to gather the strings that appear on the first Page of each Document. <code class="docutils literal notranslate"><span class="pre">allow_empty_categories</span></code> allows
for returning empty lists for Categories that haven’t had any exclusive first-page strings found across their Documents.
This means that those Categories would not be used in the prediction process.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
    <span class="n">Category</span><span class="s1">&#39;s Documents.</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    def __init__(self, categories: List[Category], tokenizer, *args, **kwargs):</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Initialize</span> <span class="n">the</span> <span class="n">Context</span> <span class="n">Aware</span> <span class="n">File</span> <span class="n">Splitting</span> <span class="n">Model</span><span class="o">.</span>

        <span class="p">:</span><span class="n">param</span> <span class="n">categories</span><span class="p">:</span> <span class="n">A</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">Categories</span> <span class="n">to</span> <span class="n">run</span> <span class="n">training</span><span class="o">/</span><span class="n">prediction</span> <span class="n">of</span> <span class="n">the</span> <span class="n">model</span> <span class="n">on</span><span class="o">.</span>
        <span class="p">:</span><span class="nb">type</span> <span class="n">categories</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Category</span><span class="p">]</span>
        <span class="p">:</span><span class="n">param</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span> <span class="n">used</span> <span class="k">for</span> <span class="n">processing</span> <span class="n">Documents</span> <span class="n">on</span> <span class="n">fitting</span> <span class="n">when</span> <span class="n">searching</span> <span class="k">for</span> <span class="n">exclusive</span> <span class="n">first</span><span class="o">-</span><span class="n">page</span>
        <span class="n">strings</span><span class="o">.</span>
        <span class="p">:</span><span class="n">raises</span> <span class="ne">ValueError</span><span class="p">:</span> <span class="n">When</span> <span class="n">an</span> <span class="n">empty</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">Categories</span> <span class="ow">is</span> <span class="n">passed</span> <span class="n">into</span> <span class="n">categories</span> <span class="n">argument</span><span class="o">.</span>
        <span class="p">:</span><span class="n">raises</span> <span class="ne">ValueError</span><span class="p">:</span> <span class="n">When</span> <span class="n">a</span> <span class="nb">list</span> <span class="n">passed</span> <span class="n">into</span> <span class="n">categories</span> <span class="n">contains</span> <span class="n">elements</span> <span class="n">other</span> <span class="n">than</span> <span class="n">Categories</span><span class="o">.</span>
        <span class="p">:</span><span class="n">raises</span> <span class="ne">ValueError</span><span class="p">:</span> <span class="n">When</span> <span class="n">a</span> <span class="nb">list</span> <span class="n">passed</span> <span class="n">into</span> <span class="n">categories</span> <span class="n">contains</span> <span class="n">at</span> <span class="n">least</span> <span class="n">one</span> <span class="n">Category</span> <span class="k">with</span> <span class="n">no</span> <span class="n">Documents</span> <span class="ow">or</span> <span class="n">test</span>
</pre></div>
</div>
<p>Next, we define <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method. The method accepts a Page as an input and checks its Span set for containing
first-page strings for each of the Categories. If there is at least one intersection, the Page is predicted to be a
first Page. If there are no intersections, the Page is predicted to be a non-first Page.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &gt;&gt;&gt; from konfuzio_sdk.tokenizer.regex import ConnectedTextTokenizer</span>
<span class="sd">        &gt;&gt;&gt; from konfuzio_sdk.data import Project</span>
<span class="sd">        &gt;&gt;&gt; project = Project(id_=46)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = ConnectedTextTokenizer()</span>
<span class="sd">        &gt;&gt;&gt; model = ContextAwareFileSplittingModel(categories=project.categories, tokenizer=tokenizer).fit()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">categories</span><span class="p">:</span>
            <span class="c1"># method exclusive_first_page_strings fetches a set of first-page strings exclusive among the Documents</span>
            <span class="c1"># of a given Category. they can be found in _exclusive_first_page_strings attribute of a Category after</span>
            <span class="c1"># the method has been run. this is needed so that the information remains even if local variable</span>
            <span class="c1"># cur_first_page_strings is lost.</span>
            <span class="n">cur_first_page_strings</span> <span class="o">=</span> <span class="n">category</span><span class="o">.</span><span class="n">exclusive_first_page_strings</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>
</div>
<p>Lastly, a <code class="docutils literal notranslate"><span class="pre">check_is_ready()</span></code> method is defined. This method is used to ensure that a model is ready for prediction: the
checks cover that the Tokenizer and a set of Categories is defined, and that at least one of the Categories has
exclusive first-page strings.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>                <span class="k">if</span> <span class="n">allow_empty_categories</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">page</span><span class="p">:</span> <span class="n">Page</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Page</span><span class="p">:</span>
        <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        Predict a Page as first or non-first.</span>

<span class="s2">        :param page: A Page to receive first or non-first label.</span>
<span class="s2">        :type page: Page</span>
<span class="s2">        :return: A Page with a newly predicted is_first_page attribute.</span>

<span class="s2">        &gt;&gt;&gt; from konfuzio_sdk.tokenizer.regex import ConnectedTextTokenizer</span>
<span class="s2">        &gt;&gt;&gt; from konfuzio_sdk.data import Project</span>
<span class="s2">        &gt;&gt;&gt; project = Project(id_=46)</span>
<span class="s2">        &gt;&gt;&gt; tokenizer = ConnectedTextTokenizer()</span>
<span class="s2">        &gt;&gt;&gt; test_document = project.get_document_by_id(44865)</span>
<span class="s2">        &gt;&gt;&gt; model = ContextAwareFileSplittingModel(categories=project.categories, tokenizer=tokenizer)</span>
<span class="s2">        &gt;&gt;&gt; model.fit()</span>
</pre></div>
</div>
<p>Full code of class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="nb">globals</span><span class="p">()[</span><span class="s1">&#39;torch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">def</span> <span class="nf">restore_dependencies</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">check_is_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if Multimodal File Splitting Model instance is ready for inference.</span>

<span class="sd">        A method checks that the instance of the Model has at least one Category passed as the input and that it</span>
<span class="sd">        is fitted to run prediction.</span>

<span class="sd">    Category&#39;s Documents.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">categories</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Category</span><span class="p">],</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the Context Aware File Splitting Model.</span>

<span class="sd">        :param categories: A list of Categories to run training/prediction of the model on.</span>
<span class="sd">        :type categories: List[Category]</span>
<span class="sd">        :param tokenizer: Tokenizer used for processing Documents on fitting when searching for exclusive first-page</span>
<span class="sd">        strings.</span>
<span class="sd">        :raises ValueError: When an empty list of Categories is passed into categories argument.</span>
<span class="sd">        :raises ValueError: When a list passed into categories contains elements other than Categories.</span>
<span class="sd">        :raises ValueError: When a list passed into categories contains at least one Category with no Documents or test</span>
<span class="sd">        Documents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">ConnectedTextTokenizer</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="mi">46</span><span class="p">)</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ConnectedTextTokenizer</span><span class="p">()</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        for category in self.categories:</span>
<span class="sd">            # method exclusive_first_page_strings fetches a set of first-page strings exclusive among the Documents</span>
<span class="sd">            # of a given Category. they can be found in _exclusive_first_page_strings attribute of a Category after</span>
<span class="sd">            # the method has been run. this is needed so that the information remains even if local variable</span>
<span class="sd">            # cur_first_page_strings is lost.</span>
<span class="sd">            cur_first_page_strings = category.exclusive_first_page_strings(tokenizer=self.tokenizer)</span>
<span class="sd">            if not cur_first_page_strings:</span>
<span class="sd">                if allow_empty_categories:</span>

<span class="sd">    def predict(self, page: Page) -&gt; Page:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Predict</span> <span class="n">a</span> <span class="n">Page</span> <span class="k">as</span> <span class="n">first</span> <span class="ow">or</span> <span class="n">non</span><span class="o">-</span><span class="n">first</span><span class="o">.</span>

        <span class="p">:</span><span class="n">param</span> <span class="n">page</span><span class="p">:</span> <span class="n">A</span> <span class="n">Page</span> <span class="n">to</span> <span class="n">receive</span> <span class="n">first</span> <span class="ow">or</span> <span class="n">non</span><span class="o">-</span><span class="n">first</span> <span class="n">label</span><span class="o">.</span>
        <span class="p">:</span><span class="nb">type</span> <span class="n">page</span><span class="p">:</span> <span class="n">Page</span>
        <span class="p">:</span><span class="k">return</span><span class="p">:</span> <span class="n">A</span> <span class="n">Page</span> <span class="k">with</span> <span class="n">a</span> <span class="n">newly</span> <span class="n">predicted</span> <span class="n">is_first_page</span> <span class="n">attribute</span><span class="o">.</span>

        <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">ConnectedTextTokenizer</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="mi">46</span><span class="p">)</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ConnectedTextTokenizer</span><span class="p">()</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="mi">44865</span><span class="p">)</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
        <span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>A quick example of the class’s usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a Project and fetch a test Document of your choice</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># initialize a Context Aware File Splitting Model and fit it</span>

<span class="n">file_splitting_model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="p">(</span>
    <span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">ConnectedTextTokenizer</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># for an example run, you can take only a slice of training documents to make fitting faster</span>
<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">allow_empty_categories</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># save the model</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">include_konfuzio</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># run the prediction and see its confidence</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">test_document</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first. Confidence: </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">,</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page_confidence</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>

<span class="c1"># usage with the Splitting AI – you can load a pre-saved model or pass an initialized instance as the input</span>
<span class="c1"># in this example, we load a previously saved one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

<span class="c1"># initialize the Splitting AI</span>
<span class="n">splitting_ai</span> <span class="o">=</span> <span class="n">SplittingAI</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Splitting AI is a more high-level interface to Context Aware File Splitting Model and any other models that can be</span>
<span class="c1"># developed for File Splitting purposes. It takes a Document as an input, rather than individual Pages, because it</span>
<span class="c1"># utilizes page-level prediction of possible split points and returns Document or Documents with changes depending</span>
<span class="c1"># on the prediction mode.</span>

<span class="c1"># Splitting AI can be run in two modes: returning a list of Sub-Documents as the result of the input Document</span>
<span class="c1"># splitting or returning a copy of the input Document with Pages predicted as first having an attribute</span>
<span class="c1"># &quot;is_first_page&quot;. The flag &quot;return_pages&quot; has to be True for the latter; let&#39;s use it</span>
<span class="n">new_document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">test_document</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_document</span><span class="p">)</span>
<span class="c1"># output: [predicted_document]</span>

<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">new_document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first. Confidence: </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">,</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page_confidence</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="filesplittingevaluation-class">
<h3>FileSplittingEvaluation class<a class="headerlink" href="#filesplittingevaluation-class" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">FileSplittingEvaluation</span></code> class can be used to evaluate performance of Context-Aware File Splitting Model, returning a
set of metrics that includes precision, recall, f1 measure, True Positives, False Positives, True Negatives, and False
Negatives.</p>
<p>The class’s methods <code class="docutils literal notranslate"><span class="pre">calculate()</span></code> and <code class="docutils literal notranslate"><span class="pre">calculate_by_category()</span></code> are run at initialization. The class receives two lists
of Documents as an input – first list consists of ground-truth Documents where all first Pages are marked as such,
second is of Documents on Pages of which File Splitting Model ran a prediction of them being first or non-first.</p>
<p>The initialization would look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">FileSplittingEvaluation</span><span class="p">(</span>
    <span class="n">ground_truth_documents</span><span class="o">=</span><span class="n">YOUR_GROUND_TRUTH_LIST</span><span class="p">,</span> <span class="n">prediction_documents</span><span class="o">=</span><span class="n">YOUR_PREDICTION_LIST</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The class compares each pair of Pages. If a Page is labeled as first and the model also predicted it as first, it is
considered a True Positive. If a Page is labeled as first but the model predicted it as non-first, it is considered a
False Negative. If a Page is labeled as non-first but the model predicted it as first, it is considered a False
Positive. If a Page is labeled as non-first and the model also predicted it as non-first, it is considered a True
Negative.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>predicted correctly</p></th>
<th class="head"><p>predicted incorrectly</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>first Page</p></td>
<td><p>TP</p></td>
<td><p>FN</p></td>
</tr>
<tr class="row-odd"><td><p>non-first Page</p></td>
<td><p>TN</p></td>
<td><p>FP</p></td>
</tr>
</tbody>
</table>
<p>After iterating through all Pages of all Documents, precision, recall and f1 measure are calculated. If you wish to set
metrics to <code class="docutils literal notranslate"><span class="pre">None</span></code> in case there has been an attempt of zero division, set <code class="docutils literal notranslate"><span class="pre">allow_zero=True</span></code> at the initialization.</p>
<p>To see a certain metric after the class has been initialized, you can call a metric’s method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">())</span>
</pre></div>
</div>
<p>It is also possible to look at the metrics calculated by each Category independently. For this, pass
<code class="docutils literal notranslate"><span class="pre">search=YOUR_CATEGORY_HERE</span></code> when calling the wanted metric’s method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY</span><span class="p">))</span>
</pre></div>
</div>
<p>For more details, see the <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#ai-evaluation">Python API Documentation</a> on
Evaluation.</p>
<section id="example-of-evaluation-input-and-output">
<h4>Example of evaluation input and output<a class="headerlink" href="#example-of-evaluation-input-and-output" title="Permalink to this headline">¶</a></h4>
<p>Suppose in our test dataset we have 2 Documents of 2 Categories: one 3-paged, consisting of a single file (-&gt; it has
only one ground-truth first Page) of a first Category, and one 5-paged, consisting of three files: two 2-paged and one
1-paged (-&gt; it has three ground-truth first Pages), of a second Category.</p>
<img alt="../_images/document_example_1.png" src="../_images/document_example_1.png" />
<p><em>First document</em></p>
<img alt="../_images/document_example_2.png" src="../_images/document_example_2.png" />
<p><em>Second document</em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Document</span><span class="p">,</span> <span class="n">Page</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.evaluate</span> <span class="kn">import</span> <span class="n">FileSplittingEvaluation</span><span class="p">,</span> <span class="n">EvaluationCalculator</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">SplittingAI</span>

<span class="c1"># This example builds the Documents from scratch and without uploading a Supported File.</span>
<span class="c1"># If you uploaded your Document to the Konfuzio Server, you can just retrieve it with:</span>
<span class="c1"># document_1 = project.get_document_by_id(YOUR_DOCUMENT_ID)</span>
<span class="n">text_1</span> <span class="o">=</span> <span class="s2">&quot;Hi all,</span><span class="se">\n</span><span class="s2">I like bread.</span><span class="se">\n</span><span class="s2">I hope to get everything done soon.</span><span class="se">\n</span><span class="s2">Have you seen it?&quot;</span>
<span class="n">document_1</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">YOUR_PROJECT</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text_1</span><span class="p">,</span> <span class="n">dataset_status</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_1</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">29</span>
<span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_1</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">22</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">57</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">30</span>
<span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_1</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">58</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">31</span>
<span class="p">)</span>

<span class="c1"># As with the previous example Document, you can just retrieve an online Document with</span>
<span class="c1"># document_2 = project.get_document_by_id(YOUR_DOCUMENT_ID)</span>
<span class="n">text_2</span> <span class="o">=</span> <span class="s2">&quot;Evening,</span><span class="se">\n</span><span class="s2">thank you for coming.</span><span class="se">\n</span><span class="s2">I like fish.</span><span class="se">\n</span><span class="s2">I need it.</span><span class="se">\n</span><span class="s2">Evening.&quot;</span>
<span class="n">document_2</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">YOUR_PROJECT</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text_2</span><span class="p">,</span> <span class="n">dataset_status</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">32</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">33</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">31</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">43</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">34</span>
<span class="p">)</span>
<span class="n">_</span><span class="o">.</span><span class="n">is_first_page</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">44</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">54</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">35</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">55</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">63</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">copy_of_id</span><span class="o">=</span><span class="mi">36</span>
<span class="p">)</span>
<span class="n">_</span><span class="o">.</span><span class="n">is_first_page</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p>We need to pass two lists of Documents into the <code class="docutils literal notranslate"><span class="pre">FileSplittingEvaluation</span></code> class. So, before that, we need to run each
Page of the Documents through the model’s prediction.</p>
<p>Let’s say the evaluation gave good results, with only one first Page being predicted as non-first and all the other
Pages being predicted correctly. An example of how the evaluation would be implemented would be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">splitting_ai</span> <span class="o">=</span> <span class="n">SplittingAI</span><span class="p">(</span><span class="n">YOUR_MODEL</span><span class="p">)</span>
<span class="n">pred_1</span><span class="p">:</span> <span class="n">Document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">document_1</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pred_2</span><span class="p">:</span> <span class="n">Document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">document_2</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">evaluation</span> <span class="o">=</span> <span class="n">FileSplittingEvaluation</span><span class="p">(</span>
    <span class="n">ground_truth_documents</span><span class="o">=</span><span class="p">[</span><span class="n">document_1</span><span class="p">,</span> <span class="n">document_2</span><span class="p">],</span> <span class="n">prediction_documents</span><span class="o">=</span><span class="p">[</span><span class="n">pred_1</span><span class="p">,</span> <span class="n">pred_2</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tp</span><span class="p">())</span>
<span class="c1"># returns: 3</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tn</span><span class="p">())</span>
<span class="c1"># returns: 4</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fp</span><span class="p">())</span>
<span class="c1"># returns: 0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">())</span>
<span class="c1"># returns: 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">())</span>
<span class="c1"># returns: 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">())</span>
<span class="c1"># returns: 0.75</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">())</span>
<span class="c1"># returns: 0.85</span>
</pre></div>
</div>
<p>Our results could be reflected in a following table:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>TPs</p></th>
<th class="head"><p>TNs</p></th>
<th class="head"><p>FPs</p></th>
<th class="head"><p>FNs</p></th>
<th class="head"><p>precision</p></th>
<th class="head"><p>recall</p></th>
<th class="head"><p>F1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>3</p></td>
<td><p>4</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0.75</p></td>
<td><p>0.85</p></td>
</tr>
</tbody>
</table>
<p>If we want to see evaluation results by Category, the implementation of the Evaluation would look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">tp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">tn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 2 2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">fp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 0 0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 0 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 0.66</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 0.8</span>
</pre></div>
</div>
<p>the output could be reflected in a following table:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>TPs</p></th>
<th class="head"><p>TNs</p></th>
<th class="head"><p>FPs</p></th>
<th class="head"><p>FNs</p></th>
<th class="head"><p>precision</p></th>
<th class="head"><p>recall</p></th>
<th class="head"><p>F1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Category 1</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Category 2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0.66</p></td>
<td><p>0.8</p></td>
</tr>
</tbody>
</table>
<p>To log metrics after evaluation, you can call <code class="docutils literal notranslate"><span class="pre">EvaluationCalculator</span></code>‘s method <code class="docutils literal notranslate"><span class="pre">metrics_logging</span></code> (you would need to
specify the metrics accordingly at the class’s initialization). Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">EvaluationCalculator</span><span class="p">(</span><span class="n">tp</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">fp</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tn</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">metrics_logging</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="document-categorization">
<h2>Document Categorization<a class="headerlink" href="#document-categorization" title="Permalink to this headline">¶</a></h2>
<section id="working-with-the-category-of-a-document-and-its-individual-pages">
<h3>Working with the Category of a Document and its individual Pages<a class="headerlink" href="#working-with-the-category-of-a-document-and-its-individual-pages" title="Permalink to this headline">¶</a></h3>
<p>You can initialize a Document with a Category, which will count as if a human manually revised it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">my_category</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_category_by_id</span><span class="p">(</span><span class="n">YOUR_CATEGORY_ID</span><span class="p">)</span>

<span class="n">my_document</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;My text.&quot;</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">my_category</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">my_document</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">my_category</span>
<span class="n">my_document</span><span class="o">.</span><span class="n">set_category</span><span class="p">(</span><span class="n">my_category</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">my_document</span><span class="o">.</span><span class="n">category_is_revised</span> <span class="ow">is</span> <span class="kc">True</span>
</pre></div>
</div>
<p>If a Document is initialized with no Category, it will automatically be set to NO_CATEGORY. Another Category can be
manually set later.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">document</span><span class="o">.</span><span class="n">set_category</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">document</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">project</span><span class="o">.</span><span class="n">no_category</span>
<span class="n">document</span><span class="o">.</span><span class="n">set_category</span><span class="p">(</span><span class="n">my_category</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">document</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">my_category</span>
<span class="k">assert</span> <span class="n">document</span><span class="o">.</span><span class="n">category_is_revised</span> <span class="ow">is</span> <span class="kc">True</span>
<span class="c1"># This will set it for all of its Pages as well.</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">page</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">my_category</span>
</pre></div>
</div>
<p>If you use a Categorization AI to automatically assign a Category to a Document (such as the
<a class="reference external" href="tutorials.html#name-based-categorization-ai">NameBasedCategorizationAI</a>), each Page will be assigned a
Category Annotation with predicted confidence information, and the following properties will be accessible. You can
also find these documented under <a class="reference external" href="sourcecode.html#document">API Reference - Document</a>,
<a class="reference external" href="sourcecode.html#page">API Reference - Page</a> and
<a class="reference external" href="sourcecode.html#category-annotation">API Reference - Category Annotation</a>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CategoryAnnotation.category</span></code></p></td>
<td><p>The AI predicted Category of this Category<span class="raw-html-m2r"><br></span>Annotation.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">CategoryAnnotation.confidence</span></code></p></td>
<td><p>The AI predicted confidence of this Category<span class="raw-html-m2r"><br></span>Annotation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Document.category_annotations</span></code></p></td>
<td><p>List of predicted Category Annotations at the<span class="raw-html-m2r"><br></span>Document level.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Document.maximum_confidence_category_annotation</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>Annotation, or the human revised one if present.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Document.maximum_confidence_category</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>or the human revised one if present.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Document.category</span></code></p></td>
<td><p>Returns a Category only if all Pages have same<span class="raw-html-m2r"><br></span>Category, otherwise None. In that case, it hints<span class="raw-html-m2r"><br></span>to the fact that the Document should probably<span class="raw-html-m2r"><br></span>be revised or split into Documents with<span class="raw-html-m2r"><br></span>consistently categorized Pages.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Page.category_annotations</span></code></p></td>
<td><p>List of predicted Category Annotations at the<span class="raw-html-m2r"><br></span>Page level.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Page.maximum_confidence_category_annotation</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>Annotation or the one revised by the user for this<span class="raw-html-m2r"><br></span>Page.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Page.category</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>or the one revised by user for this Page.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="name-based-categorization-ai">
<h3>Name-based Categorization AI<a class="headerlink" href="#name-based-categorization-ai" title="Permalink to this headline">¶</a></h3>
<p>Use the name of the Category as an effective fallback logic to categorize Documents when no Categorization AI is available:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">NameBasedCategorizationAI</span>

<span class="c1"># Set up your Project.</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>

<span class="c1"># Initialize the Categorization Model.</span>
<span class="n">categorization_model</span> <span class="o">=</span> <span class="n">NameBasedCategorizationAI</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>

<span class="c1"># Retrieve a Document to categorize.</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># The Categorization Model returns a copy of the SDK Document with Category attribute</span>
<span class="c1"># (use inplace=True to maintain the original Document instead).</span>
<span class="c1"># If the input Document is already categorized, the already present Category is used</span>
<span class="c1"># (use recategorize=True if you want to force a recategorization).</span>
<span class="n">result_doc</span> <span class="o">=</span> <span class="n">categorization_model</span><span class="o">.</span><span class="n">categorize</span><span class="p">(</span><span class="n">document</span><span class="o">=</span><span class="n">test_document</span><span class="p">)</span>

<span class="c1"># Each Page is categorized individually.</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">result_doc</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">page</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found category </span><span class="si">{</span><span class="n">page</span><span class="o">.</span><span class="n">category</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># The Category of the Document is defined when all pages&#39; Categories are equal.</span>
<span class="c1"># If the Document contains mixed Categories, only the Page level Category will be defined,</span>
<span class="c1"># and the Document level Category will be NO_CATEGORY.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found category </span><span class="si">{</span><span class="n">result_doc</span><span class="o">.</span><span class="n">category</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">result_doc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-based-categorization-ai">
<h3>Model-based Categorization AI<a class="headerlink" href="#model-based-categorization-ai" title="Permalink to this headline">¶</a></h3>
<p>Build, train and test a Categorization AI using Image Models and Text Models to classify the image and text of each Page.</p>
<p>For a list of available Models see <a class="reference external" href="#categorization-models-available">Available Categorization Models</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span><span class="p">,</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">build_categorization_ai_pipeline</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">ImageModel</span><span class="p">,</span> <span class="n">TextModel</span><span class="p">,</span> <span class="n">CategorizationAI</span>

<span class="c1"># Set up your Project.</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build the Categorization AI architecture using a template</span>
<span class="c1"># of pre-built Image and Text classification Models.</span>
<span class="n">categorization_pipeline</span> <span class="o">=</span> <span class="n">build_categorization_ai_pipeline</span><span class="p">(</span>
    <span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span>
    <span class="n">documents</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">documents</span><span class="p">,</span>
    <span class="n">test_documents</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">test_documents</span><span class="p">,</span>
    <span class="n">image_model</span><span class="o">=</span><span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB0</span><span class="p">,</span>
    <span class="n">text_model</span><span class="o">=</span><span class="n">TextModel</span><span class="o">.</span><span class="n">NBOWSelfAttention</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Train the AI.</span>
<span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;Adam&#39;</span><span class="p">})</span>

<span class="c1"># Evaluate the AI</span>
<span class="n">data_quality</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">use_training_docs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ai_quality</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">data_quality</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="mf">1.0</span>
<span class="k">assert</span> <span class="n">ai_quality</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="mf">1.0</span>

<span class="c1"># Categorize a Document</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">categorization_result</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">categorize</span><span class="p">(</span><span class="n">document</span><span class="o">=</span><span class="n">document</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">categorization_result</span><span class="p">,</span> <span class="n">Document</span><span class="p">)</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">categorization_result</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found category </span><span class="si">{</span><span class="n">page</span><span class="o">.</span><span class="n">category</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Save and load a pickle file for the AI</span>
<span class="n">pickle_ai_path</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="n">categorization_pipeline</span> <span class="o">=</span> <span class="n">CategorizationAI</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">pickle_ai_path</span><span class="p">)</span>
</pre></div>
</div>
<section id="id2">
<h4>Available Categorization Models<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>When using <code class="docutils literal notranslate"><span class="pre">build_categorization_ai_pipeline</span></code>, you can select which Image Module and/or Text Module to use for
classification. At least one between the Image Model or the Text Model must be specified. Both can also be used
at the same time.</p>
<p>The list of available Categorization Models is implemented as an Enum containing the following elements:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">ImageModel</span><span class="p">,</span> <span class="n">TextModel</span>

<span class="c1"># Image Models</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG11</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG13</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG16</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG19</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB0</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB1</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB2</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB3</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB4</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB5</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB6</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB7</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB8</span>

<span class="c1"># Text Models</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">NBOW</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">NBOWSelfAttention</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">LSTM</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">BERT</span>
</pre></div>
</div>
<p>See more details about these Categorization Models under <a class="reference external" href="sourcecode.html#categorization-ai">API Reference - Categorization AI</a>.</p>
</section>
</section>
<section id="categorization-ai-overview-diagram">
<h3>Categorization AI Overview Diagram<a class="headerlink" href="#categorization-ai-overview-diagram" title="Permalink to this headline">¶</a></h3>
<p>In the first diagram, we show the class hierarchy of the available Categorization Models within the SDK. Note that the
Multimodal Model simply consists of a Multi Layer Perceptron to concatenate the feature outputs of a Text Model and an
Image Model, such that the predictions from both Models can be unified in a unique Category prediction.</p>
<p>In the second diagram, we show how these models are contained within a Model-based Categorization AI. The
<a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#categorization-ai">Categorization AI</a> class provides the high level
interface to categorize Documents, as exemplified in the code examples above. It uses a Page Categorization Model
to categorize each Page. The Page Categorization Model is a container for Categorization Models: it wraps the feature
output layers of each contained Model with a Dropout Layer and a Fully Connected Layer.</p>
<p><span class="raw-html-m2r"><div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;url&quot;:&quot;https://raw.githubusercontent.com/konfuzio-ai/konfuzio-sdk/master/docs/sdk/examples/document_categorization/CategorizationAI.drawio&quot;}"></div></span></p>
<script type="text/javascript" src="https://viewer.diagrams.net/embed2.js?&fetch=https%3A%2F%2Fraw.githubusercontent.com%2Fkonfuzio-ai%2Fkonfuzio-sdk%2Fmaster%2Fdocs%2Fsdk%2Fexamples%2Fdocument_categorization%2FCategorizationAI.drawio"></script></section>
</section>
<section id="document-information-extraction">
<h2>Document Information Extraction<a class="headerlink" href="#document-information-extraction" title="Permalink to this headline">¶</a></h2>
<section id="train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents">
<h3>Train a Konfuzio SDK Model to Extract Information From Payslip Documents<a class="headerlink" href="#train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents" title="Permalink to this headline">¶</a></h3>
<p>The tutorial <em>RFExtractionAI Demo</em> aims to show you how to use the Konfuzio SDK package to use a simple <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#konfuzio_sdk.tokenizer.regex.WhitespaceTokenizer">Whitespace
tokenizer</a> and to
train a “RFExtractionAI” model to find and extract relevant information like Name, Date and Recipient
from payslip documents.</p>
<p>You can <img alt="OpenInColab" src="https://colab.research.google.com/assets/colab-badge.svg" /> or download it from <a class="reference external" href="https://github.com/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/RFExtractionAI%20Demo.ipynb">here</a>
and try it by yourself.</p>
</section>
<section id="customize-extraction-ai">
<h3>Customize Extraction AI<a class="headerlink" href="#customize-extraction-ai" title="Permalink to this headline">¶</a></h3>
<p>Any Custom <a class="reference external" href="sourcecode.html#extraction-ai">Extraction AI</a> (derived from the Konfuzio <code class="docutils literal notranslate"><span class="pre">AbstractExtractionAI</span></code> class) should implement
the following interface:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.information_extraction</span> <span class="kn">import</span> <span class="n">AbstractExtractionAI</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>


<span class="k">class</span> <span class="nc">CustomExtractionAI</span><span class="p">(</span><span class="n">AbstractExtractionAI</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="c1"># initialize key variables required by the custom AI</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

    <span class="c1"># Define architecture and training that the model undergoes, i.e. a NN architecture or a custom hardcoded logic</span>
    <span class="c1"># This method is allowed to be implemented as a no-op if you provide the trained model in other ways</span>

    <span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="n">Document</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Document</span><span class="p">:</span>
<span class="c1"># define how the model extracts information from Documents</span>
<span class="c1"># **NB:** The result of extraction must be a copy of the input Document with added Annotations attribute `Document._annotations`</span>
</pre></div>
</div>
<p>Example usage of your Custom Extraction AI:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span><span class="p">,</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.information_extraction</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="c1"># Initialize Project and provide the AI training and test data</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>  <span class="c1"># see https://dev.konfuzio.com/sdk/get_started.html#example-usage</span>

<span class="n">extraction_pipeline</span> <span class="o">=</span> <span class="n">CustomExtractionAI</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">category</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_category_by_id</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_CATEGORY_ID</span><span class="p">)</span>
<span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">category</span><span class="o">.</span><span class="n">documents</span><span class="p">()</span>
<span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">test_documents</span> <span class="o">=</span> <span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">category</span><span class="o">.</span><span class="n">test_documents</span><span class="p">()</span>

<span class="c1"># Train the AI</span>
<span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Evaluate the AI</span>
<span class="n">data_quality</span> <span class="o">=</span> <span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">evaluate_full</span><span class="p">(</span><span class="n">use_training_docs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ai_quality</span> <span class="o">=</span> <span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">evaluate_full</span><span class="p">(</span><span class="n">use_training_docs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Extract a Document</span>
<span class="n">document</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">extraction_result</span><span class="p">:</span> <span class="n">Document</span> <span class="o">=</span> <span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">document</span><span class="o">=</span><span class="n">document</span><span class="p">)</span>

<span class="c1"># Save and load a pickle file for the model</span>
<span class="n">pickle_model_path</span> <span class="o">=</span> <span class="n">extraction_pipeline</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">model_folder</span><span class="p">,</span> <span class="n">include_konfuzio</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">extraction_pipeline_loaded</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">pickle_model_path</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-of-custom-extraction-ai-the-paragraph-extraction-ai">
<h3>Example of Custom Extraction AI: The Paragraph Extraction AI<a class="headerlink" href="#example-of-custom-extraction-ai-the-paragraph-extraction-ai" title="Permalink to this headline">¶</a></h3>
<p>In <a class="reference internal" href="#paragraph-tokenizer-tutorial"><span class="std std-ref">the Paragraph Tokenizer tutorial</span></a>, we saw how we can use the Paragraph Tokenizer
in <code class="docutils literal notranslate"><span class="pre">detectron</span></code> mode and with the <code class="docutils literal notranslate"><span class="pre">create_detectron_labels</span></code> option to segment a Document and create <code class="docutils literal notranslate"><span class="pre">figure</span></code>, <code class="docutils literal notranslate"><span class="pre">table</span></code>,
<code class="docutils literal notranslate"><span class="pre">list</span></code>, <code class="docutils literal notranslate"><span class="pre">text</span></code> and <code class="docutils literal notranslate"><span class="pre">title</span></code> Annotations. The tokenizer used this way is thus able to create Annotations like in the
following:</p>
<a class="reference internal image-reference" href="../_images/paragraph_tokenizer.png"><img alt="../_images/paragraph_tokenizer.png" src="../_images/paragraph_tokenizer.png" style="width: 411.6px; height: 582.4px;" /></a>
<p>Here we will see how we can use the Paragraph Tokenizer to create a Custom Extraction AI. What we need to create is
just a simple wrapper around the Paragraph Tokenizer. It shows how you can create your own Custom Extraction AI that
you can use in Konfuzio on-prem installations or in the <a class="reference external" href="https://help.konfuzio.com/marketplace/index.html">Konfuzio Marketplace</a>.</p>
<details class="summary-full-paragraph-extraction-ai-code">
<summary>Full Paragraph Extraction AI code</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ParagraphExtractionAI</span><span class="p">(</span><span class="n">AbstractExtractionAI</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract and label text regions using Detectron2.&quot;&quot;&quot;</span>

    <span class="c1"># start model requirements</span>
    <span class="n">requires_images</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">requires_text</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">requires_segmentation</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="c1"># end model requirements</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">category</span><span class="p">:</span> <span class="n">Category</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize ParagraphExtractionAI.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing ParagraphExtractionAI.&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="n">category</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ParagraphTokenizer</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;detectron&#39;</span><span class="p">,</span> <span class="n">create_detectron_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="n">Document</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Document</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Infer information from a given Document.</span>

<span class="sd">        :param document: Document object</span>
<span class="sd">        :return: Document with predicted Labels</span>

<span class="sd">        :raises:</span>
<span class="sd">        AttributeError: When missing a Tokenizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting extraction of </span><span class="si">{</span><span class="n">document</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">check_is_ready</span><span class="p">()</span>

        <span class="n">inference_document</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>

        <span class="n">inference_document</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">inference_document</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inference_document</span>

    <span class="k">def</span> <span class="nf">check_is_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if the ExtractionAI is ready for the inference.</span>

<span class="sd">        :raises AttributeError: When no Category is specified.</span>
<span class="sd">        :raises IndexError: When the Category does not contain the required Labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">check_is_ready</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;figure&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;table&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;list&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;text&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
</details><p><span class="raw-html-m2r"><br/></span>
Let’s go step by step.</p>
<ol class="arabic">
<li><p><strong>Imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.information_extraction</span> <span class="kn">import</span> <span class="n">AbstractExtractionAI</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.paragraph_and_sentence</span> <span class="kn">import</span> <span class="n">ParagraphTokenizer</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Category</span><span class="p">,</span> <span class="n">Document</span><span class="p">,</span> <span class="n">Project</span><span class="p">,</span> <span class="n">Label</span>

</pre></div>
</div>
</li>
<li><p><strong>Custom Extraction AI model definition</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ParagraphExtractionAI</span><span class="p">(</span><span class="n">AbstractExtractionAI</span><span class="p">):</span>
</pre></div>
</div>
<p>We define a class that inherits from the Konfuzio <code class="docutils literal notranslate"><span class="pre">AbstractExtractionAI</span></code> class. This class provides the interface
that we need to implement for our Custom Extraction AI. All Extraction AI models must inherit from this class.</p>
</li>
<li><p><strong>Add model requirements</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">requires_images</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">requires_text</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">requires_segmentation</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p>We need to define what the model needs to be able to run. This will inform the Konfuzio Server what information needs
to be made available to the model before running an extraction. If the model only needs text, you can ignore this step
or add <code class="docutils literal notranslate"><span class="pre">requires_text</span> <span class="pre">=</span> <span class="pre">True</span></code> to make it explicit. If the model requires Page images, you will need to add
<code class="docutils literal notranslate"><span class="pre">requires_images</span> <span class="pre">=</span> <span class="pre">True</span></code>. Finally, in our case we also need to add <code class="docutils literal notranslate"><span class="pre">requires_segmentation</span> <span class="pre">=</span> <span class="pre">True</span></code> to inform the Server
that the model needs the visual segmentation information created by the Paragraph Tokenizer in <code class="docutils literal notranslate"><span class="pre">detectron</span></code> mode.</p>
</li>
<li><p><strong>Initialize the model</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
   <span class="bp">self</span><span class="p">,</span>
   <span class="n">category</span><span class="p">:</span> <span class="n">Category</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
   <span class="o">*</span><span class="n">args</span><span class="p">,</span>
   <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">   </span><span class="sd">&quot;&quot;&quot;Initialize ParagraphExtractionAI.&quot;&quot;&quot;</span>
   <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing ParagraphExtractionAI.&quot;</span><span class="p">)</span>
   <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="n">category</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
   <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ParagraphTokenizer</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;detectron&#39;</span><span class="p">,</span> <span class="n">create_detectron_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>We initialize the model by calling the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method of the parent class. The only required argument is the
Category the Extraction AI will be used with. The Category is the Konfuzio object that contains all the Labels
and LabelSets that the model will use to create Annotations. This means that you need to make sure that the Category
object contains all the Labels and LabelSets that you need for your model. In our case, we need the <code class="docutils literal notranslate"><span class="pre">figure</span></code>, <code class="docutils literal notranslate"><span class="pre">table</span></code>,
<code class="docutils literal notranslate"><span class="pre">list</span></code>, <code class="docutils literal notranslate"><span class="pre">text</span></code> and <code class="docutils literal notranslate"><span class="pre">title</span></code> Labels.</p>
</li>
<li><p><strong>Define the extract method</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="n">Document</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Document</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Infer information from a given Document.</span>

<span class="sd">        :param document: Document object</span>
<span class="sd">        :return: Document with predicted Labels</span>

<span class="sd">        :raises:</span>
<span class="sd">        AttributeError: When missing a Tokenizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting extraction of </span><span class="si">{</span><span class="n">document</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">check_is_ready</span><span class="p">()</span>

        <span class="n">inference_document</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>

        <span class="n">inference_document</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">inference_document</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inference_document</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">extract</span></code> method is the core of the Extraction AI. It takes a Document as input and returns a Document with
Annotations. Make sure to do a <code class="docutils literal notranslate"><span class="pre">deepcopy</span></code> of the Document that is passed so that you add the new Annotations to a
Virtual Document with no Annotations. The Annotations are created by the model and added to the Document. In our
case, we simply call the Paragraph Tokenizer in <code class="docutils literal notranslate"><span class="pre">detectron</span></code> mode and with the <code class="docutils literal notranslate"><span class="pre">create_detectron_labels</span></code> option.</p>
</li>
<li><p><strong>[OPTIONAL] Define the check_is_ready method</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">check_is_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if the ExtractionAI is ready for the inference.</span>

<span class="sd">        :raises AttributeError: When no Category is specified.</span>
<span class="sd">        :raises IndexError: When the Category does not contain the required Labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">check_is_ready</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;figure&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;table&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;list&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;text&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">check_is_ready</span></code> method is used to check if the model is ready to be used. It should return <code class="docutils literal notranslate"><span class="pre">True</span></code> if the model
is ready to extract, and <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. It is checked before saving the model. You don’t have to implement it,
and it will only check that a Category is defined.</p>
<p>In our case, we also check that the model contains all the Labels that we need. This is not strictly necessary, but
it is a good practice to make sure that the model is ready to be used.</p>
</li>
<li><p><strong>Use the model locally</strong></p>
<p>We first make sure that all needed Labels are present in the Category.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">TEST_PROJECT_ID</span><span class="p">)</span>
<span class="n">category</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_category_by_id</span><span class="p">(</span><span class="n">TEST_PAYSLIPS_CATEGORY_ID</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;figure&#39;</span><span class="p">,</span> <span class="s1">&#39;table&#39;</span><span class="p">,</span> <span class="s1">&#39;list&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;title&#39;</span><span class="p">]</span>

<span class="c1"># creating Labels in case they do not exist</span>
<span class="n">label_set</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_set_by_name</span><span class="p">(</span><span class="n">category</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>  <span class="c1"># default Category label set</span>

<span class="k">for</span> <span class="n">label_name</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">label_name</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
        <span class="n">Label</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">label_name</span><span class="p">,</span> <span class="n">label_sets</span><span class="o">=</span><span class="p">[</span><span class="n">label_set</span><span class="p">])</span>
</pre></div>
</div>
<p>We can now use the model to extract a Document. And then we also can run extract on a Document and save the model to
a pickle file that can be used in Konfuzio Server.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">TEST_DOCUMENT_ID</span><span class="p">)</span>

<span class="n">paragraph_extraction_ai</span> <span class="o">=</span> <span class="n">ParagraphExtractionAI</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="n">category</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">paragraph_extraction_ai</span><span class="o">.</span><span class="n">check_is_ready</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">True</span>

<span class="n">extracted_document</span> <span class="o">=</span> <span class="n">paragraph_extraction_ai</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">extracted_document</span><span class="o">.</span><span class="n">annotations</span><span class="p">(</span><span class="n">use_correct</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>  <span class="c1"># Show all the created Annotations</span>

<span class="n">model_path</span> <span class="o">=</span> <span class="n">paragraph_extraction_ai</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</pre></div>
</div>
</li>
<li><p><strong>Upload the model to Konfuzio Server</strong></p>
<p>You can use the Konfuzio SDK to upload your model to your on-prem installation like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.api</span> <span class="kn">import</span> <span class="n">upload_ai_model</span>

<span class="n">upload_ai_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">category_ids</span><span class="o">=</span><span class="p">[</span><span class="n">category</span><span class="o">.</span><span class="n">id_</span><span class="p">])</span>
</pre></div>
</div>
<p>Once the model is uploaded you can also share your model with others on the <a class="reference external" href="https://help.konfuzio.com/marketplace/index.html">Konfuzio Marketplace</a>.</p>
</li>
</ol>
</section>
<section id="evaluate-a-trained-extraction-ai-model">
<h3>Evaluate a Trained Extraction AI Model<a class="headerlink" href="#evaluate-a-trained-extraction-ai-model" title="Permalink to this headline">¶</a></h3>
<p>In this example we will see how we can evaluate a trained <code class="docutils literal notranslate"><span class="pre">RFExtractionAI</span></code> model. We will assume that we have a trained
pickled model available. See <a class="reference external" href="https://dev.konfuzio.com/sdk/examples/examples.html#train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents">here</a>
for how to train such a model, and check out the <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#ai-evaluation">Evaluation</a>
documentation for more details.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">RFExtractionAI</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># To get the evaluation of the full pipeline</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_full</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Full evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Full evaluation recall: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Full evaluation precision: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># To get the evaluation of the Tokenizer alone</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_tokenizer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tokenizer_f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># To get the evaluation of the Label classifier given perfect tokenization</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_clf</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label classifier evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">clf_f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># To get the evaluation of the LabelSet given perfect Label classification</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_clf</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label Set evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="paragraph-and-sentence-tokenizer">
<h2>Paragraph and Sentence Tokenizer<a class="headerlink" href="#paragraph-and-sentence-tokenizer" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">ParagraphTokenizer</span></code> and <code class="docutils literal notranslate"><span class="pre">SentenceTokenizer</span></code> are used to split a document into paragraphs and sentences
respectively. They both come with two different modes: <code class="docutils literal notranslate"><span class="pre">detectron</span></code> and <code class="docutils literal notranslate"><span class="pre">line_distance</span></code>. The <code class="docutils literal notranslate"><span class="pre">detectron</span></code> mode uses a
fine-tuned <a class="reference external" href="https://github.com/facebookresearch/detectron2">Detectron2</a> model to detect paragraph Annotations. The
<code class="docutils literal notranslate"><span class="pre">line_distance</span></code> mode uses a rule based approach, and is therefore faster, but tends to be less accurate. In particular,
it fails to handle documents with two columns. The <code class="docutils literal notranslate"><span class="pre">detectron</span></code> mode is the default. It can also be used together with
the <code class="docutils literal notranslate"><span class="pre">create_detectron_labels</span></code> setting to create Annotations with the label given by our <a class="reference external" href="https://github.com/facebookresearch/detectron2">Detectron2</a> model:
<code class="docutils literal notranslate"><span class="pre">figure</span></code>, <code class="docutils literal notranslate"><span class="pre">table</span></code>, <code class="docutils literal notranslate"><span class="pre">list</span></code>, <code class="docutils literal notranslate"><span class="pre">text</span></code> and <code class="docutils literal notranslate"><span class="pre">title</span></code>.</p>
<section id="paragraph-tokenizer">
<span id="paragraph-tokenizer-tutorial"></span><h3>Paragraph Tokenizer<a class="headerlink" href="#paragraph-tokenizer" title="Permalink to this headline">¶</a></h3>
<p>For example, to tokenize a Document into paragraphs using the <code class="docutils literal notranslate"><span class="pre">ParagraphTokenizer</span></code> in <code class="docutils literal notranslate"><span class="pre">detectron</span></code> mode and the
<code class="docutils literal notranslate"><span class="pre">create_detectron_labels</span></code> option to use the labels provided by our Detectron model, you can use the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.paragraph_and_sentence</span> <span class="kn">import</span> <span class="n">ParagraphTokenizer</span>

<span class="c1"># initialize a Project and fetch a Document to tokenize</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># create the ParagraphTokenizer and tokenize the Document</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ParagraphTokenizer</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;detectron&#39;</span><span class="p">,</span> <span class="n">create_detectron_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">document</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting Annotations will look like this:</p>
<img alt="../_images/paragraph_tokenizer.png" src="../_images/paragraph_tokenizer.png" />
</section>
<section id="sentence-tokenizer">
<h3>Sentence Tokenizer<a class="headerlink" href="#sentence-tokenizer" title="Permalink to this headline">¶</a></h3>
<p>If you are interested in a more fine-grained tokenization, you can use the <code class="docutils literal notranslate"><span class="pre">SentenceTokenizer</span></code>. It can be used to create
Annotations for each individual sentence in a text Document. To use it, you can use the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.paragraph_and_sentence</span> <span class="kn">import</span> <span class="n">SentenceTokenizer</span>

<span class="c1"># initialize a Project and fetch a Document to tokenize</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># create the SentenceTokenizer and tokenize the Document</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SentenceTokenizer</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;detectron&#39;</span><span class="p">)</span>

<span class="n">document</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting Annotations will look like this:</p>
<img alt="../_images/sentence_tokenizer.png" src="../_images/sentence_tokenizer.png" />
</section>
</section>
<section id="data-validation-rules">
<h2>Data Validation Rules<a class="headerlink" href="#data-validation-rules" title="Permalink to this headline">¶</a></h2>
<p>Konfuzio automatically applies a set of rules for validating data within a <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#project">Project</a>.
Data Validation Rules ensure that Training and Test data is consistent and well formed for training an
<a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#extraction-ai">Extraction AI</a> with Konfuzio.</p>
<p>In general, if a Document fails any of the checks described in the next sections, it will not be possible to train an
AI with that Document.</p>
<p>More specifically:</p>
<ul class="simple">
<li><p>If a Document fails any of the checks described in the <a class="reference external" href="#id7">Bbox Validation Rules</a> section, it
will not be possible to initialize the Project as a Python object (such as with
<code class="docutils literal notranslate"><span class="pre">project</span> <span class="pre">=</span> <span class="pre">Project(YOUR_PROJECT_ID)</span></code>), and a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised. All other Documents in the Project will be
able to be initialized.</p></li>
<li><p>If a Document fails any of the checks described in the sections
<a class="reference external" href="#id5">Annotation Validation Rules</a> and <a class="reference external" href="#id6">Span Validation Rules</a>, it
will not be possible to retrieve the Annotations (including their Spans) that fail the specific checks (such as with
<code class="docutils literal notranslate"><span class="pre">annotation</span> <span class="pre">=</span> <span class="pre">document.get_annotation_by_id(YOUR_ANNOTATION_ID)</span></code>), and a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised. All other
Annotations in the Document will be retrievable.</p></li>
</ul>
<section id="initializing-a-project-with-the-data-validation-rules-enabled">
<h3>Initializing a Project with the Data Validation Rules enabled<a class="headerlink" href="#initializing-a-project-with-the-data-validation-rules-enabled" title="Permalink to this headline">¶</a></h3>
<p>By default, any <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#project">Project</a> has the Data Validation Rules enabled, so nothing
special needs to be done to enable it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>  <span class="c1"># all the data in this Project will be validated</span>
</pre></div>
</div>
</section>
<section id="document-validation-rules">
<h3>Document Validation Rules<a class="headerlink" href="#document-validation-rules" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#document">Document</a> passes the Data Validation Rules only if all the
contained Annotations, Spans and Bboxes pass the Data Validation Rules.
If at least one Annotation, Span, or Bbox within a Document fails one of the following checks, the entire Document is
marked as unsuitable for training an Extraction AI.</p>
</section>
<section id="annotation-validation">
<span id="id8"></span><h3>Annotation Validation Rules<a class="headerlink" href="#annotation-validation" title="Permalink to this headline">¶</a></h3>
<p>An <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#annotation">Annotation</a> passes the Data Validation Rules only if:</p>
<ol class="arabic simple">
<li><p>The Annotation is not from a Category different from the Document’s Category</p></li>
<li><p>The Annotation is not entirely overlapping with another Annotation with the same Label</p>
<ul class="simple">
<li><p>It implies that partial overlaps with same Labels are allowed</p></li>
<li><p>It implies that full overlaps with different Labels are allowed</p></li>
</ul>
</li>
<li><p>The Annotation has at least one Span</p></li>
</ol>
<p>Please note that the Annotation Validation Rules are indifferent about the values of <code class="docutils literal notranslate"><span class="pre">Annotation.is_correct</span></code> or <code class="docutils literal notranslate"><span class="pre">Annotation.revised</span></code>.
For more information about what these boolean values mean, see <a class="reference external" href="https://help.konfuzio.com/modules/annotations/index.html">Konfuzio Server - Annotations</a>.</p>
</section>
<section id="span-validation">
<span id="id9"></span><h3>Span Validation Rules<a class="headerlink" href="#span-validation" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#span">Span</a> passes the Data Validation Rules only if:</p>
<ol class="arabic simple">
<li><p>The Span contains non-empty text (the start offset must be strictly greater than the end offset)</p></li>
<li><p>The Span is contained within a single line of text (must not be distributed across multiple lines)</p></li>
</ol>
</section>
<section id="bbox-validation">
<span id="id10"></span><h3>Bbox Validation Rules<a class="headerlink" href="#bbox-validation" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#bbox">Bbox</a> passes the Data Validation Rules only if:</p>
<ol class="arabic simple">
<li><p>The Bbox has non-negative width and height (zero is allowed for compatibility reasons with many OCR engines)</p></li>
<li><p>The Bbox is entirely contained within the bounds of a Page</p></li>
<li><p>The character that is mapped by the Bbox must correspond to the text in the Document</p></li>
</ol>
</section>
<section id="initializing-a-project-with-the-data-validation-rules-disabled">
<h3>Initializing a Project with the Data Validation Rules disabled<a class="headerlink" href="#initializing-a-project-with-the-data-validation-rules-disabled" title="Permalink to this headline">¶</a></h3>
<p>By default, any <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#project">Project</a> has the Data Validation Rules enabled.</p>
<p>A possible reason for choosing to disable the Data Validation Rules that come with the Konfuzio SDK, is that an expert user
wants to define a custom data structure or training pipeline which violates some assumptions normally present in Konfuzio
Extraction AIs and pipelines.
If you don’t want to validate your data, you should initialize the Project with <code class="docutils literal notranslate"><span class="pre">strict_data_validation=False</span></code>.</p>
<p>We highly recommend to keep the Data Validation Rules enabled at all times, as it ensures that Training and Test data
is consistent for training an Extraction AI. Disabling the Data Validation Rules and training an
<a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#extraction-ai">Extraction AI</a> with potentially duplicated, malformed,
or inconsistent data can <strong>decrease the quality of an Extraction AI</strong>. Only disable them if you know what you are doing.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">,</span> <span class="n">strict_data_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="find-possible-outliers-among-the-ground-truth-annotations">
<h2>Find possible outliers among the ground-truth Annotations<a class="headerlink" href="#find-possible-outliers-among-the-ground-truth-annotations" title="Permalink to this headline">¶</a></h2>
<p>If you want to ensure that Annotations of a Label are consistent and check for possible outliers, you can use one of
the <code class="docutils literal notranslate"><span class="pre">Label</span></code> class’s methods. There are three of them available.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">get_probable_outliers_by_regex</span></code> looks for the worst regexes used to find the Annotations. “Worst” is determined by
the number of True Positives calculated upon evaluating the regexes’ performance. Returns Annotations predicted by the
regexes with the least amount of True Positives. By default, the method returns Annotations retrieved by the regex that
performs on the level of 10% in comparison to the best one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>

<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers_by_regex</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_probable_outliers_by_confidence</span></code> looks for the Annotations with the least confidence level, provided it is lower
than the specified threshold (the default threshold is 0.5). Accepts an instance of EvaluationExtraction class as an input and uses confidence predictions from there.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>

<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers_by_regex</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers_by_confidence</span><span class="p">(</span><span class="n">evaluation</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_probable_outliers_by_normalization</span></code> looks for the Annotations that are unable to pass normalization by the data
type of the given Label (meaning that they are not of the same data type themselves, thus outliers).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers_by_normalization</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p>All three of the methods return a list of Annotations that are deemed outliers by the logic of the current method; the
contents of the output are not necessarily wrong, however, they may have some difference from the main body of the
Annotations under a given Label.</p>
<p>To have a more thorough check, you can use a method <code class="docutils literal notranslate"><span class="pre">get_probable_outliers</span></code> that allows for combining the
aforementioned methods or have them run together and return only those Annotations that were detected by all of them.</p>
<p>Here’s an example of running the latter method with one of the search methods disabled explicitly. By default, all
three of the search methods are enabled.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">confidence_search</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="create-regex-based-annotations">
<h2>Create Regex-based Annotations<a class="headerlink" href="#create-regex-based-annotations" title="Permalink to this headline">¶</a></h2>
<p><strong>Pro Tip</strong>: Read our technical blog post <a class="reference external" href="https://helm-nagel.com/Automated-Regex-Generation-based-on-examples">Automated Regex</a> to find out how we use Regex to detect outliers in our annotated data.</p>
<p>Let’s see a simple example of how can we use the <code class="docutils literal notranslate"><span class="pre">konfuzio_sdk</span></code> package to get information on a project and to post annotations.</p>
<p>You can follow the example below to post annotations of a certain word or expression in the first document uploaded.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span><span class="p">,</span> <span class="n">Annotation</span><span class="p">,</span> <span class="n">Span</span>

<span class="n">my_project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Word/expression to annotate in the Document</span>
<span class="c1"># should match an existing one in your Document</span>
<span class="n">input_expression</span> <span class="o">=</span> <span class="s2">&quot;Musterstraße&quot;</span>

<span class="c1"># Label for the Annotation</span>
<span class="n">label_name</span> <span class="o">=</span> <span class="s2">&quot;Lohnart&quot;</span>
<span class="c1"># Getting the Label from the Project</span>
<span class="n">my_label</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">label_name</span><span class="p">)</span>

<span class="c1"># LabelSet to which the Label belongs</span>
<span class="n">label_set</span> <span class="o">=</span> <span class="n">my_label</span><span class="o">.</span><span class="n">label_sets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># First Document in the Project</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Matches of the word/expression in the Document</span>
<span class="n">matches_locations</span> <span class="o">=</span> <span class="p">[(</span><span class="n">m</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">input_expression</span><span class="p">,</span> <span class="n">document</span><span class="o">.</span><span class="n">text</span><span class="p">)]</span>

<span class="c1"># List to save the links to the Annotations created</span>
<span class="n">new_annotations_links</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Create Annotation for each match</span>
<span class="k">for</span> <span class="n">offsets</span> <span class="ow">in</span> <span class="n">matches_locations</span><span class="p">:</span>
    <span class="n">span</span> <span class="o">=</span> <span class="n">Span</span><span class="p">(</span><span class="n">start_offset</span><span class="o">=</span><span class="n">offsets</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end_offset</span><span class="o">=</span><span class="n">offsets</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">annotation_obj</span> <span class="o">=</span> <span class="n">Annotation</span><span class="p">(</span>
        <span class="n">document</span><span class="o">=</span><span class="n">document</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">my_label</span><span class="p">,</span> <span class="n">label_set</span><span class="o">=</span><span class="n">label_set</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">spans</span><span class="o">=</span><span class="p">[</span><span class="n">span</span><span class="p">],</span> <span class="n">is_correct</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">new_annotation_added</span> <span class="o">=</span> <span class="n">annotation_obj</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">new_annotation_added</span><span class="p">:</span>
        <span class="n">new_annotations_links</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">annotation_obj</span><span class="o">.</span><span class="n">get_link</span><span class="p">())</span>
    <span class="n">annotation_obj</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">delete_online</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">new_annotations_links</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-label-regex-tokenizer">
<h2>Train Label Regex Tokenizer<a class="headerlink" href="#train-label-regex-tokenizer" title="Permalink to this headline">¶</a></h2>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">konfuzio_sdk</span></code> package to train a custom Regex tokenizer.</p>
<p>In this example, you will see how to find regex expressions that match with occurrences of the “Lohnart” Label in the
training data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">RegexTokenizer</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.base</span> <span class="kn">import</span> <span class="n">ListTokenizer</span>

<span class="n">my_project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">category</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_category_by_id</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_CATEGORY_ID</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ListTokenizer</span><span class="p">(</span><span class="n">tokenizers</span><span class="o">=</span><span class="p">[])</span>

<span class="n">label</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s2">&quot;Lohnart&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">regex</span> <span class="ow">in</span> <span class="n">label</span><span class="o">.</span><span class="n">find_regex</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="n">category</span><span class="p">):</span>
    <span class="n">regex_tokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="p">(</span><span class="n">regex</span><span class="o">=</span><span class="n">regex</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">regex_tokenizer</span><span class="p">)</span>

<span class="c1"># You can then use it to create an Annotation for every matching string in a Document.</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="finding-spans-of-a-label-not-found-by-a-tokenizer">
<h2>Finding Spans of a Label Not Found by a Tokenizer<a class="headerlink" href="#finding-spans-of-a-label-not-found-by-a-tokenizer" title="Permalink to this headline">¶</a></h2>
<p>Here is an example of how to use the <code class="docutils literal notranslate"><span class="pre">Label.spans_not_found_by_tokenizer</span></code> method. This will allow you to determine if a RegexTokenizer is suitable at finding the Spans of a Label, or what Spans might have been annotated wrong. Say, you have a number of annotations assigned to the <code class="docutils literal notranslate"><span class="pre">IBAN</span></code> Label and want to know which Spans would not be found when using the WhiteSpace Tokenizer. You can follow this example to find all the relevant Spans.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">WhitespaceTokenizer</span>

<span class="n">my_project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">category</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">categories</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">WhitespaceTokenizer</span><span class="p">()</span>

<span class="n">label</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;Austellungsdatum&#39;</span><span class="p">)</span>

<span class="n">spans_not_found</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">spans_not_found_by_tokenizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="n">category</span><span class="p">])</span>

<span class="k">for</span> <span class="n">span</span> <span class="ow">in</span> <span class="n">spans_not_found</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">span</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">span</span><span class="o">.</span><span class="n">offset_string</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="getting-word-bounding-box-bbox-for-a-document">
<h2>Getting Word Bounding Box (BBox) for a Document<a class="headerlink" href="#getting-word-bounding-box-bbox-for-a-document" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we will walk through how to extract the bounding box (<a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#bbox">BBox</a>)
for words in a Document, rather than for individual characters, using the Konfuzio SDK. This process involves the use of
the <code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code> from the Konfuzio SDK to tokenize the Document and identify word-level Spans, which can then
be visualized or used to extract BBox information.</p>
<section id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>You will need to have the Konfuzio SDK installed.</p></li>
<li><p>You should have access to a Project on the Konfuzio platform.</p></li>
</ul>
</section>
<section id="preview-of-result">
<h3>Preview of Result<a class="headerlink" href="#preview-of-result" title="Permalink to this headline">¶</a></h3>
<p><span class="raw-html-m2r"><img src="https://github.com/konfuzio-ai/konfuzio-sdk/assets/2879188/5f7a8501-cd89-487d-a332-0703f3c35fc8" data-canonical-src="https://github.com/konfuzio-ai/konfuzio-sdk/assets/2879188/5f7a8501-cd89-487d-a332-0703f3c35fc8" width="200" height="400" /></span></p>
</section>
<section id="steps">
<h3>Steps<a class="headerlink" href="#steps" title="Permalink to this headline">¶</a></h3>
<ol class="arabic">
<li><p><strong>Import necessary modules</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">WhitespaceTokenizer</span>

</pre></div>
</div>
</li>
<li><p><strong>Initialize your Project</strong>:</p>
<p>This involves creating a Project instance with the appropriate ID.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Retrieve a Document from your Project</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Create a copy of your Document without Annotations</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">document</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Tokenize the Document</strong>:</p>
<p>This process involves splitting the Document into word-level Spans using the <code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><strong>Visualize all word-level Annotations</strong>:</p>
<p>After getting the bounding box for all Spans, you might want to visually check the results to make sure the bounding
boxes are correctly assigned. Here’s how you can do it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">document</span><span class="o">.</span><span class="n">get_page_by_index</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">get_annotations_image</span><span class="p">(</span><span class="n">display_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/word-bboxes.png" src="../_images/word-bboxes.png" />
<p>This will display an image of the Document with all word-level Annotations. The image may look a bit messy with all
the Labels.</p>
</li>
<li><p><strong>Get bounding box for all Spans</strong>:</p>
<p>You can retrieve bounding boxes for all word-level Spans using the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">span_bboxes</span> <span class="o">=</span> <span class="p">[</span><span class="n">span</span><span class="o">.</span><span class="n">bbox</span><span class="p">()</span> <span class="k">for</span> <span class="n">span</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">spans</span><span class="p">()]</span>
</pre></div>
</div>
<p>Each bounding box (<code class="docutils literal notranslate"><span class="pre">Bbox</span></code>) corresponds to a particular word and is characterized by four coordinates: x0 and y0 define
the bottom-left corner, while x1 and y1 indicate the top-right corner. These coordinates detail the bounding box’s
location and size on the Document Page.</p>
</li>
</ol>
</section>
</section>
<section id="retrain-flair-ner-ontonotes-fast-with-human-revised-annotations">
<h2>Retrain Flair NER-Ontonotes-Fast with Human Revised Annotations<a class="headerlink" href="#retrain-flair-ner-ontonotes-fast-with-human-revised-annotations" title="Permalink to this headline">¶</a></h2>
<p>The tutorial <em>HRetrain Flair NER-Ontonotes-Fast with Human Revised Annotations</em> aims to show you how to use the
Konfuzio SDK package to include an easy feedback workflow in your training pipeline. It also gives an example of how you
can take advantage of open-source models to speed up the annotation process and use the feedback workflow to adapt the
domain knowledge of the model to your aim.</p>
<p>You can <a class="reference external" href="https://colab.research.google.com/github/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/human_in_the_loop.ipynb"><img alt="OpenInColab1" src="https://colab.research.google.com/assets/colab-badge.svg" /></a> or download it from
<a class="reference external" href="https://github.com/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/human_in_the_loop.ipynb">here</a>
and try it by yourself.</p>
</section>
<section id="count-relevant-expressions-in-annual-reports">
<h2>Count Relevant Expressions in Annual Reports<a class="headerlink" href="#count-relevant-expressions-in-annual-reports" title="Permalink to this headline">¶</a></h2>
<p>The tutorial <em>Count Relevant Expressions in Annual Reports</em> aims to show you how to use the Konfuzio SDK package to
retrieve structured and organized information that can be used for a deeper analysis and understanding of your data.
It will show you how to identify and count pre-specified expressions in documents and how to collect that information.</p>
<p>You can <a class="reference external" href="https://colab.research.google.com/github/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/word_count.ipynb"><img alt="OpenInColab2" src="https://colab.research.google.com/assets/colab-badge.svg" /></a> or download it from
<a class="reference external" href="https://github.com/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/word_count.ipynb">here</a>
and try it by yourself.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="get_started.html" class="btn btn-neutral float-left" title="Get Started" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="explanations.html" class="btn btn-neutral float-right" title="Explanations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Helm und Nagel GmbH.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D02B3QF8Z3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-D02B3QF8Z3');
</script>
<script src="https://cmp.osano.com/16CVyMSbk3Iar1G3f/97ee6223-b0cb-4f8c-abd6-a25a0d6f6507/osano.js"></script>
<script>window._nQc="89655017";</script>
<script async src="https://serve.albacross.com/track.js"></script>
<script data-jsd-embedded data-key="42374b9a-2f7b-46ec-ae7b-b79a89aa3dd9" data-base-url="https://jsd-widget.atlassian.com" src="https://jsd-widget.atlassian.com/assets/embed.js"></script>


</body>
</html>