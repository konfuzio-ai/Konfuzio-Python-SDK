<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tutorials &mdash; Konfuzio  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/full_green_square.png"/>
    <link rel="canonical" href="https://dev.konfuzio.com/sdk/examples/examples.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
        <script>mermaid.initialize({startOnLoad:true});</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Konfuzio
            <img src="../../_static/docs__static_square_transparent_super_small.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Konfuzio SDK</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">What is the Konfuzio SDK?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../explanations.html">Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sourcecode.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribution.html">Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Konfuzio Server</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../web/index.html">What is the Konfuzio Server?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../web/explanations.html">Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../web/api-v3.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../web/on_premises.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../web/changelog_app.html">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Konfuzio Document Validation UI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dvui/index.html">What is the Konfuzio Document Validation UI?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dvui/explanations.html">Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dvui/sourcecode.html">Source Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dvui/changelog.html">Changelog</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Konfuzio</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Tutorials</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/sdk/examples/examples.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <hr class="docutils" />
<section id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Permalink to this headline">¶</a></h1>
<p><em>Tutorials are lessons that take the reader by the hand through a series of steps to complete a project of some kind.</em>
<em>Tutorials are learning-oriented.</em></p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The first step we’re going to cover is <a class="reference external" href="tutorials.html#splitting-for-multi-file-documents-step-by-step-guide">File Splitting</a>
– this happens when the original Document consists of several smaller sub-Documents and needs to be separated so that each one can be processed individually.</p>
<p>Second part is on <a class="reference external" href="tutorials.html#document-categorization">Categorization</a>, where a Document is labelled to be of a certain Category within the Project.</p>
<p>Third part describes <a class="reference external" href="tutorials.html#train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents">Information Extraction</a>, during which various information is obtained from unstructured texts,
i.e. Name, Date, Recipient, or any other custom Labels.</p>
<p>For a more in-depth look at each step, be sure to check out the
<a class="reference external" href="explanations.html#architecture-sdk-to-server">Architecture Diagram</a> that reflects each step of the
document-processing pipeline.</p>
</section>
<section id="data-validation-rules">
<h2>Data Validation Rules<a class="headerlink" href="#data-validation-rules" title="Permalink to this headline">¶</a></h2>
<p>Konfuzio automatically applies a set of rules for validating data within a <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#project">Project</a>.
Data Validation Rules ensure that Training and Test data is consistent and well formed for training an
<a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#extraction-ai">Extraction AI</a> with Konfuzio.</p>
<p>In general, if a Document fails any of the checks described in the next sections, it will not be possible to train an
AI with that Document.</p>
<p>More specifically:</p>
<ul class="simple">
<li><p>If a Document fails any of the checks described in the <a class="reference external" href="#id4">Bbox Validation Rules</a> section, it
will not be possible to initialize the Project as a Python object (such as with
<code class="docutils literal notranslate"><span class="pre">project</span> <span class="pre">=</span> <span class="pre">Project(YOUR_PROJECT_ID)</span></code>), and a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised. All other Documents in the Project will be
able to be initialized.</p></li>
<li><p>If a Document fails any of the checks described in the sections
<a class="reference external" href="#id2">Annotation Validation Rules</a> and <a class="reference external" href="#id3">Span Validation Rules</a>, it
will not be possible to retrieve the Annotations (including their Spans) that fail the specific checks (such as with
<code class="docutils literal notranslate"><span class="pre">annotation</span> <span class="pre">=</span> <span class="pre">document.get_annotation_by_id(YOUR_ANNOTATION_ID)</span></code>), and a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised. All other
Annotations in the Document will be retrievable.</p></li>
</ul>
<section id="initializing-a-project-with-the-data-validation-rules-enabled">
<h3>Initializing a Project with the Data Validation Rules enabled<a class="headerlink" href="#initializing-a-project-with-the-data-validation-rules-enabled" title="Permalink to this headline">¶</a></h3>
<p>By default, any <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#project">Project</a> has the Data Validation Rules enabled, so nothing
special needs to be done to enable it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>  <span class="c1"># all the data in this Project will be validated</span>
</pre></div>
</div>
</section>
<section id="document-validation-rules">
<h3>Document Validation Rules<a class="headerlink" href="#document-validation-rules" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#document">Document</a> passes the Data Validation Rules only if all the
contained Annotations, Spans and Bboxes pass the Data Validation Rules.
If at least one Annotation, Span, or Bbox within a Document fails one of the following checks, the entire Document is
marked as unsuitable for training an Extraction AI.</p>
</section>
<section id="id2">
<h3>Annotation Validation Rules<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>An <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#annotation">Annotation</a> passes the Data Validation Rules only if:</p>
<ol class="arabic simple">
<li><p>The Annotation is not from a Category different from the Document’s Category</p></li>
<li><p>The Annotation is not entirely overlapping with another Annotation with the same Label</p>
<ul class="simple">
<li><p>It implies that partial overlaps with same Labels are allowed</p></li>
<li><p>It implies that full overlaps with different Labels are allowed</p></li>
</ul>
</li>
<li><p>The Annotation has at least one Span</p></li>
</ol>
<p>Please note that the Annotation Validation Rules are indifferent about the values of <code class="docutils literal notranslate"><span class="pre">Annotation.is_correct</span></code> or <code class="docutils literal notranslate"><span class="pre">Annotation.revised</span></code>.
For more information about what these boolean values mean, see <a class="reference external" href="https://help.konfuzio.com/modules/annotations/index.html">Konfuzio Server - Annotations</a>.</p>
</section>
<section id="id3">
<h3>Span Validation Rules<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#span">Span</a> passes the Data Validation Rules only if:</p>
<ol class="arabic simple">
<li><p>The Span contains non-empty text (the start offset must be strictly greater than the end offset)</p></li>
<li><p>The Span is contained within a single line of text (must not be distributed across multiple lines)</p></li>
</ol>
</section>
<section id="id4">
<h3>Bbox Validation Rules<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#bbox">Bbox</a> passes the Data Validation Rules only if:</p>
<ol class="arabic simple">
<li><p>The Bbox has non-negative width and height (zero is allowed for compatibility reasons with many OCR engines)</p></li>
<li><p>The Bbox is entirely contained within the bounds of a Page</p></li>
<li><p>The character that is mapped by the Bbox must correspond to the text in the Document</p></li>
</ol>
</section>
<section id="initializing-a-project-with-the-data-validation-rules-disabled">
<h3>Initializing a Project with the Data Validation Rules disabled<a class="headerlink" href="#initializing-a-project-with-the-data-validation-rules-disabled" title="Permalink to this headline">¶</a></h3>
<p>By default, any <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#project">Project</a> has the Data Validation Rules enabled.</p>
<p>A possible reason for choosing to disable the Data Validation Rules that come with the Konfuzio SDK, is that an expert user
wants to define a custom data structure or training pipeline which violates some assumptions normally present in Konfuzio
Extraction AIs and pipelines.
If you don’t want to validate your data, you should initialize the Project with <code class="docutils literal notranslate"><span class="pre">strict_data_validation=False</span></code>.</p>
<p>We highly recommend to keep the Data Validation Rules enabled at all times, as it ensures that Training and Test data
is consistent for training an Extraction AI. Disabling the Data Validation Rules and training an
<a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#extraction-ai">Extraction AI</a> with potentially duplicated, malformed,
or inconsistent data can <strong>decrease the quality of an Extraction AI</strong>. Only disable them if you know what you are doing.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">,</span> <span class="n">strict_data_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id7">
<h2>File Splitting<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<section id="split-a-file-into-separate-documents">
<h3>Split a file into separate Documents<a class="headerlink" href="#split-a-file-into-separate-documents" title="Permalink to this headline">¶</a></h3>
<p>Let’s see how to use the <code class="docutils literal notranslate"><span class="pre">konfuzio_sdk</span></code> to automatically split a file into several Documents. We will be using
a pre-built class <code class="docutils literal notranslate"><span class="pre">SplittingAI</span></code> and an instance of a trained <code class="docutils literal notranslate"><span class="pre">ContextAwareFileSplittingModel</span></code>. The latter uses a
context-aware logic. By context-aware we mean a rule-based approach that looks for common strings between the first
Pages of all Category’s Documents. Upon predicting whether a Page is a potential splitting point (meaning whether it is
first or not), we compare Page’s contents to these common first-page strings; if there is occurrence of at least one
such string, we mark a Page to be first (thus meaning it is a splitting point).</p>
<p>This tutorial can also be used with the <code class="docutils literal notranslate"><span class="pre">MultimodalFileSplittingModel</span></code>; the only difference in the initialization is
that it does not require specifying a Tokenizer explicitly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Page</span><span class="p">,</span> <span class="n">Category</span><span class="p">,</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">SplittingAI</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">ContextAwareFileSplittingModel</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.information_extraction</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">ConnectedTextTokenizer</span>

<span class="c1"># initialize a Project and fetch a test Document of your choice</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># initialize a Context Aware File Splitting Model and fit it</span>

<span class="n">file_splitting_model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">ConnectedTextTokenizer</span><span class="p">())</span>
<span class="c1"># to run a Multimodal File Splitting Model instead, replace the line above with the following lines. note that training</span>
<span class="c1"># a Multimodal File Splitting Model can take longer that Context Aware File Splitting Model.</span>
<span class="c1">#</span>
<span class="c1"># from konfuzio_sdk.trainer.file_splitting import MultimodalFileSplittingModel</span>
<span class="c1"># file_splitting_model = MultimodalFileSplittingModel(categories=project.categories)</span>

<span class="c1"># for an example run, you can take only a slice of training documents to make fitting faster</span>
<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">allow_empty_categories</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># save the model</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">include_konfuzio</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># run the prediction</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">test_document</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>

<span class="c1"># usage with the Splitting AI – you can load a pre-saved model or pass an initialized instance as the input</span>
<span class="c1"># in this example, we load a previously saved one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

<span class="c1"># initialize the Splitting AI</span>
<span class="n">splitting_ai</span> <span class="o">=</span> <span class="n">SplittingAI</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Splitting AI is a more high-level interface to Context Aware File Splitting Model and any other models that can be</span>
<span class="c1"># developed for File Splitting purposes. It takes a Document as an input, rather than individual Pages, because it</span>
<span class="c1"># utilizes page-level prediction of possible split points and returns Document or Documents with changes depending on</span>
<span class="c1"># the prediction mode.</span>

<span class="c1"># Splitting AI can be run in two modes: returning a list of Sub-Documents as the result of the input Document</span>
<span class="c1"># splitting or returning a copy of the input Document with Pages predicted as first having an attribute</span>
<span class="c1"># &quot;is_first_page&quot;. The flag &quot;return_pages&quot; has to be True for the latter; let&#39;s use it</span>
<span class="n">new_document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">test_document</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_document</span><span class="p">)</span>
<span class="c1"># output: [predicted_document]</span>

<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">new_document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="splitting-for-multi-document-files-step-by-step-guide">
<h3>Splitting for multi-Document files: Step-by-step guide<a class="headerlink" href="#splitting-for-multi-document-files-step-by-step-guide" title="Permalink to this headline">¶</a></h3>
<section id="intro">
<h4>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¶</a></h4>
<p>It’s common for multipage files to not be perfectly organized, and in some cases, multiple independent Documents may be
included in a single file. To ensure that these Documents are properly processed and separated, we will be discussing a
method for identifying and splitting them into individual, independent Sub-documents.</p>
<img alt="../../_images/multi_file_document_example.png" src="../../_images/multi_file_document_example.png" />
<p><em>Multi-file Document Example</em></p>
<p>Konfuzio SDK offers two ways for separating Documents that may be included in a single file. One of them is training
the instance of the Multimodal File Splitting Model for file splitting that would predict whether a Page is first or
not and running the Splitting AI with it. Multimodal File Splitting Model is a combined approach based on architecture
that processes textual and visual data from the Documents separately (in our case, using BERT and VGG19 simplified
architectures respectively) and then combines the outputs which go into a Multi-layer Perceptron architecture as
inputs. A more detailed scheme of the architecture can be found further.</p>
<p>If you hover over the image you can zoom or use the full page mode.</p>
<p><span class="raw-html-m2r"><div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;url&quot;:&quot;https://raw.githubusercontent.com/konfuzio-ai/konfuzio-sdk/master/docs/sdk/examples/file-splitting-class/fusion_model.drawio&quot;}"></div></span></p>
<script type="text/javascript" src="https://viewer.diagrams.net/embed2.js?&fetch=https%3A%2F%2Fraw.githubusercontent.com%2Fkonfuzio-ai%2Fkonfuzio-sdk%2Fmaster%2Fdocs%2Fsdk%2Fexamples%2Ffile-splitting-class%2Ffusion_model.drawio"></script><p>Another approach is context-aware file splitting logic which is presented by Context Aware File Splitting Model. This
approach involves analyzing the contents of each Page and identifying similarities to the first Pages of the Document.
It will allow us to define splitting points and divide the Document into multiple Sub-documents. It’s important to note
that this approach is only effective for Documents written in the same language and that the process must be repeated
for each Category. In this tutorial, we will explain how to implement the class for this model step by step.</p>
<p>If you are unfamiliar with the SDK’s main concepts (like Page or Span), you can get to know them at <a class="reference external" href="https://dev.konfuzio.com/sdk/explanations.html#data-layer-concepts">Data Layer Concepts</a>.</p>
</section>
<section id="quick-explanation">
<h4>Quick explanation<a class="headerlink" href="#quick-explanation" title="Permalink to this headline">¶</a></h4>
<p>The first step in implementing this method is “training”: this involves tokenizing the Document by splitting its text
into parts, specifically into strings without line breaks. We then gather the exclusive strings from Spans, which are
the parts of the text in the Page, and compare them to the first Pages of each Document in the training data.</p>
<p>Once we have identified these strings, we can use them to determine whether a Page in an input Document is a first Page
or not. We do this by going through the strings in the Page and comparing them to the set of strings collected in the
training stage. If we find at least one string that intersects between the current Page and the strings from the first
step, we believe it is the first Page.</p>
<p>Note that the more Documents we use in the training stage, the less intersecting strings we are likely to find. If you
find that your set of first-page strings is empty, try using a smaller slice of the dataset instead of the whole set.
Generally, when used on Documents within the same Category, this algorithm should not return an empty set. If that is
the case, it’s worth checking if your data is consistent, for example, not in different languages or containing other
Categories.</p>
</section>
<section id="step-by-step-explanation">
<h4>Step-by-step explanation<a class="headerlink" href="#step-by-step-explanation" title="Permalink to this headline">¶</a></h4>
<p>In this section, we will walk you through the process of setting up the <code class="docutils literal notranslate"><span class="pre">ContextAwareFileSplittingModel</span></code> class, which
can be found in the code block at the bottom of this page. This class is already implemented and can be imported using
<code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">konfuzio_sdk.trainer.file_splitting</span> <span class="pre">import</span> <span class="pre">ContextAwareFileSplittingModel</span></code>.</p>
<p>Note that any custom File Splitting AI (derived from <code class="docutils literal notranslate"><span class="pre">AbstractFileSplittingModel</span></code> class) requires having the following
methods implemented:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code> to initialize key variables required by the custom AI;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code> to define architecture and training that the model undergoes, i.e. a certain NN architecture or a custom</p></li>
<li><p>hardcoded logic;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict</span></code> to define how the model classifies Pages as first or non-first. <strong>NB:</strong> the classification needs to be
run on the Page level, not the Document level – the result of classification is reflected in <code class="docutils literal notranslate"><span class="pre">is_first_page</span></code> attribute
value, which is unique to the Page class and is not present in Document class. Pages with <code class="docutils literal notranslate"><span class="pre">is_first_page</span> <span class="pre">=</span> <span class="pre">True</span></code> become
splitting points, thus, each new Sub-Document has a Page predicted as first as its starting point.</p></li>
</ul>
<p>To begin, we will make all the necessary imports:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Page</span><span class="p">,</span> <span class="n">Category</span><span class="p">,</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">AbstractFileSplittingModel</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">SplittingAI</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.information_extraction</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">ConnectedTextTokenizer</span>
</pre></div>
</div>
<p>Then, let’s initialize the <code class="docutils literal notranslate"><span class="pre">ContextAwareFileSplittingModel</span></code> class:</p>
<p>The class inherits from <code class="docutils literal notranslate"><span class="pre">AbstractFileSplittingModel</span></code>, so we run <code class="docutils literal notranslate"><span class="pre">super().__init__(categories=categories)</span></code> to properly
inherit its attributes. The <code class="docutils literal notranslate"><span class="pre">tokenizer</span></code> attribute will be used to process the text within the Document, separating it
into Spans. This is done to ensure that the text in all the Documents is split using the same logic (particularly
tokenization by separating on <code class="docutils literal notranslate"><span class="pre">\n</span></code> whitespaces by ConnectedTextTokenizer, which is used in the example in the end of the
page) and it will be possible to find common Spans. It will be used for training and testing Documents as well as any
Document that will undergo splitting. It’s important to note that if you run fitting with one Tokenizer and then
reassign it within the same instance of the model, all previously gathered strings will be deleted and replaced by new
ones. <code class="docutils literal notranslate"><span class="pre">requires_images</span></code> and <code class="docutils literal notranslate"><span class="pre">requires_text</span></code> determine whether these types of data are used for prediction; this is
needed for distinguishing between preprocessing types once a model is passed into the Splitting AI.</p>
<p>An example of how ConnectedTextTokenizer works:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># before tokenization</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">test_document</span><span class="o">.</span><span class="n">text</span>

<span class="c1"># output: &quot;Hi all,\nI like bread.\n\fI hope to get everything done soon.\n\fMorning,\n\fI&#39;m glad to see you.&quot;</span>
<span class="c1">#             &quot;\n\fMorning,&quot;</span>

<span class="n">test_document</span><span class="o">.</span><span class="n">spans</span><span class="p">()</span>

<span class="c1"># output: []</span>

<span class="n">test_document</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_document</span><span class="p">)</span>

<span class="c1"># after tokenization</span>
<span class="n">test_document</span><span class="o">.</span><span class="n">spans</span><span class="p">()</span>

<span class="c1"># output: [Span (0, 7), Span (8, 21), Span (22, 58), Span (59, 68), Span (69, 90), Span (91, 100)]</span>

<span class="n">test_document</span><span class="o">.</span><span class="n">spans</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">offset_string</span>

<span class="c1"># output: &quot;Hi all,&quot;</span>
</pre></div>
</div>
<p>The first method to define will be the <code class="docutils literal notranslate"><span class="pre">fit()</span></code> method. For each Category, we call <code class="docutils literal notranslate"><span class="pre">exclusive_first_page_strings</span></code> method,
which allows us to gather the strings that appear on the first Page of each Document. <code class="docutils literal notranslate"><span class="pre">allow_empty_categories</span></code> allows
for returning empty lists for Categories that haven’t had any exclusive first-page strings found across their Documents.
This means that those Categories would not be used in the prediction process.</p>
<p>Next, we define <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method. The method accepts a Page as an input and checks its Span set for containing
first-page strings for each of the Categories. If there is at least one intersection, the Page is predicted to be a
first Page. If there are no intersections, the Page is predicted to be a non-first Page.</p>
<p>Lastly, a <code class="docutils literal notranslate"><span class="pre">check_is_ready()</span></code> method is defined. This method is used to ensure that a model is ready for prediction: the
checks cover that the Tokenizer and a set of Categories is defined, and that at least one of the Categories has
exclusive first-page strings.</p>
<p>Full code of class:</p>
<p>A quick example of the class’s usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a Project and fetch a test Document of your choice</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># initialize a Context Aware File Splitting Model and fit it</span>

<span class="n">file_splitting_model</span> <span class="o">=</span> <span class="n">ContextAwareFileSplittingModel</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">ConnectedTextTokenizer</span><span class="p">())</span>

<span class="c1"># for an example run, you can take only a slice of training documents to make fitting faster</span>
<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">documents</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="n">file_splitting_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">allow_empty_categories</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># save the model</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">include_konfuzio</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># run the prediction</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">test_document</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">file_splitting_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pred</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>

<span class="c1"># usage with the Splitting AI – you can load a pre-saved model or pass an initialized instance as the input</span>
<span class="c1"># in this example, we load a previously saved one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

<span class="c1"># initialize the Splitting AI</span>
<span class="n">splitting_ai</span> <span class="o">=</span> <span class="n">SplittingAI</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Splitting AI is a more high-level interface to Context Aware File Splitting Model and any other models that can be</span>
<span class="c1"># developed for File Splitting purposes. It takes a Document as an input, rather than individual Pages, because it</span>
<span class="c1"># utilizes page-level prediction of possible split points and returns Document or Documents with changes depending on</span>
<span class="c1"># the prediction mode.</span>

<span class="c1"># Splitting AI can be run in two modes: returning a list of Sub-Documents as the result of the input Document</span>
<span class="c1"># splitting or returning a copy of the input Document with Pages predicted as first having an attribute</span>
<span class="c1"># &quot;is_first_page&quot;. The flag &quot;return_pages&quot; has to be True for the latter; let&#39;s use it</span>
<span class="n">new_document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">test_document</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_document</span><span class="p">)</span>
<span class="c1"># output: [predicted_document]</span>

<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">new_document</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">page</span><span class="o">.</span><span class="n">is_first_page</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Page </span><span class="si">{}</span><span class="s1"> is predicted as the non-first.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">number</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="filesplittingevaluation-class">
<h3>FileSplittingEvaluation class<a class="headerlink" href="#filesplittingevaluation-class" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">FileSplittingEvaluation</span></code> class can be used to evaluate performance of Context-Aware File Splitting Model, returning a
set of metrics that includes precision, recall, f1 measure, True Positives, False Positives, True Negatives, and False
Negatives.</p>
<p>The class’s methods <code class="docutils literal notranslate"><span class="pre">calculate()</span></code> and <code class="docutils literal notranslate"><span class="pre">calculate_by_category()</span></code> are run at initialization. The class receives two lists
of Documents as an input – first list consists of ground-truth Documents where all first Pages are marked as such,
second is of Documents on Pages of which File Splitting Model ran a prediction of them being first or non-first.</p>
<p>The initialization would look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">FileSplittingEvaluation</span><span class="p">(</span>
    <span class="n">ground_truth_documents</span><span class="o">=</span><span class="n">YOUR_GROUND_TRUTH_LIST</span><span class="p">,</span> <span class="n">prediction_documents</span><span class="o">=</span><span class="n">YOUR_PREDICTION_LIST</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The class compares each pair of Pages. If a Page is labeled as first and the model also predicted it as first, it is
considered a True Positive. If a Page is labeled as first but the model predicted it as non-first, it is considered a
False Negative. If a Page is labeled as non-first but the model predicted it as first, it is considered a False
Positive. If a Page is labeled as non-first and the model also predicted it as non-first, it is considered a True
Negative.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>predicted correctly</p></th>
<th class="head"><p>predicted incorrectly</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>first Page</p></td>
<td><p>TP</p></td>
<td><p>FN</p></td>
</tr>
<tr class="row-odd"><td><p>non-first Page</p></td>
<td><p>TN</p></td>
<td><p>FP</p></td>
</tr>
</tbody>
</table>
<p>After iterating through all Pages of all Documents, precision, recall and f1 measure are calculated. If you wish to set
metrics to <code class="docutils literal notranslate"><span class="pre">None</span></code> in case there has been an attempt of zero division, set <code class="docutils literal notranslate"><span class="pre">allow_zero=True</span></code> at the initialization.</p>
<p>To see a certain metric after the class has been initialized, you can call a metric’s method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">())</span>
</pre></div>
</div>
<p>It is also possible to look at the metrics calculated by each Category independently. For this, pass
<code class="docutils literal notranslate"><span class="pre">search=YOUR_CATEGORY_HERE</span></code> when calling the wanted metric’s method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY</span><span class="p">))</span>
</pre></div>
</div>
<p>For more details, see the <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#evaluation">Python API Documentation</a> on
Evaluation.</p>
<section id="example-of-evaluation-input-and-output">
<h4>Example of evaluation input and output<a class="headerlink" href="#example-of-evaluation-input-and-output" title="Permalink to this headline">¶</a></h4>
<p>Suppose in our test dataset we have 2 Documents of 2 Categories: one 3-paged, consisting of a single file (-&gt; it has
only one ground-truth first Page) of a first Category, and one 5-paged, consisting of three files: two 2-paged and one
1-paged (-&gt; it has three ground-truth first Pages), of a second Category.</p>
<img alt="../../_images/document_example_1.png" src="../../_images/document_example_1.png" />
<p><em>First document</em></p>
<img alt="../../_images/document_example_2.png" src="../../_images/document_example_2.png" />
<p><em>Second document</em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Document</span><span class="p">,</span> <span class="n">Page</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.evaluate</span> <span class="kn">import</span> <span class="n">FileSplittingEvaluation</span><span class="p">,</span> <span class="n">EvaluationCalculator</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.file_splitting</span> <span class="kn">import</span> <span class="n">SplittingAI</span>

<span class="c1"># This example builds the Documents from scratch and without uploading a Supported File.</span>
<span class="c1"># If you uploaded your Document to the Konfuzio Server, you can just retrieve it with:</span>
<span class="c1"># document_1 = project.get_document_by_id(YOUR_DOCUMENT_ID)</span>
<span class="n">text_1</span> <span class="o">=</span> <span class="s2">&quot;Hi all,</span><span class="se">\n</span><span class="s2">I like bread.</span><span class="se">\n</span><span class="s2">I hope to get everything done soon.</span><span class="se">\n</span><span class="s2">Have you seen it?&quot;</span>
<span class="n">document_1</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">YOUR_PROJECT</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text_1</span><span class="p">,</span> <span class="n">dataset_status</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span>
    <span class="n">document</span><span class="o">=</span><span class="n">document_1</span><span class="p">,</span>
    <span class="n">start_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">end_offset</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span>
    <span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span>
    <span class="n">document</span><span class="o">=</span><span class="n">document_1</span><span class="p">,</span>
    <span class="n">start_offset</span><span class="o">=</span><span class="mi">22</span><span class="p">,</span>
    <span class="n">end_offset</span><span class="o">=</span><span class="mi">57</span><span class="p">,</span>
    <span class="n">number</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span>
    <span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span>
    <span class="n">document</span><span class="o">=</span><span class="n">document_1</span><span class="p">,</span>
    <span class="n">start_offset</span><span class="o">=</span><span class="mi">58</span><span class="p">,</span>
    <span class="n">end_offset</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span>
    <span class="n">number</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># As with the previous example Document, you can just retrieve an online Document with</span>
<span class="c1"># document_2 = project.get_document_by_id(YOUR_DOCUMENT_ID)</span>
<span class="n">text_2</span> <span class="o">=</span> <span class="s2">&quot;Evening,</span><span class="se">\n</span><span class="s2">thank you for coming.</span><span class="se">\n</span><span class="s2">I like fish.</span><span class="se">\n</span><span class="s2">I need it.</span><span class="se">\n</span><span class="s2">Evening.&quot;</span>
<span class="n">document_2</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">YOUR_PROJECT</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text_2</span><span class="p">,</span> <span class="n">dataset_status</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">31</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">43</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">_</span><span class="o">.</span><span class="n">is_first_page</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">44</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">54</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">Page</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">original_size</span><span class="o">=</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">240</span><span class="p">),</span> <span class="n">document</span><span class="o">=</span><span class="n">document_2</span><span class="p">,</span> <span class="n">start_offset</span><span class="o">=</span><span class="mi">55</span><span class="p">,</span> <span class="n">end_offset</span><span class="o">=</span><span class="mi">63</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">_</span><span class="o">.</span><span class="n">is_first_page</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p>We need to pass two lists of Documents into the <code class="docutils literal notranslate"><span class="pre">FileSplittingEvaluation</span></code> class. So, before that, we need to run each
Page of the Documents through the model’s prediction.</p>
<p>Let’s say the evaluation gave good results, with only one first Page being predicted as non-first and all the other
Pages being predicted correctly. An example of how the evaluation would be implemented would be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">splitting_ai</span> <span class="o">=</span> <span class="n">SplittingAI</span><span class="p">(</span><span class="n">YOUR_MODEL</span><span class="p">)</span>
<span class="n">pred_1</span><span class="p">:</span> <span class="n">Document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">document_1</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pred_2</span><span class="p">:</span> <span class="n">Document</span> <span class="o">=</span> <span class="n">splitting_ai</span><span class="o">.</span><span class="n">propose_split_documents</span><span class="p">(</span><span class="n">document_2</span><span class="p">,</span> <span class="n">return_pages</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">FileSplittingEvaluation</span><span class="p">(</span>
    <span class="n">ground_truth_documents</span><span class="o">=</span><span class="p">[</span><span class="n">document_1</span><span class="p">,</span> <span class="n">document_2</span><span class="p">],</span> <span class="n">prediction_documents</span><span class="o">=</span><span class="p">[</span><span class="n">pred_1</span><span class="p">,</span> <span class="n">pred_2</span><span class="p">]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tp</span><span class="p">())</span>
<span class="c1"># returns: 3</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tn</span><span class="p">())</span>
<span class="c1"># returns: 4</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fp</span><span class="p">())</span>
<span class="c1"># returns: 0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">())</span>
<span class="c1"># returns: 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">())</span>
<span class="c1"># returns: 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">())</span>
<span class="c1"># returns: 0.75</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">())</span>
<span class="c1"># returns: 0.85</span>
</pre></div>
</div>
<p>Our results could be reflected in a following table:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>TPs</p></th>
<th class="head"><p>TNs</p></th>
<th class="head"><p>FPs</p></th>
<th class="head"><p>FNs</p></th>
<th class="head"><p>precision</p></th>
<th class="head"><p>recall</p></th>
<th class="head"><p>F1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>3</p></td>
<td><p>4</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0.75</p></td>
<td><p>0.85</p></td>
</tr>
</tbody>
</table>
<p>If we want to see evaluation results by Category, the implementation of the Evaluation would look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">tp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">tn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 2 2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">fp</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 0 0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 0 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 0.66</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_1</span><span class="p">),</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="n">search</span><span class="o">=</span><span class="n">YOUR_CATEGORY_2</span><span class="p">))</span>
<span class="c1"># returns: 1 0.8</span>
</pre></div>
</div>
<p>the output could be reflected in a following table:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>TPs</p></th>
<th class="head"><p>TNs</p></th>
<th class="head"><p>FPs</p></th>
<th class="head"><p>FNs</p></th>
<th class="head"><p>precision</p></th>
<th class="head"><p>recall</p></th>
<th class="head"><p>F1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Category 1</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Category 2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0.66</p></td>
<td><p>0.8</p></td>
</tr>
</tbody>
</table>
<p>To log metrics after evaluation, you can call <code class="docutils literal notranslate"><span class="pre">EvaluationCalculator</span></code>‘s method <code class="docutils literal notranslate"><span class="pre">metrics_logging</span></code> (you would need to
specify the metrics accordingly at the class’s initialization). Example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">EvaluationCalculator</span><span class="p">(</span><span class="n">tp</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">fp</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tn</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">metrics_logging</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="document-categorization">
<h2>Document Categorization<a class="headerlink" href="#document-categorization" title="Permalink to this headline">¶</a></h2>
<section id="working-with-the-category-of-a-document-and-its-individual-pages">
<h3>Working with the Category of a Document and its individual Pages<a class="headerlink" href="#working-with-the-category-of-a-document-and-its-individual-pages" title="Permalink to this headline">¶</a></h3>
<p>You can initialize a Document with a Category, which will count as if a human manually revised it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">my_category</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_category_by_id</span><span class="p">(</span><span class="n">YOUR_CATEGORY_ID</span><span class="p">)</span>

<span class="n">my_document</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;My text.&quot;</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">my_category</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">my_document</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">my_category</span>
<span class="k">assert</span> <span class="n">my_document</span><span class="o">.</span><span class="n">category_is_revised</span> <span class="ow">is</span> <span class="kc">True</span>
</pre></div>
</div>
<p>If a Document is initialized with no Category, it can be manually set later.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">document</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">project</span><span class="o">.</span><span class="n">no_category</span>
<span class="n">document</span><span class="o">.</span><span class="n">set_category</span><span class="p">(</span><span class="n">my_category</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">document</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">my_category</span>
<span class="k">assert</span> <span class="n">document</span><span class="o">.</span><span class="n">category_is_revised</span> <span class="ow">is</span> <span class="kc">True</span>
<span class="c1"># This will set it for all of its Pages as well.</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">page</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="n">my_category</span>
</pre></div>
</div>
<p>If you use a Categorization AI to automatically assign a Category to a Document (such as the
<a class="reference external" href="tutorials.html#categorization-fallback-logic">NameBasedCategorizationAI</a>), each Page will be assigned a
Category Annotation with predicted confidence information, and the following properties will be accessible. You can
also find these documented under <a class="reference external" href="sourcecode.html#document">API Reference - Document</a>,
<a class="reference external" href="sourcecode.html#page">API Reference - Page</a> and
<a class="reference external" href="sourcecode.html#category-annotation">API Reference - Category Annotation</a>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CategoryAnnotation.category</span></code></p></td>
<td><p>The AI predicted Category of this Category<span class="raw-html-m2r"><br></span>Annotation.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">CategoryAnnotation.confidence</span></code></p></td>
<td><p>The AI predicted confidence of this Category<span class="raw-html-m2r"><br></span>Annotation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Document.category_annotations</span></code></p></td>
<td><p>List of predicted Category Annotations at the<span class="raw-html-m2r"><br></span>Document level.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Document.maximum_confidence_category_annotation</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>Annotation, or the human revised one if present.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Document.maximum_confidence_category</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>or the human revised one if present.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Document.category</span></code></p></td>
<td><p>Returns a Category only if all Pages have same<span class="raw-html-m2r"><br></span>Category, otherwise None. In that case, it hints<span class="raw-html-m2r"><br></span>to the fact that the Document should probably<span class="raw-html-m2r"><br></span>be revised or split into Documents with<span class="raw-html-m2r"><br></span>consistently categorized Pages.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Page.category_annotations</span></code></p></td>
<td><p>List of predicted Category Annotations at the<span class="raw-html-m2r"><br></span>Page level.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Page.maximum_confidence_category_annotation</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>Annotation or the one revised by the user for this<span class="raw-html-m2r"><br></span>Page.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Page.category</span></code></p></td>
<td><p>Get the maximum confidence predicted Category<span class="raw-html-m2r"><br></span>or the one revised by user for this Page.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="name-based-categorization-ai">
<h3>Name-based Categorization AI<a class="headerlink" href="#name-based-categorization-ai" title="Permalink to this headline">¶</a></h3>
<p>Use the name of the Category as an effective fallback logic to categorize Documents when no Categorization AI is available:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span><span class="p">,</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">NameBasedCategorizationAI</span>

<span class="c1"># Set up your Project.</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>

<span class="c1"># Initialize the Categorization Model.</span>
<span class="n">categorization_model</span> <span class="o">=</span> <span class="n">NameBasedCategorizationAI</span><span class="p">(</span><span class="n">project</span><span class="p">)</span>
<span class="n">categorization_model</span><span class="o">.</span><span class="n">categories</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">categories</span>

<span class="c1"># Retrieve a Document to categorize.</span>
<span class="n">test_document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>

<span class="c1"># The Categorization Model returns a copy of the SDK Document with Category attribute</span>
<span class="c1"># (use inplace=True to maintain the original Document instead).</span>
<span class="c1"># If the input Document is already categorized, the already present Category is used</span>
<span class="c1"># (use recategorize=True if you want to force a recategorization).</span>
<span class="n">result_doc</span> <span class="o">=</span> <span class="n">categorization_model</span><span class="o">.</span><span class="n">categorize</span><span class="p">(</span><span class="n">document</span><span class="o">=</span><span class="n">test_document</span><span class="p">)</span>

<span class="c1"># Each Page is categorized individually.</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">result_doc</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found category </span><span class="si">{</span><span class="n">page</span><span class="o">.</span><span class="n">category</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># The Category of the Document is defined when all pages&#39; Categories are equal.</span>
<span class="c1"># If the Document contains mixed Categories, only the Page level Category will be defined,</span>
<span class="c1"># and the Document level Category will be None.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found category </span><span class="si">{</span><span class="n">result_doc</span><span class="o">.</span><span class="n">category</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">result_doc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="model-based-categorization-ai">
<h3>Model-based Categorization AI<a class="headerlink" href="#model-based-categorization-ai" title="Permalink to this headline">¶</a></h3>
<p>Build, train and test a Categorization AI using Image Models and Text Models to classify the image and text of each Page.</p>
<p>For a list of available Models see <a class="reference external" href="#id8">Available Categorization Models</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span><span class="p">,</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.information_extraction</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">ImageModel</span><span class="p">,</span> <span class="n">TextModel</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">build_categorization_ai_pipeline</span>

<span class="c1"># Set up your Project.</span>
<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>

<span class="c1"># Build the Categorization AI architecture using a template</span>
<span class="c1"># of pre-built Image and Text classification Models.</span>
<span class="n">categorization_pipeline</span> <span class="o">=</span> <span class="n">build_categorization_ai_pipeline</span><span class="p">(</span>
    <span class="n">categories</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span>
    <span class="n">documents</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">documents</span><span class="p">,</span>
    <span class="n">test_documents</span><span class="o">=</span><span class="n">project</span><span class="o">.</span><span class="n">test_documents</span><span class="p">,</span>
    <span class="n">image_model</span><span class="o">=</span><span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB0</span><span class="p">,</span>
    <span class="n">text_model</span><span class="o">=</span><span class="n">TextModel</span><span class="o">.</span><span class="n">NBOWSelfAttention</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Train the AI.</span>
<span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Evaluate the AI</span>
<span class="n">data_quality</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">use_training_docs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ai_quality</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

<span class="c1"># Categorize a Document</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">categorization_result</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">categorize</span><span class="p">(</span><span class="n">document</span><span class="o">=</span><span class="n">document</span><span class="p">)</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">categorization_result</span><span class="o">.</span><span class="n">pages</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found category </span><span class="si">{</span><span class="n">page</span><span class="o">.</span><span class="n">category</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Save and load a pickle file for the AI</span>
<span class="n">pickle_ai_path</span> <span class="o">=</span> <span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="n">categorization_pipeline_loaded</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">categorization_pipeline</span><span class="o">.</span><span class="n">pipeline_path</span><span class="p">)</span>
</pre></div>
</div>
<section id="id8">
<h4>Available Categorization Models<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>When using <code class="docutils literal notranslate"><span class="pre">build_categorization_ai_pipeline</span></code>, you can select which Image Module and/or Text Module to use for
classification. At least one betweem the Image Model or the Text Model must be specified. Both can also be used
at the same time.</p>
<p>The list of available Categorization Models is implemented as an Enum containing the following elements:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.document_categorization</span> <span class="kn">import</span> <span class="n">ImageModel</span><span class="p">,</span> <span class="n">TextModel</span>

<span class="c1"># Image Models</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG11</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG13</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG16</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">VGG19</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB0</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB1</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB2</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB3</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB4</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB5</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB6</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB7</span>
<span class="n">ImageModel</span><span class="o">.</span><span class="n">EfficientNetB8</span>

<span class="c1"># Text Models</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">NBOW</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">NBOWSelfAttention</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">LSTM</span>
<span class="n">TextModel</span><span class="o">.</span><span class="n">BERT</span>
</pre></div>
</div>
<p>See more details about these Categorization Models under <a class="reference external" href="sourcecode.html#categorization-ai">API Reference - Categorization AI</a>.</p>
</section>
</section>
<section id="categorization-ai-overview-diagram">
<h3>Categorization AI Overview Diagram<a class="headerlink" href="#categorization-ai-overview-diagram" title="Permalink to this headline">¶</a></h3>
<p>In the first diagram, we show the class hierarchy of the available Categorization Models within the SDK. Note that the
Multimodal Model simply consists of a Multi Layer Perceptron to concatenate the feature outputs of a Text Model and an
Image Model, such that the predictions from both Models can be unified in a unique Category prediction.</p>
<p>In the second diagram, we show how these models are contained within a Model-based Categorization AI. The
<a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#categorization-ai">Categorization AI</a> class provides the high level
interface to categorize Documents, as exemplified in the code examples above. It uses a Page Categorization Model
to categorize each Page. The Page Categorization Model is a container for Categorization Models: it wraps the feature
output layers of each contained Model with a Dropout Layer and a Fully Connected Layer.</p>
<p><span class="raw-html-m2r"><div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers tags lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;url&quot;:&quot;https://raw.githubusercontent.com/konfuzio-ai/konfuzio-sdk/master/docs/sdk/examples/document_categorization/CategorizationAI.drawio&quot;}"></div></span></p>
<script type="text/javascript" src="https://viewer.diagrams.net/embed2.js?&fetch=https%3A%2F%2Fraw.githubusercontent.com%2Fkonfuzio-ai%2Fkonfuzio-sdk%2Fmaster%2Fdocs%2Fsdk%2Fexamples%2Fdocument_categorization%2FCategorizationAI.drawio"></script></section>
</section>
<section id="find-possible-outliers-among-the-ground-truth-annotations">
<h2>Find possible outliers among the ground-truth Annotations<a class="headerlink" href="#find-possible-outliers-among-the-ground-truth-annotations" title="Permalink to this headline">¶</a></h2>
<p>If you want to ensure that Annotations of a Label are consistent and check for possible outliers, you can use one of
the <code class="docutils literal notranslate"><span class="pre">Label</span></code> class’s methods. There are three of them available.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">get_probable_outliers_by_regex</span></code> looks for the worst regexes used to find the Annotations. “Worst” is determined by
the number of True Positives calculated upon evaluating the regexes’ performance. Returns Annotations predicted by the
regexes with the least amount of True Positives. By default, the method returns Annotations retrieved by the regex that
performs on the level of 10% in comparison to the best one.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers_by_regex</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_probable_outliers_by_confidence</span></code> looks for the Annotations with the least confidence level, provided it is lower
than the specified threshold (the default threshold is 0.5). Accepts an instance of EvaluationExtraction class as an input and uses confidence predictions from there.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers_by_confidence</span><span class="p">(</span><span class="n">evaluation</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_probable_outliers_by_normalization</span></code> looks for the Annotations that are unable to pass normalization by the data
type of the given Label (meaning that they are not of the same data type themselves, thus outliers).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers_by_normalization</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p>All three of the methods return a list of Annotations that are deemed outliers by the logic of the current method; the
contents of the output are not necessarily wrong, however, they may have some difference from the main body of the
Annotations under a given Label.</p>
<p>To have a more thorough check, you can use a method <code class="docutils literal notranslate"><span class="pre">get_probable_outliers</span></code> that allows for combining the
aforementioned methods or have them run together and return only those Annotations that were detected by all of them.</p>
<p>Here’s an example of running the latter method with one of the search methods disabled explicitly. By default, all
three of the search methods are enabled.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>

<span class="n">project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">YOUR_LABEL_NAME</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">get_probable_outliers</span><span class="p">(</span><span class="n">project</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span> <span class="n">confidence_search</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents">
<h2>Train a Konfuzio SDK Model to Extract Information From Payslip Documents<a class="headerlink" href="#train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents" title="Permalink to this headline">¶</a></h2>
<p>The tutorial <em>RFExtractionAI Demo</em> aims to show you how to use the Konfuzio SDK package to use a simple <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#konfuzio_sdk.tokenizer.regex.WhitespaceTokenizer">Whitespace
tokenizer</a> and to
train a “RFExtractionAI” model to find and extract relevant information like Name, Date and Recipient
from payslip documents.</p>
<p>You can <img alt="OpenInColab" src="https://colab.research.google.com/assets/colab-badge.svg" />* or download it from <code class="docutils literal notranslate"><span class="pre">here</span> <span class="pre">&lt;https://github.com/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/RFExtractionAI%20Demo.ipynb&gt;</span></code>*
and try it by yourself.</p>
</section>
<section id="evaluate-a-trained-extraction-ai-model">
<h2>Evaluate a Trained Extraction AI Model<a class="headerlink" href="#evaluate-a-trained-extraction-ai-model" title="Permalink to this headline">¶</a></h2>
<p>In this example we will see how we can evaluate a trained <code class="docutils literal notranslate"><span class="pre">RFExtractionAI</span></code> model. We will assume that we have a trained
pickled model available. See <a class="reference external" href="https://dev.konfuzio.com/sdk/examples/examples.html#train-a-konfuzio-sdk-model-to-extract-information-from-payslip-documents">here</a>
for how to train such a model, and check out the <a class="reference external" href="https://dev.konfuzio.com/sdk/sourcecode.html#evaluation">Evaluation</a>
documentation for more details.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.trainer.information_extraction</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">)</span>

<span class="c1"># To get the evaluation of the full pipeline</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_full</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Full evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Full evaluation recall: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">recall</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Full evaluation precision: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">precision</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># To get the evaluation of the Tokenizer alone</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_tokenizer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tokenizer evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">tokenizer_f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># To get the evaluation of the Label classifier given perfect tokenization</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_clf</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label classifier evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">clf_f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># To get the evaluation of the LabelSet given perfect Label classification</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate_clf</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label Set evaluation F1 score: </span><span class="si">{</span><span class="n">evaluation</span><span class="o">.</span><span class="n">f1</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="create-regex-based-annotations">
<h2>Create Regex-based Annotations<a class="headerlink" href="#create-regex-based-annotations" title="Permalink to this headline">¶</a></h2>
<p><strong>Pro Tip</strong>: Read our technical blog post <a class="reference external" href="https://helm-nagel.com/Automated-Regex-Generation-based-on-examples">Automated Regex</a> to find out how we use Regex to detect outliers in our annotated data.</p>
<p>Let’s see a simple example of how can we use the <code class="docutils literal notranslate"><span class="pre">konfuzio_sdk</span></code> package to get information on a project and to post annotations.</p>
<p>You can follow the example below to post annotations of a certain word or expression in the first document uploaded.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span><span class="p">,</span> <span class="n">Annotation</span><span class="p">,</span> <span class="n">Span</span>

<span class="n">my_project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>

<span class="c1"># Word/expression to annotate in the Document</span>
<span class="c1"># should match an existing one in your Document</span>
<span class="n">input_expression</span> <span class="o">=</span> <span class="s2">&quot;Musterstraße&quot;</span>

<span class="c1"># Label for the Annotation</span>
<span class="n">label_name</span> <span class="o">=</span> <span class="s2">&quot;Lohnart&quot;</span>
<span class="c1"># Getting the Label from the Project</span>
<span class="n">my_label</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="n">label_name</span><span class="p">)</span>

<span class="c1"># LabelSet to which the Label belongs</span>
<span class="n">label_set</span> <span class="o">=</span> <span class="n">my_label</span><span class="o">.</span><span class="n">label_sets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># First Document in the Project</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Matches of the word/expression in the Document</span>
<span class="n">matches_locations</span> <span class="o">=</span> <span class="p">[(</span><span class="n">m</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">m</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">input_expression</span><span class="p">,</span> <span class="n">document</span><span class="o">.</span><span class="n">text</span><span class="p">)]</span>

<span class="c1"># List to save the links to the Annotations created</span>
<span class="n">new_annotations_links</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Create Annotation for each match</span>
<span class="k">for</span> <span class="n">offsets</span> <span class="ow">in</span> <span class="n">matches_locations</span><span class="p">:</span>
    <span class="n">span</span> <span class="o">=</span> <span class="n">Span</span><span class="p">(</span><span class="n">start_offset</span><span class="o">=</span><span class="n">offsets</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end_offset</span><span class="o">=</span><span class="n">offsets</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">annotation_obj</span> <span class="o">=</span> <span class="n">Annotation</span><span class="p">(</span>
        <span class="n">document</span><span class="o">=</span><span class="n">document</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">my_label</span><span class="p">,</span> <span class="n">label_set</span><span class="o">=</span><span class="n">label_set</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">spans</span><span class="o">=</span><span class="p">[</span><span class="n">span</span><span class="p">],</span> <span class="n">is_correct</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">new_annotation_added</span> <span class="o">=</span> <span class="n">annotation_obj</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">new_annotation_added</span><span class="p">:</span>
        <span class="n">new_annotations_links</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">annotation_obj</span><span class="o">.</span><span class="n">get_link</span><span class="p">())</span>
    <span class="n">annotation_obj</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">delete_online</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">new_annotations_links</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-label-regex-tokenizer">
<h2>Train Label Regex Tokenizer<a class="headerlink" href="#train-label-regex-tokenizer" title="Permalink to this headline">¶</a></h2>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">konfuzio_sdk</span></code> package to train a custom Regex tokenizer.</p>
<p>In this example, you will see how to find regex expressions that match with occurrences of the “Lohnart” Label in the
training data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">RegexTokenizer</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.base</span> <span class="kn">import</span> <span class="n">ListTokenizer</span>

<span class="n">my_project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">category</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_category_by_id</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_CATEGORY_ID</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ListTokenizer</span><span class="p">(</span><span class="n">tokenizers</span><span class="o">=</span><span class="p">[])</span>

<span class="n">label</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s2">&quot;Lohnart&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">regex</span> <span class="ow">in</span> <span class="n">label</span><span class="o">.</span><span class="n">find_regex</span><span class="p">(</span><span class="n">category</span><span class="o">=</span><span class="n">category</span><span class="p">):</span>
    <span class="n">regex_tokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="p">(</span><span class="n">regex</span><span class="o">=</span><span class="n">regex</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">regex_tokenizer</span><span class="p">)</span>

<span class="c1"># You can then use it to create an Annotation for every matching string in a Document.</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">YOUR_DOCUMENT_ID</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="finding-spans-of-a-label-not-found-by-a-tokenizer">
<h2>Finding Spans of a Label Not Found by a Tokenizer<a class="headerlink" href="#finding-spans-of-a-label-not-found-by-a-tokenizer" title="Permalink to this headline">¶</a></h2>
<p>Here is an example of how to use the <code class="docutils literal notranslate"><span class="pre">Label.spans_not_found_by_tokenizer</span></code> method. This will allow you to determine if a RegexTokenizer is suitable at finding the Spans of a Label, or what Spans might have been annotated wrong. Say, you have a number of annotations assigned to the <code class="docutils literal notranslate"><span class="pre">IBAN</span></code> Label and want to know which Spans would not be found when using the WhiteSpace Tokenizer. You can follow this example to find all the relevant Spans.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">konfuzio_sdk.data</span> <span class="kn">import</span> <span class="n">Project</span>
<span class="kn">from</span> <span class="nn">konfuzio_sdk.tokenizer.regex</span> <span class="kn">import</span> <span class="n">WhitespaceTokenizer</span>

<span class="n">my_project</span> <span class="o">=</span> <span class="n">Project</span><span class="p">(</span><span class="n">id_</span><span class="o">=</span><span class="n">YOUR_PROJECT_ID</span><span class="p">)</span>
<span class="n">category</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">categories</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">WhitespaceTokenizer</span><span class="p">()</span>

<span class="n">label</span> <span class="o">=</span> <span class="n">my_project</span><span class="o">.</span><span class="n">get_label_by_name</span><span class="p">(</span><span class="s1">&#39;Austellungsdatum&#39;</span><span class="p">)</span>

<span class="n">spans_not_found</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">spans_not_found_by_tokenizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="n">category</span><span class="p">])</span>

<span class="k">for</span> <span class="n">span</span> <span class="ow">in</span> <span class="n">spans_not_found</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">span</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">span</span><span class="o">.</span><span class="n">offset_string</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="retrain-flair-ner-ontonotes-fast-with-human-revised-annotations">
<h2>Retrain Flair NER-Ontonotes-Fast with Human Revised Annotations<a class="headerlink" href="#retrain-flair-ner-ontonotes-fast-with-human-revised-annotations" title="Permalink to this headline">¶</a></h2>
<p>The tutorial <em>HRetrain Flair NER-Ontonotes-Fast with Human Revised Annotations</em> aims to show you how to use the
Konfuzio SDK package to include an easy feedback workflow in your training pipeline. It also gives an example of how you
can take advantage of open-source models to speed up the annotation process and use the feedback workflow to adapt the
domain knowledge of the model to your aim.</p>
<p>You can <a class="reference external" href="https://colab.research.google.com/github/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/human_in_the_loop.ipynb"><img alt="OpenInColab1" src="https://colab.research.google.com/assets/colab-badge.svg" /></a> or download it from
<a class="reference external" href="https://github.com/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/human_in_the_loop.ipynb">here</a>
and try it by yourself.</p>
</section>
<section id="count-relevant-expressions-in-annual-reports">
<h2>Count Relevant Expressions in Annual Reports<a class="headerlink" href="#count-relevant-expressions-in-annual-reports" title="Permalink to this headline">¶</a></h2>
<p>The tutorial <em>Count Relevant Expressions in Annual Reports</em> aims to show you how to use the Konfuzio SDK package to
retrieve structured and organized information that can be used for a deeper analysis and understanding of your data.
It will show you how to identify and count pre-specified expressions in documents and how to collect that information.</p>
<p>You can <a class="reference external" href="https://colab.research.google.com/github/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/word_count.ipynb"><img alt="OpenInColab2" src="https://colab.research.google.com/assets/colab-badge.svg" /></a> or download it from
<a class="reference external" href="https://github.com/konfuzio-ai/document-ai-python-sdk/blob/master/docs/sdk/examples/word_count.ipynb">here</a>
and try it by yourself.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Helm und Nagel GmbH.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D02B3QF8Z3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-D02B3QF8Z3');
</script>
<script src="https://cmp.osano.com/16CVyMSbk3Iar1G3f/97ee6223-b0cb-4f8c-abd6-a25a0d6f6507/osano.js"></script>
<script>window._nQc="89655017";</script>
<script async src="https://serve.albacross.com/track.js"></script>
<script data-jsd-embedded data-key="42374b9a-2f7b-46ec-ae7b-b79a89aa3dd9" data-base-url="https://jsd-widget.atlassian.com" src="https://jsd-widget.atlassian.com/assets/embed.js"></script>


</body>
</html>